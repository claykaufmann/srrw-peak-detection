{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Classification of Anomaly Peaks with 1D resnet\n",
    "Using normal train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "from sklearn import preprocessing\n",
    "from resnet import ResNet1D\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torchsummary import summary\n",
    "\n",
    "sys.path.insert(1, \"../\")\n",
    "\n",
    "from datasets import fdomDataset, fdomAugOnlyDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "WINDOW_SIZE = 15 # the size of each data segment\n",
    "TEST_SIZE = 0.10\n",
    "SEED = 42\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to data files\n",
    "fdom_raw_data = (\n",
    "    \"../Data/converted_data/julian_format/fDOM_raw_10.1.2011-9.4.2020.csv\"\n",
    ")\n",
    "stage_raw_data = \"../Data/converted_data/julian_format/stage_10.1.11-1.1.19.csv\"\n",
    "turb_raw_data = (\n",
    "    \"../Data/converted_data/julian_format/turbidity_raw_10.1.2011_9.4.2020.csv\"\n",
    ")\n",
    "\n",
    "fdom_labeled = \"../Data/labeled_data/ground_truths/fDOM/fDOM_all_julian_0k-300k.csv\"\n",
    "\n",
    "fdom_raw_augmented = \"../Data/augmented_data/fdom/unlabeled/unlabeled_fdom.csv\"\n",
    "fdom_labeled_augmented = \"../Data/augmented_data/fdom/labeled/labeled_fdom_peaks.csv\"\n",
    "\n",
    "turb_augmented_raw_data = \"../Data/augmented_data/fdom/unlabeled/unlabeled_turb.csv\"\n",
    "\n",
    "stage_augmented_data_fn = \"../Data/augmented_data/fdom/unlabeled/unlabeled_stage.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# get device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/../Tools/get_candidates.py:221: PeakPropertyWarning: some peaks have a prominence of 0\n",
      "  peaks, props = find_peaks(\n",
      "/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/../Tools/get_candidates.py:335: PeakPropertyWarning: some peaks have a prominence of 0\n",
      "  peaks, props = find_peaks(\n"
     ]
    }
   ],
   "source": [
    "# create dataset\n",
    "classes = [\"NAP\", \"FSK\", \"FPT\", \"PLP\", \"PP\", \"SKP\"]\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "targets = le.fit_transform(classes)\n",
    "\n",
    "# train on class balanced data\n",
    "train_dataset = fdomAugOnlyDataset(\n",
    "    le,\n",
    "    fdom_raw_augmented,\n",
    "    stage_augmented_data_fn,\n",
    "    turb_augmented_raw_data,\n",
    "    fdom_labeled_augmented,\n",
    "    window_size=WINDOW_SIZE\n",
    ")\n",
    "\n",
    "# test on unbalanced data\n",
    "test_dataset = fdomDataset(\n",
    "    le,\n",
    "    fdom_raw_data,\n",
    "    stage_raw_data,\n",
    "    turb_raw_data,\n",
    "    fdom_labeled,\n",
    "    window_size=WINDOW_SIZE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into training/testing\n",
    "This should not be the final iteration, this is just to get initial results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training / testing\n",
    "\n",
    "# create dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1                [-1, 64, 6]          31,808\n",
      "   MyConv1dPadSame-2                [-1, 64, 6]               0\n",
      "       BatchNorm1d-3                [-1, 64, 6]             128\n",
      "              ReLU-4                [-1, 64, 6]               0\n",
      "            Conv1d-5                [-1, 64, 6]          65,600\n",
      "   MyConv1dPadSame-6                [-1, 64, 6]               0\n",
      "       BatchNorm1d-7                [-1, 64, 6]             128\n",
      "              ReLU-8                [-1, 64, 6]               0\n",
      "           Dropout-9                [-1, 64, 6]               0\n",
      "           Conv1d-10                [-1, 64, 6]          65,600\n",
      "  MyConv1dPadSame-11                [-1, 64, 6]               0\n",
      "       BasicBlock-12                [-1, 64, 6]               0\n",
      "      BatchNorm1d-13                [-1, 64, 6]             128\n",
      "             ReLU-14                [-1, 64, 6]               0\n",
      "          Dropout-15                [-1, 64, 6]               0\n",
      "           Conv1d-16                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-17                [-1, 64, 3]               0\n",
      "      BatchNorm1d-18                [-1, 64, 3]             128\n",
      "             ReLU-19                [-1, 64, 3]               0\n",
      "          Dropout-20                [-1, 64, 3]               0\n",
      "           Conv1d-21                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-22                [-1, 64, 3]               0\n",
      "        MaxPool1d-23                [-1, 64, 3]               0\n",
      "MyMaxPool1dPadSame-24                [-1, 64, 3]               0\n",
      "       BasicBlock-25                [-1, 64, 3]               0\n",
      "      BatchNorm1d-26                [-1, 64, 3]             128\n",
      "             ReLU-27                [-1, 64, 3]               0\n",
      "          Dropout-28                [-1, 64, 3]               0\n",
      "           Conv1d-29                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-30                [-1, 64, 3]               0\n",
      "      BatchNorm1d-31                [-1, 64, 3]             128\n",
      "             ReLU-32                [-1, 64, 3]               0\n",
      "          Dropout-33                [-1, 64, 3]               0\n",
      "           Conv1d-34                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-35                [-1, 64, 3]               0\n",
      "       BasicBlock-36                [-1, 64, 3]               0\n",
      "      BatchNorm1d-37                [-1, 64, 3]             128\n",
      "             ReLU-38                [-1, 64, 3]               0\n",
      "          Dropout-39                [-1, 64, 3]               0\n",
      "           Conv1d-40                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-41                [-1, 64, 3]               0\n",
      "      BatchNorm1d-42                [-1, 64, 3]             128\n",
      "             ReLU-43                [-1, 64, 3]               0\n",
      "          Dropout-44                [-1, 64, 3]               0\n",
      "           Conv1d-45                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-46                [-1, 64, 3]               0\n",
      "       BasicBlock-47                [-1, 64, 3]               0\n",
      "      BatchNorm1d-48                [-1, 64, 3]             128\n",
      "             ReLU-49                [-1, 64, 3]               0\n",
      "          Dropout-50                [-1, 64, 3]               0\n",
      "           Conv1d-51                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-52                [-1, 64, 3]               0\n",
      "      BatchNorm1d-53                [-1, 64, 3]             128\n",
      "             ReLU-54                [-1, 64, 3]               0\n",
      "          Dropout-55                [-1, 64, 3]               0\n",
      "           Conv1d-56                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-57                [-1, 64, 3]               0\n",
      "       BasicBlock-58                [-1, 64, 3]               0\n",
      "      BatchNorm1d-59                [-1, 64, 3]             128\n",
      "             ReLU-60                [-1, 64, 3]               0\n",
      "          Dropout-61                [-1, 64, 3]               0\n",
      "           Conv1d-62                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-63                [-1, 64, 3]               0\n",
      "      BatchNorm1d-64                [-1, 64, 3]             128\n",
      "             ReLU-65                [-1, 64, 3]               0\n",
      "          Dropout-66                [-1, 64, 3]               0\n",
      "           Conv1d-67                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-68                [-1, 64, 3]               0\n",
      "       BasicBlock-69                [-1, 64, 3]               0\n",
      "      BatchNorm1d-70                [-1, 64, 3]             128\n",
      "             ReLU-71                [-1, 64, 3]               0\n",
      "          Dropout-72                [-1, 64, 3]               0\n",
      "           Conv1d-73                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-74                [-1, 64, 3]               0\n",
      "      BatchNorm1d-75                [-1, 64, 3]             128\n",
      "             ReLU-76                [-1, 64, 3]               0\n",
      "          Dropout-77                [-1, 64, 3]               0\n",
      "           Conv1d-78                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-79                [-1, 64, 3]               0\n",
      "       BasicBlock-80                [-1, 64, 3]               0\n",
      "      BatchNorm1d-81                [-1, 64, 3]             128\n",
      "             ReLU-82                [-1, 64, 3]               0\n",
      "          Dropout-83                [-1, 64, 3]               0\n",
      "           Conv1d-84                [-1, 64, 2]          65,600\n",
      "  MyConv1dPadSame-85                [-1, 64, 2]               0\n",
      "      BatchNorm1d-86                [-1, 64, 2]             128\n",
      "             ReLU-87                [-1, 64, 2]               0\n",
      "          Dropout-88                [-1, 64, 2]               0\n",
      "           Conv1d-89                [-1, 64, 2]          65,600\n",
      "  MyConv1dPadSame-90                [-1, 64, 2]               0\n",
      "        MaxPool1d-91                [-1, 64, 2]               0\n",
      "MyMaxPool1dPadSame-92                [-1, 64, 2]               0\n",
      "       BasicBlock-93                [-1, 64, 2]               0\n",
      "      BatchNorm1d-94                [-1, 64, 2]             128\n",
      "             ReLU-95                [-1, 64, 2]               0\n",
      "          Dropout-96                [-1, 64, 2]               0\n",
      "           Conv1d-97                [-1, 64, 2]          65,600\n",
      "  MyConv1dPadSame-98                [-1, 64, 2]               0\n",
      "      BatchNorm1d-99                [-1, 64, 2]             128\n",
      "            ReLU-100                [-1, 64, 2]               0\n",
      "         Dropout-101                [-1, 64, 2]               0\n",
      "          Conv1d-102                [-1, 64, 2]          65,600\n",
      " MyConv1dPadSame-103                [-1, 64, 2]               0\n",
      "      BasicBlock-104                [-1, 64, 2]               0\n",
      "     BatchNorm1d-105                [-1, 64, 2]             128\n",
      "            ReLU-106                [-1, 64, 2]               0\n",
      "         Dropout-107                [-1, 64, 2]               0\n",
      "          Conv1d-108                [-1, 64, 2]          65,600\n",
      " MyConv1dPadSame-109                [-1, 64, 2]               0\n",
      "     BatchNorm1d-110                [-1, 64, 2]             128\n",
      "            ReLU-111                [-1, 64, 2]               0\n",
      "         Dropout-112                [-1, 64, 2]               0\n",
      "          Conv1d-113                [-1, 64, 2]          65,600\n",
      " MyConv1dPadSame-114                [-1, 64, 2]               0\n",
      "      BasicBlock-115                [-1, 64, 2]               0\n",
      "     BatchNorm1d-116                [-1, 64, 2]             128\n",
      "            ReLU-117                [-1, 64, 2]               0\n",
      "         Dropout-118                [-1, 64, 2]               0\n",
      "          Conv1d-119                [-1, 64, 2]          65,600\n",
      " MyConv1dPadSame-120                [-1, 64, 2]               0\n",
      "     BatchNorm1d-121                [-1, 64, 2]             128\n",
      "            ReLU-122                [-1, 64, 2]               0\n",
      "         Dropout-123                [-1, 64, 2]               0\n",
      "          Conv1d-124                [-1, 64, 2]          65,600\n",
      " MyConv1dPadSame-125                [-1, 64, 2]               0\n",
      "      BasicBlock-126                [-1, 64, 2]               0\n",
      "     BatchNorm1d-127                [-1, 64, 2]             128\n",
      "            ReLU-128                [-1, 64, 2]               0\n",
      "         Dropout-129                [-1, 64, 2]               0\n",
      "          Conv1d-130                [-1, 64, 2]          65,600\n",
      " MyConv1dPadSame-131                [-1, 64, 2]               0\n",
      "     BatchNorm1d-132                [-1, 64, 2]             128\n",
      "            ReLU-133                [-1, 64, 2]               0\n",
      "         Dropout-134                [-1, 64, 2]               0\n",
      "          Conv1d-135                [-1, 64, 2]          65,600\n",
      " MyConv1dPadSame-136                [-1, 64, 2]               0\n",
      "      BasicBlock-137                [-1, 64, 2]               0\n",
      "     BatchNorm1d-138                [-1, 64, 2]             128\n",
      "            ReLU-139                [-1, 64, 2]               0\n",
      "         Dropout-140                [-1, 64, 2]               0\n",
      "          Conv1d-141               [-1, 128, 2]         131,200\n",
      " MyConv1dPadSame-142               [-1, 128, 2]               0\n",
      "     BatchNorm1d-143               [-1, 128, 2]             256\n",
      "            ReLU-144               [-1, 128, 2]               0\n",
      "         Dropout-145               [-1, 128, 2]               0\n",
      "          Conv1d-146               [-1, 128, 2]         262,272\n",
      " MyConv1dPadSame-147               [-1, 128, 2]               0\n",
      "      BasicBlock-148               [-1, 128, 2]               0\n",
      "     BatchNorm1d-149               [-1, 128, 2]             256\n",
      "            ReLU-150               [-1, 128, 2]               0\n",
      "         Dropout-151               [-1, 128, 2]               0\n",
      "          Conv1d-152               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-153               [-1, 128, 1]               0\n",
      "     BatchNorm1d-154               [-1, 128, 1]             256\n",
      "            ReLU-155               [-1, 128, 1]               0\n",
      "         Dropout-156               [-1, 128, 1]               0\n",
      "          Conv1d-157               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-158               [-1, 128, 1]               0\n",
      "       MaxPool1d-159               [-1, 128, 1]               0\n",
      "MyMaxPool1dPadSame-160               [-1, 128, 1]               0\n",
      "      BasicBlock-161               [-1, 128, 1]               0\n",
      "     BatchNorm1d-162               [-1, 128, 1]             256\n",
      "            ReLU-163               [-1, 128, 1]               0\n",
      "         Dropout-164               [-1, 128, 1]               0\n",
      "          Conv1d-165               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-166               [-1, 128, 1]               0\n",
      "     BatchNorm1d-167               [-1, 128, 1]             256\n",
      "            ReLU-168               [-1, 128, 1]               0\n",
      "         Dropout-169               [-1, 128, 1]               0\n",
      "          Conv1d-170               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-171               [-1, 128, 1]               0\n",
      "      BasicBlock-172               [-1, 128, 1]               0\n",
      "     BatchNorm1d-173               [-1, 128, 1]             256\n",
      "            ReLU-174               [-1, 128, 1]               0\n",
      "         Dropout-175               [-1, 128, 1]               0\n",
      "          Conv1d-176               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-177               [-1, 128, 1]               0\n",
      "     BatchNorm1d-178               [-1, 128, 1]             256\n",
      "            ReLU-179               [-1, 128, 1]               0\n",
      "         Dropout-180               [-1, 128, 1]               0\n",
      "          Conv1d-181               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-182               [-1, 128, 1]               0\n",
      "      BasicBlock-183               [-1, 128, 1]               0\n",
      "     BatchNorm1d-184               [-1, 128, 1]             256\n",
      "            ReLU-185               [-1, 128, 1]               0\n",
      "         Dropout-186               [-1, 128, 1]               0\n",
      "          Conv1d-187               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-188               [-1, 128, 1]               0\n",
      "     BatchNorm1d-189               [-1, 128, 1]             256\n",
      "            ReLU-190               [-1, 128, 1]               0\n",
      "         Dropout-191               [-1, 128, 1]               0\n",
      "          Conv1d-192               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-193               [-1, 128, 1]               0\n",
      "      BasicBlock-194               [-1, 128, 1]               0\n",
      "     BatchNorm1d-195               [-1, 128, 1]             256\n",
      "            ReLU-196               [-1, 128, 1]               0\n",
      "         Dropout-197               [-1, 128, 1]               0\n",
      "          Conv1d-198               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-199               [-1, 128, 1]               0\n",
      "     BatchNorm1d-200               [-1, 128, 1]             256\n",
      "            ReLU-201               [-1, 128, 1]               0\n",
      "         Dropout-202               [-1, 128, 1]               0\n",
      "          Conv1d-203               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-204               [-1, 128, 1]               0\n",
      "      BasicBlock-205               [-1, 128, 1]               0\n",
      "     BatchNorm1d-206               [-1, 128, 1]             256\n",
      "            ReLU-207               [-1, 128, 1]               0\n",
      "         Dropout-208               [-1, 128, 1]               0\n",
      "          Conv1d-209               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-210               [-1, 128, 1]               0\n",
      "     BatchNorm1d-211               [-1, 128, 1]             256\n",
      "            ReLU-212               [-1, 128, 1]               0\n",
      "         Dropout-213               [-1, 128, 1]               0\n",
      "          Conv1d-214               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-215               [-1, 128, 1]               0\n",
      "      BasicBlock-216               [-1, 128, 1]               0\n",
      "     BatchNorm1d-217               [-1, 128, 1]             256\n",
      "            ReLU-218               [-1, 128, 1]               0\n",
      "         Dropout-219               [-1, 128, 1]               0\n",
      "          Conv1d-220               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-221               [-1, 128, 1]               0\n",
      "     BatchNorm1d-222               [-1, 128, 1]             256\n",
      "            ReLU-223               [-1, 128, 1]               0\n",
      "         Dropout-224               [-1, 128, 1]               0\n",
      "          Conv1d-225               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-226               [-1, 128, 1]               0\n",
      "       MaxPool1d-227               [-1, 128, 1]               0\n",
      "MyMaxPool1dPadSame-228               [-1, 128, 1]               0\n",
      "      BasicBlock-229               [-1, 128, 1]               0\n",
      "     BatchNorm1d-230               [-1, 128, 1]             256\n",
      "            ReLU-231               [-1, 128, 1]               0\n",
      "         Dropout-232               [-1, 128, 1]               0\n",
      "          Conv1d-233               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-234               [-1, 128, 1]               0\n",
      "     BatchNorm1d-235               [-1, 128, 1]             256\n",
      "            ReLU-236               [-1, 128, 1]               0\n",
      "         Dropout-237               [-1, 128, 1]               0\n",
      "          Conv1d-238               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-239               [-1, 128, 1]               0\n",
      "      BasicBlock-240               [-1, 128, 1]               0\n",
      "     BatchNorm1d-241               [-1, 128, 1]             256\n",
      "            ReLU-242               [-1, 128, 1]               0\n",
      "         Dropout-243               [-1, 128, 1]               0\n",
      "          Conv1d-244               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-245               [-1, 128, 1]               0\n",
      "     BatchNorm1d-246               [-1, 128, 1]             256\n",
      "            ReLU-247               [-1, 128, 1]               0\n",
      "         Dropout-248               [-1, 128, 1]               0\n",
      "          Conv1d-249               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-250               [-1, 128, 1]               0\n",
      "      BasicBlock-251               [-1, 128, 1]               0\n",
      "     BatchNorm1d-252               [-1, 128, 1]             256\n",
      "            ReLU-253               [-1, 128, 1]               0\n",
      "         Dropout-254               [-1, 128, 1]               0\n",
      "          Conv1d-255               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-256               [-1, 128, 1]               0\n",
      "     BatchNorm1d-257               [-1, 128, 1]             256\n",
      "            ReLU-258               [-1, 128, 1]               0\n",
      "         Dropout-259               [-1, 128, 1]               0\n",
      "          Conv1d-260               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-261               [-1, 128, 1]               0\n",
      "      BasicBlock-262               [-1, 128, 1]               0\n",
      "     BatchNorm1d-263               [-1, 128, 1]             256\n",
      "            ReLU-264               [-1, 128, 1]               0\n",
      "         Dropout-265               [-1, 128, 1]               0\n",
      "          Conv1d-266               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-267               [-1, 128, 1]               0\n",
      "     BatchNorm1d-268               [-1, 128, 1]             256\n",
      "            ReLU-269               [-1, 128, 1]               0\n",
      "         Dropout-270               [-1, 128, 1]               0\n",
      "          Conv1d-271               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-272               [-1, 128, 1]               0\n",
      "      BasicBlock-273               [-1, 128, 1]               0\n",
      "     BatchNorm1d-274               [-1, 128, 1]             256\n",
      "            ReLU-275               [-1, 128, 1]               0\n",
      "         Dropout-276               [-1, 128, 1]               0\n",
      "          Conv1d-277               [-1, 256, 1]         524,544\n",
      " MyConv1dPadSame-278               [-1, 256, 1]               0\n",
      "     BatchNorm1d-279               [-1, 256, 1]             512\n",
      "            ReLU-280               [-1, 256, 1]               0\n",
      "         Dropout-281               [-1, 256, 1]               0\n",
      "          Conv1d-282               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-283               [-1, 256, 1]               0\n",
      "      BasicBlock-284               [-1, 256, 1]               0\n",
      "     BatchNorm1d-285               [-1, 256, 1]             512\n",
      "            ReLU-286               [-1, 256, 1]               0\n",
      "         Dropout-287               [-1, 256, 1]               0\n",
      "          Conv1d-288               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-289               [-1, 256, 1]               0\n",
      "     BatchNorm1d-290               [-1, 256, 1]             512\n",
      "            ReLU-291               [-1, 256, 1]               0\n",
      "         Dropout-292               [-1, 256, 1]               0\n",
      "          Conv1d-293               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-294               [-1, 256, 1]               0\n",
      "       MaxPool1d-295               [-1, 256, 1]               0\n",
      "MyMaxPool1dPadSame-296               [-1, 256, 1]               0\n",
      "      BasicBlock-297               [-1, 256, 1]               0\n",
      "     BatchNorm1d-298               [-1, 256, 1]             512\n",
      "            ReLU-299               [-1, 256, 1]               0\n",
      "         Dropout-300               [-1, 256, 1]               0\n",
      "          Conv1d-301               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-302               [-1, 256, 1]               0\n",
      "     BatchNorm1d-303               [-1, 256, 1]             512\n",
      "            ReLU-304               [-1, 256, 1]               0\n",
      "         Dropout-305               [-1, 256, 1]               0\n",
      "          Conv1d-306               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-307               [-1, 256, 1]               0\n",
      "      BasicBlock-308               [-1, 256, 1]               0\n",
      "     BatchNorm1d-309               [-1, 256, 1]             512\n",
      "            ReLU-310               [-1, 256, 1]               0\n",
      "         Dropout-311               [-1, 256, 1]               0\n",
      "          Conv1d-312               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-313               [-1, 256, 1]               0\n",
      "     BatchNorm1d-314               [-1, 256, 1]             512\n",
      "            ReLU-315               [-1, 256, 1]               0\n",
      "         Dropout-316               [-1, 256, 1]               0\n",
      "          Conv1d-317               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-318               [-1, 256, 1]               0\n",
      "      BasicBlock-319               [-1, 256, 1]               0\n",
      "     BatchNorm1d-320               [-1, 256, 1]             512\n",
      "            ReLU-321               [-1, 256, 1]               0\n",
      "         Dropout-322               [-1, 256, 1]               0\n",
      "          Conv1d-323               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-324               [-1, 256, 1]               0\n",
      "     BatchNorm1d-325               [-1, 256, 1]             512\n",
      "            ReLU-326               [-1, 256, 1]               0\n",
      "         Dropout-327               [-1, 256, 1]               0\n",
      "          Conv1d-328               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-329               [-1, 256, 1]               0\n",
      "      BasicBlock-330               [-1, 256, 1]               0\n",
      "     BatchNorm1d-331               [-1, 256, 1]             512\n",
      "            ReLU-332               [-1, 256, 1]               0\n",
      "         Dropout-333               [-1, 256, 1]               0\n",
      "          Conv1d-334               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-335               [-1, 256, 1]               0\n",
      "     BatchNorm1d-336               [-1, 256, 1]             512\n",
      "            ReLU-337               [-1, 256, 1]               0\n",
      "         Dropout-338               [-1, 256, 1]               0\n",
      "          Conv1d-339               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-340               [-1, 256, 1]               0\n",
      "      BasicBlock-341               [-1, 256, 1]               0\n",
      "     BatchNorm1d-342               [-1, 256, 1]             512\n",
      "            ReLU-343               [-1, 256, 1]               0\n",
      "         Dropout-344               [-1, 256, 1]               0\n",
      "          Conv1d-345               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-346               [-1, 256, 1]               0\n",
      "     BatchNorm1d-347               [-1, 256, 1]             512\n",
      "            ReLU-348               [-1, 256, 1]               0\n",
      "         Dropout-349               [-1, 256, 1]               0\n",
      "          Conv1d-350               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-351               [-1, 256, 1]               0\n",
      "      BasicBlock-352               [-1, 256, 1]               0\n",
      "     BatchNorm1d-353               [-1, 256, 1]             512\n",
      "            ReLU-354               [-1, 256, 1]               0\n",
      "         Dropout-355               [-1, 256, 1]               0\n",
      "          Conv1d-356               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-357               [-1, 256, 1]               0\n",
      "     BatchNorm1d-358               [-1, 256, 1]             512\n",
      "            ReLU-359               [-1, 256, 1]               0\n",
      "         Dropout-360               [-1, 256, 1]               0\n",
      "          Conv1d-361               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-362               [-1, 256, 1]               0\n",
      "       MaxPool1d-363               [-1, 256, 1]               0\n",
      "MyMaxPool1dPadSame-364               [-1, 256, 1]               0\n",
      "      BasicBlock-365               [-1, 256, 1]               0\n",
      "     BatchNorm1d-366               [-1, 256, 1]             512\n",
      "            ReLU-367               [-1, 256, 1]               0\n",
      "         Dropout-368               [-1, 256, 1]               0\n",
      "          Conv1d-369               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-370               [-1, 256, 1]               0\n",
      "     BatchNorm1d-371               [-1, 256, 1]             512\n",
      "            ReLU-372               [-1, 256, 1]               0\n",
      "         Dropout-373               [-1, 256, 1]               0\n",
      "          Conv1d-374               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-375               [-1, 256, 1]               0\n",
      "      BasicBlock-376               [-1, 256, 1]               0\n",
      "     BatchNorm1d-377               [-1, 256, 1]             512\n",
      "            ReLU-378               [-1, 256, 1]               0\n",
      "         Dropout-379               [-1, 256, 1]               0\n",
      "          Conv1d-380               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-381               [-1, 256, 1]               0\n",
      "     BatchNorm1d-382               [-1, 256, 1]             512\n",
      "            ReLU-383               [-1, 256, 1]               0\n",
      "         Dropout-384               [-1, 256, 1]               0\n",
      "          Conv1d-385               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-386               [-1, 256, 1]               0\n",
      "      BasicBlock-387               [-1, 256, 1]               0\n",
      "     BatchNorm1d-388               [-1, 256, 1]             512\n",
      "            ReLU-389               [-1, 256, 1]               0\n",
      "         Dropout-390               [-1, 256, 1]               0\n",
      "          Conv1d-391               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-392               [-1, 256, 1]               0\n",
      "     BatchNorm1d-393               [-1, 256, 1]             512\n",
      "            ReLU-394               [-1, 256, 1]               0\n",
      "         Dropout-395               [-1, 256, 1]               0\n",
      "          Conv1d-396               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-397               [-1, 256, 1]               0\n",
      "      BasicBlock-398               [-1, 256, 1]               0\n",
      "     BatchNorm1d-399               [-1, 256, 1]             512\n",
      "            ReLU-400               [-1, 256, 1]               0\n",
      "         Dropout-401               [-1, 256, 1]               0\n",
      "          Conv1d-402               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-403               [-1, 256, 1]               0\n",
      "     BatchNorm1d-404               [-1, 256, 1]             512\n",
      "            ReLU-405               [-1, 256, 1]               0\n",
      "         Dropout-406               [-1, 256, 1]               0\n",
      "          Conv1d-407               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-408               [-1, 256, 1]               0\n",
      "      BasicBlock-409               [-1, 256, 1]               0\n",
      "     BatchNorm1d-410               [-1, 256, 1]             512\n",
      "            ReLU-411               [-1, 256, 1]               0\n",
      "         Dropout-412               [-1, 256, 1]               0\n",
      "          Conv1d-413               [-1, 512, 1]       2,097,664\n",
      " MyConv1dPadSame-414               [-1, 512, 1]               0\n",
      "     BatchNorm1d-415               [-1, 512, 1]           1,024\n",
      "            ReLU-416               [-1, 512, 1]               0\n",
      "         Dropout-417               [-1, 512, 1]               0\n",
      "          Conv1d-418               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-419               [-1, 512, 1]               0\n",
      "      BasicBlock-420               [-1, 512, 1]               0\n",
      "     BatchNorm1d-421               [-1, 512, 1]           1,024\n",
      "            ReLU-422               [-1, 512, 1]               0\n",
      "         Dropout-423               [-1, 512, 1]               0\n",
      "          Conv1d-424               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-425               [-1, 512, 1]               0\n",
      "     BatchNorm1d-426               [-1, 512, 1]           1,024\n",
      "            ReLU-427               [-1, 512, 1]               0\n",
      "         Dropout-428               [-1, 512, 1]               0\n",
      "          Conv1d-429               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-430               [-1, 512, 1]               0\n",
      "       MaxPool1d-431               [-1, 512, 1]               0\n",
      "MyMaxPool1dPadSame-432               [-1, 512, 1]               0\n",
      "      BasicBlock-433               [-1, 512, 1]               0\n",
      "     BatchNorm1d-434               [-1, 512, 1]           1,024\n",
      "            ReLU-435               [-1, 512, 1]               0\n",
      "         Dropout-436               [-1, 512, 1]               0\n",
      "          Conv1d-437               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-438               [-1, 512, 1]               0\n",
      "     BatchNorm1d-439               [-1, 512, 1]           1,024\n",
      "            ReLU-440               [-1, 512, 1]               0\n",
      "         Dropout-441               [-1, 512, 1]               0\n",
      "          Conv1d-442               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-443               [-1, 512, 1]               0\n",
      "      BasicBlock-444               [-1, 512, 1]               0\n",
      "     BatchNorm1d-445               [-1, 512, 1]           1,024\n",
      "            ReLU-446               [-1, 512, 1]               0\n",
      "         Dropout-447               [-1, 512, 1]               0\n",
      "          Conv1d-448               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-449               [-1, 512, 1]               0\n",
      "     BatchNorm1d-450               [-1, 512, 1]           1,024\n",
      "            ReLU-451               [-1, 512, 1]               0\n",
      "         Dropout-452               [-1, 512, 1]               0\n",
      "          Conv1d-453               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-454               [-1, 512, 1]               0\n",
      "      BasicBlock-455               [-1, 512, 1]               0\n",
      "     BatchNorm1d-456               [-1, 512, 1]           1,024\n",
      "            ReLU-457               [-1, 512, 1]               0\n",
      "         Dropout-458               [-1, 512, 1]               0\n",
      "          Conv1d-459               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-460               [-1, 512, 1]               0\n",
      "     BatchNorm1d-461               [-1, 512, 1]           1,024\n",
      "            ReLU-462               [-1, 512, 1]               0\n",
      "         Dropout-463               [-1, 512, 1]               0\n",
      "          Conv1d-464               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-465               [-1, 512, 1]               0\n",
      "      BasicBlock-466               [-1, 512, 1]               0\n",
      "     BatchNorm1d-467               [-1, 512, 1]           1,024\n",
      "            ReLU-468               [-1, 512, 1]               0\n",
      "         Dropout-469               [-1, 512, 1]               0\n",
      "          Conv1d-470               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-471               [-1, 512, 1]               0\n",
      "     BatchNorm1d-472               [-1, 512, 1]           1,024\n",
      "            ReLU-473               [-1, 512, 1]               0\n",
      "         Dropout-474               [-1, 512, 1]               0\n",
      "          Conv1d-475               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-476               [-1, 512, 1]               0\n",
      "      BasicBlock-477               [-1, 512, 1]               0\n",
      "     BatchNorm1d-478               [-1, 512, 1]           1,024\n",
      "            ReLU-479               [-1, 512, 1]               0\n",
      "         Dropout-480               [-1, 512, 1]               0\n",
      "          Conv1d-481               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-482               [-1, 512, 1]               0\n",
      "     BatchNorm1d-483               [-1, 512, 1]           1,024\n",
      "            ReLU-484               [-1, 512, 1]               0\n",
      "         Dropout-485               [-1, 512, 1]               0\n",
      "          Conv1d-486               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-487               [-1, 512, 1]               0\n",
      "      BasicBlock-488               [-1, 512, 1]               0\n",
      "     BatchNorm1d-489               [-1, 512, 1]           1,024\n",
      "            ReLU-490               [-1, 512, 1]               0\n",
      "         Dropout-491               [-1, 512, 1]               0\n",
      "          Conv1d-492               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-493               [-1, 512, 1]               0\n",
      "     BatchNorm1d-494               [-1, 512, 1]           1,024\n",
      "            ReLU-495               [-1, 512, 1]               0\n",
      "         Dropout-496               [-1, 512, 1]               0\n",
      "          Conv1d-497               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-498               [-1, 512, 1]               0\n",
      "       MaxPool1d-499               [-1, 512, 1]               0\n",
      "MyMaxPool1dPadSame-500               [-1, 512, 1]               0\n",
      "      BasicBlock-501               [-1, 512, 1]               0\n",
      "     BatchNorm1d-502               [-1, 512, 1]           1,024\n",
      "            ReLU-503               [-1, 512, 1]               0\n",
      "         Dropout-504               [-1, 512, 1]               0\n",
      "          Conv1d-505               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-506               [-1, 512, 1]               0\n",
      "     BatchNorm1d-507               [-1, 512, 1]           1,024\n",
      "            ReLU-508               [-1, 512, 1]               0\n",
      "         Dropout-509               [-1, 512, 1]               0\n",
      "          Conv1d-510               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-511               [-1, 512, 1]               0\n",
      "      BasicBlock-512               [-1, 512, 1]               0\n",
      "     BatchNorm1d-513               [-1, 512, 1]           1,024\n",
      "            ReLU-514               [-1, 512, 1]               0\n",
      "         Dropout-515               [-1, 512, 1]               0\n",
      "          Conv1d-516               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-517               [-1, 512, 1]               0\n",
      "     BatchNorm1d-518               [-1, 512, 1]           1,024\n",
      "            ReLU-519               [-1, 512, 1]               0\n",
      "         Dropout-520               [-1, 512, 1]               0\n",
      "          Conv1d-521               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-522               [-1, 512, 1]               0\n",
      "      BasicBlock-523               [-1, 512, 1]               0\n",
      "     BatchNorm1d-524               [-1, 512, 1]           1,024\n",
      "            ReLU-525               [-1, 512, 1]               0\n",
      "         Dropout-526               [-1, 512, 1]               0\n",
      "          Conv1d-527               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-528               [-1, 512, 1]               0\n",
      "     BatchNorm1d-529               [-1, 512, 1]           1,024\n",
      "            ReLU-530               [-1, 512, 1]               0\n",
      "         Dropout-531               [-1, 512, 1]               0\n",
      "          Conv1d-532               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-533               [-1, 512, 1]               0\n",
      "      BasicBlock-534               [-1, 512, 1]               0\n",
      "     BatchNorm1d-535               [-1, 512, 1]           1,024\n",
      "            ReLU-536               [-1, 512, 1]               0\n",
      "         Dropout-537               [-1, 512, 1]               0\n",
      "          Conv1d-538               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-539               [-1, 512, 1]               0\n",
      "     BatchNorm1d-540               [-1, 512, 1]           1,024\n",
      "            ReLU-541               [-1, 512, 1]               0\n",
      "         Dropout-542               [-1, 512, 1]               0\n",
      "          Conv1d-543               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-544               [-1, 512, 1]               0\n",
      "      BasicBlock-545               [-1, 512, 1]               0\n",
      "     BatchNorm1d-546               [-1, 512, 1]           1,024\n",
      "            ReLU-547               [-1, 512, 1]               0\n",
      "          Linear-548                    [-1, 6]           3,078\n",
      "================================================================\n",
      "Total params: 131,045,062\n",
      "Trainable params: 131,045,062\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.14\n",
      "Params size (MB): 499.90\n",
      "Estimated Total Size (MB): 501.03\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# init model\n",
    "model = ResNet1D(\n",
    "    in_channels=WINDOW_SIZE * 2 + 1,\n",
    "    base_filters=64,\n",
    "    kernel_size=16,\n",
    "    stride=2,\n",
    "    n_block=48,\n",
    "    groups=1,  # check this\n",
    "    n_classes=len(classes),\n",
    "    downsample_gap=6,\n",
    "    increasefilter_gap=12,\n",
    "    verbose=False,\n",
    ").to(device)\n",
    "\n",
    "model = model.float()\n",
    "\n",
    "# print a model summary\n",
    "print(summary(model, (WINDOW_SIZE * 2 + 1, 6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer/criterion\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "all_loss = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    }
   ],
   "source": [
    "prog_bar = tqdm(trainloader, desc='Training', leave=False)\n",
    "for i, batch in enumerate(prog_bar):\n",
    "    x = batch[0].to(device)\n",
    "\n",
    "    # squeeze y to flatten predictions into 1d tensor\n",
    "    y = batch[1].squeeze().to(device)\n",
    "\n",
    "    pred = model(x.float())\n",
    "\n",
    "    loss = criterion(pred, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    all_loss.append(loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: NAP   is 11.7 %\n",
      "Accuracy for class: FSK   is 0.0 %\n",
      "Accuracy for class: FPT   is 0.0 %\n",
      "Accuracy for class: PLP   is 19.2 %\n",
      "Accuracy for class: PP    is 26.2 %\n",
      "Accuracy for class: SKP   is 20.7 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "prog_bar = tqdm(testloader, desc='Testing', leave=False)\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(prog_bar):\n",
    "        x = batch[0].to(device)\n",
    "\n",
    "        y = batch[1].squeeze().to(device)\n",
    "\n",
    "        outs = model(x.float())\n",
    "\n",
    "        _, preds = torch.max(outs, 1)\n",
    "\n",
    "        for label, prediction in zip(y, preds):\n",
    "            # convert label and prediction to current vals\n",
    "            label = le.inverse_transform([label])[0]\n",
    "            prediction = le.inverse_transform([prediction])[0]\n",
    "\n",
    "            if label == prediction:\n",
    "                correct_pred[label] += 1 # this may not work\n",
    "            total_pred[label] += 1\n",
    "\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    # because of unbalanced data, we need to not print out any classes that didn't have any labels\n",
    "    if total_pred[classname] != 0:\n",
    "        accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "        print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')\n",
    "    else:\n",
    "        accuracy = 0.0\n",
    "        print(f'CLASS NOT IN TEST BATCH: {classname:5s}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement displaying metrics"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ed753961bdc37ee89b4275051722ceb8ec0b57b8793db9d189305c313070a7d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('srrw')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
