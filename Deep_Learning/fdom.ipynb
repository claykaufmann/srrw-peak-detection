{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Classification of Anomaly Peaks with 1D resnet\n",
    "Using normal train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "from sklearn import preprocessing\n",
    "from resnet import ResNet1D\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torchsummary import summary\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, balanced_accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "sys.path.insert(1, \"../\")\n",
    "\n",
    "from datasets import fdomDataset, fdomAugOnlyDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "WINDOW_SIZE = 15 # the size of each data segment\n",
    "TEST_SIZE = 0.10\n",
    "SEED = 42\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to data files\n",
    "fdom_raw_data = (\n",
    "    \"../Data/converted_data/julian_format/fDOM_raw_10.1.2011-9.4.2020.csv\"\n",
    ")\n",
    "stage_raw_data = \"../Data/converted_data/julian_format/stage_10.1.11-1.1.19.csv\"\n",
    "turb_raw_data = (\n",
    "    \"../Data/converted_data/julian_format/turbidity_raw_10.1.2011_9.4.2020.csv\"\n",
    ")\n",
    "\n",
    "fdom_labeled = \"../Data/labeled_data/ground_truths/fDOM/fDOM_all_julian_0k-300k.csv\"\n",
    "\n",
    "fdom_raw_augmented = \"../Data/augmented_data/fdom/unlabeled/unlabeled_fdom.csv\"\n",
    "fdom_labeled_augmented = \"../Data/augmented_data/fdom/labeled/labeled_fdom_peaks.csv\"\n",
    "\n",
    "turb_augmented_raw_data = \"../Data/augmented_data/fdom/unlabeled/unlabeled_turb.csv\"\n",
    "\n",
    "stage_augmented_data_fn = \"../Data/augmented_data/fdom/unlabeled/unlabeled_stage.csv\"\n",
    "\n",
    "fdom_fpt_lookup_path = \"../Data/augmented_data/fdom/fpt_lookup.csv\"\n",
    "fdom_fsk_lookup_path = \"../Data/augmented_data/fdom/fsk_lookup.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# get device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fdomAugOnlyDataset.__init__() missing 4 required positional arguments: 'fdom_augmented_dir', 'stage_augmented_dir', 'turb_augmented_dir', and 'fdom_labeled_aug_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb Cell 7'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000006?line=4'>5</a>\u001b[0m targets \u001b[39m=\u001b[39m le\u001b[39m.\u001b[39mfit_transform(classes)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000006?line=6'>7</a>\u001b[0m \u001b[39m# # train on class balanced data\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000006?line=7'>8</a>\u001b[0m train_dataset \u001b[39m=\u001b[39m fdomAugOnlyDataset(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000006?line=8'>9</a>\u001b[0m     le,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000006?line=9'>10</a>\u001b[0m     fdom_raw_augmented,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000006?line=10'>11</a>\u001b[0m     stage_augmented_data_fn,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000006?line=11'>12</a>\u001b[0m     turb_augmented_raw_data,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000006?line=12'>13</a>\u001b[0m     fdom_labeled_augmented,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000006?line=13'>14</a>\u001b[0m     window_size\u001b[39m=\u001b[39;49mWINDOW_SIZE,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000006?line=14'>15</a>\u001b[0m     fpt_lookup_filename\u001b[39m=\u001b[39;49mfdom_fpt_lookup_path,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000006?line=15'>16</a>\u001b[0m     fsk_lookup_filename\u001b[39m=\u001b[39;49mfdom_fsk_lookup_path,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000006?line=16'>17</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000006?line=18'>19</a>\u001b[0m \u001b[39m# test on unbalanced data\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000006?line=19'>20</a>\u001b[0m test_dataset \u001b[39m=\u001b[39m fdomDataset(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000006?line=20'>21</a>\u001b[0m     le,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000006?line=21'>22</a>\u001b[0m     fdom_raw_data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000006?line=31'>32</a>\u001b[0m     fsk_lookup_filename\u001b[39m=\u001b[39mfdom_fsk_lookup_path,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000006?line=32'>33</a>\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: fdomAugOnlyDataset.__init__() missing 4 required positional arguments: 'fdom_augmented_dir', 'stage_augmented_dir', 'turb_augmented_dir', and 'fdom_labeled_aug_dir'"
     ]
    }
   ],
   "source": [
    "# create dataset\n",
    "classes = [\"NAP\", \"FSK\", \"FPT\", \"PLP\", \"PP\", \"SKP\"]\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "targets = le.fit_transform(classes)\n",
    "\n",
    "# # train on class balanced data\n",
    "train_dataset = fdomAugOnlyDataset(\n",
    "    le,\n",
    "    fdom_raw_data,\n",
    "    stage_raw_data,\n",
    "    turb_raw_data,\n",
    "    fdom_labeled,\n",
    "    fdom_raw_augmented,\n",
    "    stage_augmented_data_fn,\n",
    "    turb_augmented_raw_data,\n",
    "    fdom_labeled_augmented,\n",
    "    window_size=WINDOW_SIZE,\n",
    "    fpt_lookup_filename=fdom_fpt_lookup_path,\n",
    "    fsk_lookup_filename=fdom_fsk_lookup_path,\n",
    ")\n",
    "\n",
    "# test on unbalanced data\n",
    "test_dataset = fdomDataset(\n",
    "    le,\n",
    "    fdom_raw_data,\n",
    "    stage_raw_data,\n",
    "    turb_raw_data,\n",
    "    fdom_labeled,\n",
    "    # fdom_raw_augmented,\n",
    "    # stage_augmented_data_fn,\n",
    "    # turb_augmented_raw_data,\n",
    "    # fdom_labeled_augmented,\n",
    "    window_size=WINDOW_SIZE,\n",
    "    fpt_lookup_filename=fdom_fpt_lookup_path,\n",
    "    fsk_lookup_filename=fdom_fsk_lookup_path,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into training/testing\n",
    "This should not be the final iteration, this is just to get initial results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is a custom collate function which pads different length objects into one shape, allowing variable sized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: this is broken, not batching correctly\n",
    "# the batch is a tuple...\n",
    "def collate_fn_padd(batch):\n",
    "    '''\n",
    "    Padds batch of variable length\n",
    "\n",
    "    note: it converts things ToTensor manually here since the ToTensor transform\n",
    "    assume it takes in images rather than arbitrary tensors.\n",
    "    '''\n",
    "    ## get sequence lengths\n",
    "    lengths = torch.tensor([ len(t) for t in batch ]).to(device)\n",
    "    print(batch[0][0].shape)\n",
    "    ## padd\n",
    "    batch = [ torch.Tensor(t).to(device) for t in batch ] # this is the broken line, because dim 1 is variable length\n",
    "    batch = torch.nn.utils.rnn.pad_sequence(batch)\n",
    "    ## compute mask\n",
    "    mask = (batch != 0).to(device)\n",
    "    return batch, lengths, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training / testing\n",
    "# train_size = int(0.85 * len(dataset))\n",
    "# test_size = len(dataset) - train_size\n",
    "# train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# create dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn_padd\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn_padd\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1                [-1, 64, 6]          31,808\n",
      "   MyConv1dPadSame-2                [-1, 64, 6]               0\n",
      "       BatchNorm1d-3                [-1, 64, 6]             128\n",
      "              ReLU-4                [-1, 64, 6]               0\n",
      "            Conv1d-5                [-1, 64, 6]          65,600\n",
      "   MyConv1dPadSame-6                [-1, 64, 6]               0\n",
      "       BatchNorm1d-7                [-1, 64, 6]             128\n",
      "              ReLU-8                [-1, 64, 6]               0\n",
      "           Dropout-9                [-1, 64, 6]               0\n",
      "           Conv1d-10                [-1, 64, 6]          65,600\n",
      "  MyConv1dPadSame-11                [-1, 64, 6]               0\n",
      "       BasicBlock-12                [-1, 64, 6]               0\n",
      "      BatchNorm1d-13                [-1, 64, 6]             128\n",
      "             ReLU-14                [-1, 64, 6]               0\n",
      "          Dropout-15                [-1, 64, 6]               0\n",
      "           Conv1d-16                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-17                [-1, 64, 3]               0\n",
      "      BatchNorm1d-18                [-1, 64, 3]             128\n",
      "             ReLU-19                [-1, 64, 3]               0\n",
      "          Dropout-20                [-1, 64, 3]               0\n",
      "           Conv1d-21                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-22                [-1, 64, 3]               0\n",
      "        MaxPool1d-23                [-1, 64, 3]               0\n",
      "MyMaxPool1dPadSame-24                [-1, 64, 3]               0\n",
      "       BasicBlock-25                [-1, 64, 3]               0\n",
      "      BatchNorm1d-26                [-1, 64, 3]             128\n",
      "             ReLU-27                [-1, 64, 3]               0\n",
      "          Dropout-28                [-1, 64, 3]               0\n",
      "           Conv1d-29                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-30                [-1, 64, 3]               0\n",
      "      BatchNorm1d-31                [-1, 64, 3]             128\n",
      "             ReLU-32                [-1, 64, 3]               0\n",
      "          Dropout-33                [-1, 64, 3]               0\n",
      "           Conv1d-34                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-35                [-1, 64, 3]               0\n",
      "       BasicBlock-36                [-1, 64, 3]               0\n",
      "      BatchNorm1d-37                [-1, 64, 3]             128\n",
      "             ReLU-38                [-1, 64, 3]               0\n",
      "          Dropout-39                [-1, 64, 3]               0\n",
      "           Conv1d-40                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-41                [-1, 64, 3]               0\n",
      "      BatchNorm1d-42                [-1, 64, 3]             128\n",
      "             ReLU-43                [-1, 64, 3]               0\n",
      "          Dropout-44                [-1, 64, 3]               0\n",
      "           Conv1d-45                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-46                [-1, 64, 3]               0\n",
      "       BasicBlock-47                [-1, 64, 3]               0\n",
      "      BatchNorm1d-48                [-1, 64, 3]             128\n",
      "             ReLU-49                [-1, 64, 3]               0\n",
      "          Dropout-50                [-1, 64, 3]               0\n",
      "           Conv1d-51                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-52                [-1, 64, 3]               0\n",
      "      BatchNorm1d-53                [-1, 64, 3]             128\n",
      "             ReLU-54                [-1, 64, 3]               0\n",
      "          Dropout-55                [-1, 64, 3]               0\n",
      "           Conv1d-56                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-57                [-1, 64, 3]               0\n",
      "       BasicBlock-58                [-1, 64, 3]               0\n",
      "      BatchNorm1d-59                [-1, 64, 3]             128\n",
      "             ReLU-60                [-1, 64, 3]               0\n",
      "          Dropout-61                [-1, 64, 3]               0\n",
      "           Conv1d-62                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-63                [-1, 64, 3]               0\n",
      "      BatchNorm1d-64                [-1, 64, 3]             128\n",
      "             ReLU-65                [-1, 64, 3]               0\n",
      "          Dropout-66                [-1, 64, 3]               0\n",
      "           Conv1d-67                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-68                [-1, 64, 3]               0\n",
      "       BasicBlock-69                [-1, 64, 3]               0\n",
      "      BatchNorm1d-70                [-1, 64, 3]             128\n",
      "             ReLU-71                [-1, 64, 3]               0\n",
      "          Dropout-72                [-1, 64, 3]               0\n",
      "           Conv1d-73                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-74                [-1, 64, 3]               0\n",
      "      BatchNorm1d-75                [-1, 64, 3]             128\n",
      "             ReLU-76                [-1, 64, 3]               0\n",
      "          Dropout-77                [-1, 64, 3]               0\n",
      "           Conv1d-78                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-79                [-1, 64, 3]               0\n",
      "       BasicBlock-80                [-1, 64, 3]               0\n",
      "      BatchNorm1d-81                [-1, 64, 3]             128\n",
      "             ReLU-82                [-1, 64, 3]               0\n",
      "          Dropout-83                [-1, 64, 3]               0\n",
      "           Conv1d-84                [-1, 64, 2]          65,600\n",
      "  MyConv1dPadSame-85                [-1, 64, 2]               0\n",
      "      BatchNorm1d-86                [-1, 64, 2]             128\n",
      "             ReLU-87                [-1, 64, 2]               0\n",
      "          Dropout-88                [-1, 64, 2]               0\n",
      "           Conv1d-89                [-1, 64, 2]          65,600\n",
      "  MyConv1dPadSame-90                [-1, 64, 2]               0\n",
      "        MaxPool1d-91                [-1, 64, 2]               0\n",
      "MyMaxPool1dPadSame-92                [-1, 64, 2]               0\n",
      "       BasicBlock-93                [-1, 64, 2]               0\n",
      "      BatchNorm1d-94                [-1, 64, 2]             128\n",
      "             ReLU-95                [-1, 64, 2]               0\n",
      "          Dropout-96                [-1, 64, 2]               0\n",
      "           Conv1d-97                [-1, 64, 2]          65,600\n",
      "  MyConv1dPadSame-98                [-1, 64, 2]               0\n",
      "      BatchNorm1d-99                [-1, 64, 2]             128\n",
      "            ReLU-100                [-1, 64, 2]               0\n",
      "         Dropout-101                [-1, 64, 2]               0\n",
      "          Conv1d-102                [-1, 64, 2]          65,600\n",
      " MyConv1dPadSame-103                [-1, 64, 2]               0\n",
      "      BasicBlock-104                [-1, 64, 2]               0\n",
      "     BatchNorm1d-105                [-1, 64, 2]             128\n",
      "            ReLU-106                [-1, 64, 2]               0\n",
      "         Dropout-107                [-1, 64, 2]               0\n",
      "          Conv1d-108                [-1, 64, 2]          65,600\n",
      " MyConv1dPadSame-109                [-1, 64, 2]               0\n",
      "     BatchNorm1d-110                [-1, 64, 2]             128\n",
      "            ReLU-111                [-1, 64, 2]               0\n",
      "         Dropout-112                [-1, 64, 2]               0\n",
      "          Conv1d-113                [-1, 64, 2]          65,600\n",
      " MyConv1dPadSame-114                [-1, 64, 2]               0\n",
      "      BasicBlock-115                [-1, 64, 2]               0\n",
      "     BatchNorm1d-116                [-1, 64, 2]             128\n",
      "            ReLU-117                [-1, 64, 2]               0\n",
      "         Dropout-118                [-1, 64, 2]               0\n",
      "          Conv1d-119                [-1, 64, 2]          65,600\n",
      " MyConv1dPadSame-120                [-1, 64, 2]               0\n",
      "     BatchNorm1d-121                [-1, 64, 2]             128\n",
      "            ReLU-122                [-1, 64, 2]               0\n",
      "         Dropout-123                [-1, 64, 2]               0\n",
      "          Conv1d-124                [-1, 64, 2]          65,600\n",
      " MyConv1dPadSame-125                [-1, 64, 2]               0\n",
      "      BasicBlock-126                [-1, 64, 2]               0\n",
      "     BatchNorm1d-127                [-1, 64, 2]             128\n",
      "            ReLU-128                [-1, 64, 2]               0\n",
      "         Dropout-129                [-1, 64, 2]               0\n",
      "          Conv1d-130                [-1, 64, 2]          65,600\n",
      " MyConv1dPadSame-131                [-1, 64, 2]               0\n",
      "     BatchNorm1d-132                [-1, 64, 2]             128\n",
      "            ReLU-133                [-1, 64, 2]               0\n",
      "         Dropout-134                [-1, 64, 2]               0\n",
      "          Conv1d-135                [-1, 64, 2]          65,600\n",
      " MyConv1dPadSame-136                [-1, 64, 2]               0\n",
      "      BasicBlock-137                [-1, 64, 2]               0\n",
      "     BatchNorm1d-138                [-1, 64, 2]             128\n",
      "            ReLU-139                [-1, 64, 2]               0\n",
      "         Dropout-140                [-1, 64, 2]               0\n",
      "          Conv1d-141               [-1, 128, 2]         131,200\n",
      " MyConv1dPadSame-142               [-1, 128, 2]               0\n",
      "     BatchNorm1d-143               [-1, 128, 2]             256\n",
      "            ReLU-144               [-1, 128, 2]               0\n",
      "         Dropout-145               [-1, 128, 2]               0\n",
      "          Conv1d-146               [-1, 128, 2]         262,272\n",
      " MyConv1dPadSame-147               [-1, 128, 2]               0\n",
      "      BasicBlock-148               [-1, 128, 2]               0\n",
      "     BatchNorm1d-149               [-1, 128, 2]             256\n",
      "            ReLU-150               [-1, 128, 2]               0\n",
      "         Dropout-151               [-1, 128, 2]               0\n",
      "          Conv1d-152               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-153               [-1, 128, 1]               0\n",
      "     BatchNorm1d-154               [-1, 128, 1]             256\n",
      "            ReLU-155               [-1, 128, 1]               0\n",
      "         Dropout-156               [-1, 128, 1]               0\n",
      "          Conv1d-157               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-158               [-1, 128, 1]               0\n",
      "       MaxPool1d-159               [-1, 128, 1]               0\n",
      "MyMaxPool1dPadSame-160               [-1, 128, 1]               0\n",
      "      BasicBlock-161               [-1, 128, 1]               0\n",
      "     BatchNorm1d-162               [-1, 128, 1]             256\n",
      "            ReLU-163               [-1, 128, 1]               0\n",
      "         Dropout-164               [-1, 128, 1]               0\n",
      "          Conv1d-165               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-166               [-1, 128, 1]               0\n",
      "     BatchNorm1d-167               [-1, 128, 1]             256\n",
      "            ReLU-168               [-1, 128, 1]               0\n",
      "         Dropout-169               [-1, 128, 1]               0\n",
      "          Conv1d-170               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-171               [-1, 128, 1]               0\n",
      "      BasicBlock-172               [-1, 128, 1]               0\n",
      "     BatchNorm1d-173               [-1, 128, 1]             256\n",
      "            ReLU-174               [-1, 128, 1]               0\n",
      "         Dropout-175               [-1, 128, 1]               0\n",
      "          Conv1d-176               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-177               [-1, 128, 1]               0\n",
      "     BatchNorm1d-178               [-1, 128, 1]             256\n",
      "            ReLU-179               [-1, 128, 1]               0\n",
      "         Dropout-180               [-1, 128, 1]               0\n",
      "          Conv1d-181               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-182               [-1, 128, 1]               0\n",
      "      BasicBlock-183               [-1, 128, 1]               0\n",
      "     BatchNorm1d-184               [-1, 128, 1]             256\n",
      "            ReLU-185               [-1, 128, 1]               0\n",
      "         Dropout-186               [-1, 128, 1]               0\n",
      "          Conv1d-187               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-188               [-1, 128, 1]               0\n",
      "     BatchNorm1d-189               [-1, 128, 1]             256\n",
      "            ReLU-190               [-1, 128, 1]               0\n",
      "         Dropout-191               [-1, 128, 1]               0\n",
      "          Conv1d-192               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-193               [-1, 128, 1]               0\n",
      "      BasicBlock-194               [-1, 128, 1]               0\n",
      "     BatchNorm1d-195               [-1, 128, 1]             256\n",
      "            ReLU-196               [-1, 128, 1]               0\n",
      "         Dropout-197               [-1, 128, 1]               0\n",
      "          Conv1d-198               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-199               [-1, 128, 1]               0\n",
      "     BatchNorm1d-200               [-1, 128, 1]             256\n",
      "            ReLU-201               [-1, 128, 1]               0\n",
      "         Dropout-202               [-1, 128, 1]               0\n",
      "          Conv1d-203               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-204               [-1, 128, 1]               0\n",
      "      BasicBlock-205               [-1, 128, 1]               0\n",
      "     BatchNorm1d-206               [-1, 128, 1]             256\n",
      "            ReLU-207               [-1, 128, 1]               0\n",
      "         Dropout-208               [-1, 128, 1]               0\n",
      "          Conv1d-209               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-210               [-1, 128, 1]               0\n",
      "     BatchNorm1d-211               [-1, 128, 1]             256\n",
      "            ReLU-212               [-1, 128, 1]               0\n",
      "         Dropout-213               [-1, 128, 1]               0\n",
      "          Conv1d-214               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-215               [-1, 128, 1]               0\n",
      "      BasicBlock-216               [-1, 128, 1]               0\n",
      "     BatchNorm1d-217               [-1, 128, 1]             256\n",
      "            ReLU-218               [-1, 128, 1]               0\n",
      "         Dropout-219               [-1, 128, 1]               0\n",
      "          Conv1d-220               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-221               [-1, 128, 1]               0\n",
      "     BatchNorm1d-222               [-1, 128, 1]             256\n",
      "            ReLU-223               [-1, 128, 1]               0\n",
      "         Dropout-224               [-1, 128, 1]               0\n",
      "          Conv1d-225               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-226               [-1, 128, 1]               0\n",
      "       MaxPool1d-227               [-1, 128, 1]               0\n",
      "MyMaxPool1dPadSame-228               [-1, 128, 1]               0\n",
      "      BasicBlock-229               [-1, 128, 1]               0\n",
      "     BatchNorm1d-230               [-1, 128, 1]             256\n",
      "            ReLU-231               [-1, 128, 1]               0\n",
      "         Dropout-232               [-1, 128, 1]               0\n",
      "          Conv1d-233               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-234               [-1, 128, 1]               0\n",
      "     BatchNorm1d-235               [-1, 128, 1]             256\n",
      "            ReLU-236               [-1, 128, 1]               0\n",
      "         Dropout-237               [-1, 128, 1]               0\n",
      "          Conv1d-238               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-239               [-1, 128, 1]               0\n",
      "      BasicBlock-240               [-1, 128, 1]               0\n",
      "     BatchNorm1d-241               [-1, 128, 1]             256\n",
      "            ReLU-242               [-1, 128, 1]               0\n",
      "         Dropout-243               [-1, 128, 1]               0\n",
      "          Conv1d-244               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-245               [-1, 128, 1]               0\n",
      "     BatchNorm1d-246               [-1, 128, 1]             256\n",
      "            ReLU-247               [-1, 128, 1]               0\n",
      "         Dropout-248               [-1, 128, 1]               0\n",
      "          Conv1d-249               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-250               [-1, 128, 1]               0\n",
      "      BasicBlock-251               [-1, 128, 1]               0\n",
      "     BatchNorm1d-252               [-1, 128, 1]             256\n",
      "            ReLU-253               [-1, 128, 1]               0\n",
      "         Dropout-254               [-1, 128, 1]               0\n",
      "          Conv1d-255               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-256               [-1, 128, 1]               0\n",
      "     BatchNorm1d-257               [-1, 128, 1]             256\n",
      "            ReLU-258               [-1, 128, 1]               0\n",
      "         Dropout-259               [-1, 128, 1]               0\n",
      "          Conv1d-260               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-261               [-1, 128, 1]               0\n",
      "      BasicBlock-262               [-1, 128, 1]               0\n",
      "     BatchNorm1d-263               [-1, 128, 1]             256\n",
      "            ReLU-264               [-1, 128, 1]               0\n",
      "         Dropout-265               [-1, 128, 1]               0\n",
      "          Conv1d-266               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-267               [-1, 128, 1]               0\n",
      "     BatchNorm1d-268               [-1, 128, 1]             256\n",
      "            ReLU-269               [-1, 128, 1]               0\n",
      "         Dropout-270               [-1, 128, 1]               0\n",
      "          Conv1d-271               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-272               [-1, 128, 1]               0\n",
      "      BasicBlock-273               [-1, 128, 1]               0\n",
      "     BatchNorm1d-274               [-1, 128, 1]             256\n",
      "            ReLU-275               [-1, 128, 1]               0\n",
      "         Dropout-276               [-1, 128, 1]               0\n",
      "          Conv1d-277               [-1, 256, 1]         524,544\n",
      " MyConv1dPadSame-278               [-1, 256, 1]               0\n",
      "     BatchNorm1d-279               [-1, 256, 1]             512\n",
      "            ReLU-280               [-1, 256, 1]               0\n",
      "         Dropout-281               [-1, 256, 1]               0\n",
      "          Conv1d-282               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-283               [-1, 256, 1]               0\n",
      "      BasicBlock-284               [-1, 256, 1]               0\n",
      "     BatchNorm1d-285               [-1, 256, 1]             512\n",
      "            ReLU-286               [-1, 256, 1]               0\n",
      "         Dropout-287               [-1, 256, 1]               0\n",
      "          Conv1d-288               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-289               [-1, 256, 1]               0\n",
      "     BatchNorm1d-290               [-1, 256, 1]             512\n",
      "            ReLU-291               [-1, 256, 1]               0\n",
      "         Dropout-292               [-1, 256, 1]               0\n",
      "          Conv1d-293               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-294               [-1, 256, 1]               0\n",
      "       MaxPool1d-295               [-1, 256, 1]               0\n",
      "MyMaxPool1dPadSame-296               [-1, 256, 1]               0\n",
      "      BasicBlock-297               [-1, 256, 1]               0\n",
      "     BatchNorm1d-298               [-1, 256, 1]             512\n",
      "            ReLU-299               [-1, 256, 1]               0\n",
      "         Dropout-300               [-1, 256, 1]               0\n",
      "          Conv1d-301               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-302               [-1, 256, 1]               0\n",
      "     BatchNorm1d-303               [-1, 256, 1]             512\n",
      "            ReLU-304               [-1, 256, 1]               0\n",
      "         Dropout-305               [-1, 256, 1]               0\n",
      "          Conv1d-306               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-307               [-1, 256, 1]               0\n",
      "      BasicBlock-308               [-1, 256, 1]               0\n",
      "     BatchNorm1d-309               [-1, 256, 1]             512\n",
      "            ReLU-310               [-1, 256, 1]               0\n",
      "         Dropout-311               [-1, 256, 1]               0\n",
      "          Conv1d-312               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-313               [-1, 256, 1]               0\n",
      "     BatchNorm1d-314               [-1, 256, 1]             512\n",
      "            ReLU-315               [-1, 256, 1]               0\n",
      "         Dropout-316               [-1, 256, 1]               0\n",
      "          Conv1d-317               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-318               [-1, 256, 1]               0\n",
      "      BasicBlock-319               [-1, 256, 1]               0\n",
      "     BatchNorm1d-320               [-1, 256, 1]             512\n",
      "            ReLU-321               [-1, 256, 1]               0\n",
      "         Dropout-322               [-1, 256, 1]               0\n",
      "          Conv1d-323               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-324               [-1, 256, 1]               0\n",
      "     BatchNorm1d-325               [-1, 256, 1]             512\n",
      "            ReLU-326               [-1, 256, 1]               0\n",
      "         Dropout-327               [-1, 256, 1]               0\n",
      "          Conv1d-328               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-329               [-1, 256, 1]               0\n",
      "      BasicBlock-330               [-1, 256, 1]               0\n",
      "     BatchNorm1d-331               [-1, 256, 1]             512\n",
      "            ReLU-332               [-1, 256, 1]               0\n",
      "         Dropout-333               [-1, 256, 1]               0\n",
      "          Conv1d-334               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-335               [-1, 256, 1]               0\n",
      "     BatchNorm1d-336               [-1, 256, 1]             512\n",
      "            ReLU-337               [-1, 256, 1]               0\n",
      "         Dropout-338               [-1, 256, 1]               0\n",
      "          Conv1d-339               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-340               [-1, 256, 1]               0\n",
      "      BasicBlock-341               [-1, 256, 1]               0\n",
      "     BatchNorm1d-342               [-1, 256, 1]             512\n",
      "            ReLU-343               [-1, 256, 1]               0\n",
      "         Dropout-344               [-1, 256, 1]               0\n",
      "          Conv1d-345               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-346               [-1, 256, 1]               0\n",
      "     BatchNorm1d-347               [-1, 256, 1]             512\n",
      "            ReLU-348               [-1, 256, 1]               0\n",
      "         Dropout-349               [-1, 256, 1]               0\n",
      "          Conv1d-350               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-351               [-1, 256, 1]               0\n",
      "      BasicBlock-352               [-1, 256, 1]               0\n",
      "     BatchNorm1d-353               [-1, 256, 1]             512\n",
      "            ReLU-354               [-1, 256, 1]               0\n",
      "         Dropout-355               [-1, 256, 1]               0\n",
      "          Conv1d-356               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-357               [-1, 256, 1]               0\n",
      "     BatchNorm1d-358               [-1, 256, 1]             512\n",
      "            ReLU-359               [-1, 256, 1]               0\n",
      "         Dropout-360               [-1, 256, 1]               0\n",
      "          Conv1d-361               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-362               [-1, 256, 1]               0\n",
      "       MaxPool1d-363               [-1, 256, 1]               0\n",
      "MyMaxPool1dPadSame-364               [-1, 256, 1]               0\n",
      "      BasicBlock-365               [-1, 256, 1]               0\n",
      "     BatchNorm1d-366               [-1, 256, 1]             512\n",
      "            ReLU-367               [-1, 256, 1]               0\n",
      "         Dropout-368               [-1, 256, 1]               0\n",
      "          Conv1d-369               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-370               [-1, 256, 1]               0\n",
      "     BatchNorm1d-371               [-1, 256, 1]             512\n",
      "            ReLU-372               [-1, 256, 1]               0\n",
      "         Dropout-373               [-1, 256, 1]               0\n",
      "          Conv1d-374               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-375               [-1, 256, 1]               0\n",
      "      BasicBlock-376               [-1, 256, 1]               0\n",
      "     BatchNorm1d-377               [-1, 256, 1]             512\n",
      "            ReLU-378               [-1, 256, 1]               0\n",
      "         Dropout-379               [-1, 256, 1]               0\n",
      "          Conv1d-380               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-381               [-1, 256, 1]               0\n",
      "     BatchNorm1d-382               [-1, 256, 1]             512\n",
      "            ReLU-383               [-1, 256, 1]               0\n",
      "         Dropout-384               [-1, 256, 1]               0\n",
      "          Conv1d-385               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-386               [-1, 256, 1]               0\n",
      "      BasicBlock-387               [-1, 256, 1]               0\n",
      "     BatchNorm1d-388               [-1, 256, 1]             512\n",
      "            ReLU-389               [-1, 256, 1]               0\n",
      "         Dropout-390               [-1, 256, 1]               0\n",
      "          Conv1d-391               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-392               [-1, 256, 1]               0\n",
      "     BatchNorm1d-393               [-1, 256, 1]             512\n",
      "            ReLU-394               [-1, 256, 1]               0\n",
      "         Dropout-395               [-1, 256, 1]               0\n",
      "          Conv1d-396               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-397               [-1, 256, 1]               0\n",
      "      BasicBlock-398               [-1, 256, 1]               0\n",
      "     BatchNorm1d-399               [-1, 256, 1]             512\n",
      "            ReLU-400               [-1, 256, 1]               0\n",
      "         Dropout-401               [-1, 256, 1]               0\n",
      "          Conv1d-402               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-403               [-1, 256, 1]               0\n",
      "     BatchNorm1d-404               [-1, 256, 1]             512\n",
      "            ReLU-405               [-1, 256, 1]               0\n",
      "         Dropout-406               [-1, 256, 1]               0\n",
      "          Conv1d-407               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-408               [-1, 256, 1]               0\n",
      "      BasicBlock-409               [-1, 256, 1]               0\n",
      "     BatchNorm1d-410               [-1, 256, 1]             512\n",
      "            ReLU-411               [-1, 256, 1]               0\n",
      "         Dropout-412               [-1, 256, 1]               0\n",
      "          Conv1d-413               [-1, 512, 1]       2,097,664\n",
      " MyConv1dPadSame-414               [-1, 512, 1]               0\n",
      "     BatchNorm1d-415               [-1, 512, 1]           1,024\n",
      "            ReLU-416               [-1, 512, 1]               0\n",
      "         Dropout-417               [-1, 512, 1]               0\n",
      "          Conv1d-418               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-419               [-1, 512, 1]               0\n",
      "      BasicBlock-420               [-1, 512, 1]               0\n",
      "     BatchNorm1d-421               [-1, 512, 1]           1,024\n",
      "            ReLU-422               [-1, 512, 1]               0\n",
      "         Dropout-423               [-1, 512, 1]               0\n",
      "          Conv1d-424               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-425               [-1, 512, 1]               0\n",
      "     BatchNorm1d-426               [-1, 512, 1]           1,024\n",
      "            ReLU-427               [-1, 512, 1]               0\n",
      "         Dropout-428               [-1, 512, 1]               0\n",
      "          Conv1d-429               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-430               [-1, 512, 1]               0\n",
      "       MaxPool1d-431               [-1, 512, 1]               0\n",
      "MyMaxPool1dPadSame-432               [-1, 512, 1]               0\n",
      "      BasicBlock-433               [-1, 512, 1]               0\n",
      "     BatchNorm1d-434               [-1, 512, 1]           1,024\n",
      "            ReLU-435               [-1, 512, 1]               0\n",
      "         Dropout-436               [-1, 512, 1]               0\n",
      "          Conv1d-437               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-438               [-1, 512, 1]               0\n",
      "     BatchNorm1d-439               [-1, 512, 1]           1,024\n",
      "            ReLU-440               [-1, 512, 1]               0\n",
      "         Dropout-441               [-1, 512, 1]               0\n",
      "          Conv1d-442               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-443               [-1, 512, 1]               0\n",
      "      BasicBlock-444               [-1, 512, 1]               0\n",
      "     BatchNorm1d-445               [-1, 512, 1]           1,024\n",
      "            ReLU-446               [-1, 512, 1]               0\n",
      "         Dropout-447               [-1, 512, 1]               0\n",
      "          Conv1d-448               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-449               [-1, 512, 1]               0\n",
      "     BatchNorm1d-450               [-1, 512, 1]           1,024\n",
      "            ReLU-451               [-1, 512, 1]               0\n",
      "         Dropout-452               [-1, 512, 1]               0\n",
      "          Conv1d-453               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-454               [-1, 512, 1]               0\n",
      "      BasicBlock-455               [-1, 512, 1]               0\n",
      "     BatchNorm1d-456               [-1, 512, 1]           1,024\n",
      "            ReLU-457               [-1, 512, 1]               0\n",
      "         Dropout-458               [-1, 512, 1]               0\n",
      "          Conv1d-459               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-460               [-1, 512, 1]               0\n",
      "     BatchNorm1d-461               [-1, 512, 1]           1,024\n",
      "            ReLU-462               [-1, 512, 1]               0\n",
      "         Dropout-463               [-1, 512, 1]               0\n",
      "          Conv1d-464               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-465               [-1, 512, 1]               0\n",
      "      BasicBlock-466               [-1, 512, 1]               0\n",
      "     BatchNorm1d-467               [-1, 512, 1]           1,024\n",
      "            ReLU-468               [-1, 512, 1]               0\n",
      "         Dropout-469               [-1, 512, 1]               0\n",
      "          Conv1d-470               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-471               [-1, 512, 1]               0\n",
      "     BatchNorm1d-472               [-1, 512, 1]           1,024\n",
      "            ReLU-473               [-1, 512, 1]               0\n",
      "         Dropout-474               [-1, 512, 1]               0\n",
      "          Conv1d-475               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-476               [-1, 512, 1]               0\n",
      "      BasicBlock-477               [-1, 512, 1]               0\n",
      "     BatchNorm1d-478               [-1, 512, 1]           1,024\n",
      "            ReLU-479               [-1, 512, 1]               0\n",
      "         Dropout-480               [-1, 512, 1]               0\n",
      "          Conv1d-481               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-482               [-1, 512, 1]               0\n",
      "     BatchNorm1d-483               [-1, 512, 1]           1,024\n",
      "            ReLU-484               [-1, 512, 1]               0\n",
      "         Dropout-485               [-1, 512, 1]               0\n",
      "          Conv1d-486               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-487               [-1, 512, 1]               0\n",
      "      BasicBlock-488               [-1, 512, 1]               0\n",
      "     BatchNorm1d-489               [-1, 512, 1]           1,024\n",
      "            ReLU-490               [-1, 512, 1]               0\n",
      "         Dropout-491               [-1, 512, 1]               0\n",
      "          Conv1d-492               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-493               [-1, 512, 1]               0\n",
      "     BatchNorm1d-494               [-1, 512, 1]           1,024\n",
      "            ReLU-495               [-1, 512, 1]               0\n",
      "         Dropout-496               [-1, 512, 1]               0\n",
      "          Conv1d-497               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-498               [-1, 512, 1]               0\n",
      "       MaxPool1d-499               [-1, 512, 1]               0\n",
      "MyMaxPool1dPadSame-500               [-1, 512, 1]               0\n",
      "      BasicBlock-501               [-1, 512, 1]               0\n",
      "     BatchNorm1d-502               [-1, 512, 1]           1,024\n",
      "            ReLU-503               [-1, 512, 1]               0\n",
      "         Dropout-504               [-1, 512, 1]               0\n",
      "          Conv1d-505               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-506               [-1, 512, 1]               0\n",
      "     BatchNorm1d-507               [-1, 512, 1]           1,024\n",
      "            ReLU-508               [-1, 512, 1]               0\n",
      "         Dropout-509               [-1, 512, 1]               0\n",
      "          Conv1d-510               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-511               [-1, 512, 1]               0\n",
      "      BasicBlock-512               [-1, 512, 1]               0\n",
      "     BatchNorm1d-513               [-1, 512, 1]           1,024\n",
      "            ReLU-514               [-1, 512, 1]               0\n",
      "         Dropout-515               [-1, 512, 1]               0\n",
      "          Conv1d-516               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-517               [-1, 512, 1]               0\n",
      "     BatchNorm1d-518               [-1, 512, 1]           1,024\n",
      "            ReLU-519               [-1, 512, 1]               0\n",
      "         Dropout-520               [-1, 512, 1]               0\n",
      "          Conv1d-521               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-522               [-1, 512, 1]               0\n",
      "      BasicBlock-523               [-1, 512, 1]               0\n",
      "     BatchNorm1d-524               [-1, 512, 1]           1,024\n",
      "            ReLU-525               [-1, 512, 1]               0\n",
      "         Dropout-526               [-1, 512, 1]               0\n",
      "          Conv1d-527               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-528               [-1, 512, 1]               0\n",
      "     BatchNorm1d-529               [-1, 512, 1]           1,024\n",
      "            ReLU-530               [-1, 512, 1]               0\n",
      "         Dropout-531               [-1, 512, 1]               0\n",
      "          Conv1d-532               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-533               [-1, 512, 1]               0\n",
      "      BasicBlock-534               [-1, 512, 1]               0\n",
      "     BatchNorm1d-535               [-1, 512, 1]           1,024\n",
      "            ReLU-536               [-1, 512, 1]               0\n",
      "         Dropout-537               [-1, 512, 1]               0\n",
      "          Conv1d-538               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-539               [-1, 512, 1]               0\n",
      "     BatchNorm1d-540               [-1, 512, 1]           1,024\n",
      "            ReLU-541               [-1, 512, 1]               0\n",
      "         Dropout-542               [-1, 512, 1]               0\n",
      "          Conv1d-543               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-544               [-1, 512, 1]               0\n",
      "      BasicBlock-545               [-1, 512, 1]               0\n",
      "     BatchNorm1d-546               [-1, 512, 1]           1,024\n",
      "            ReLU-547               [-1, 512, 1]               0\n",
      "          Linear-548                    [-1, 6]           3,078\n",
      "================================================================\n",
      "Total params: 131,045,062\n",
      "Trainable params: 131,045,062\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.14\n",
      "Params size (MB): 499.90\n",
      "Estimated Total Size (MB): 501.03\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# init model\n",
    "model = ResNet1D(\n",
    "    in_channels=WINDOW_SIZE * 2 + 1,\n",
    "    base_filters=64,\n",
    "    kernel_size=16,\n",
    "    stride=2,\n",
    "    n_block=48,\n",
    "    groups=1,  # check this\n",
    "    n_classes=len(classes),\n",
    "    downsample_gap=6,\n",
    "    increasefilter_gap=12,\n",
    "    verbose=False,\n",
    ").to(device)\n",
    "\n",
    "model = model.float()\n",
    "\n",
    "# print a model summary\n",
    "print(summary(model, (WINDOW_SIZE * 2 + 1, 6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer/criterion\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "all_loss = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]/var/folders/3w/lhkpgfc505n81_2vs8svxfpr0000gn/T/ipykernel_79345/2758473732.py:14: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /Users/runner/miniforge3/conda-bld/pytorch-recipe_1647804309932/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  batch = [ torch.Tensor(t).to(device) for t in batch ] # this is the broken line, because dim 1 is variable length\n",
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 4 at dim 1 (got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb Cell 16'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000015?line=0'>1</a>\u001b[0m prog_bar \u001b[39m=\u001b[39m tqdm(trainloader, desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTraining\u001b[39m\u001b[39m'\u001b[39m, leave\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000015?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(prog_bar):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000015?line=2'>3</a>\u001b[0m     x \u001b[39m=\u001b[39m batch[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000015?line=4'>5</a>\u001b[0m     \u001b[39m# squeeze y to flatten predictions into 1d tensor\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/tqdm/std.py?line=1191'>1192</a>\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/tqdm/std.py?line=1193'>1194</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/tqdm/std.py?line=1194'>1195</a>\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/tqdm/std.py?line=1195'>1196</a>\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/tqdm/std.py?line=1196'>1197</a>\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/tqdm/std.py?line=1197'>1198</a>\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=527'>528</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=528'>529</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=529'>530</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=530'>531</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=531'>532</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=532'>533</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=533'>534</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=567'>568</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=568'>569</a>\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=569'>570</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=570'>571</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=571'>572</a>\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py?line=51'>52</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "\u001b[1;32m/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb Cell 10'\u001b[0m in \u001b[0;36mcollate_fn_padd\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000009?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(batch[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000009?line=12'>13</a>\u001b[0m \u001b[39m## padd\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000009?line=13'>14</a>\u001b[0m batch \u001b[39m=\u001b[39m [ torch\u001b[39m.\u001b[39mTensor(t)\u001b[39m.\u001b[39mto(device) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m batch ] \u001b[39m# this is the broken line, because dim 1 is variable length\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000009?line=14'>15</a>\u001b[0m batch \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mrnn\u001b[39m.\u001b[39mpad_sequence(batch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000009?line=15'>16</a>\u001b[0m \u001b[39m## compute mask\u001b[39;00m\n",
      "\u001b[1;32m/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb Cell 10'\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000009?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(batch[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000009?line=12'>13</a>\u001b[0m \u001b[39m## padd\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000009?line=13'>14</a>\u001b[0m batch \u001b[39m=\u001b[39m [ torch\u001b[39m.\u001b[39;49mTensor(t)\u001b[39m.\u001b[39mto(device) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m batch ] \u001b[39m# this is the broken line, because dim 1 is variable length\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000009?line=14'>15</a>\u001b[0m batch \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mrnn\u001b[39m.\u001b[39mpad_sequence(batch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000009?line=15'>16</a>\u001b[0m \u001b[39m## compute mask\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 4 at dim 1 (got 1)"
     ]
    }
   ],
   "source": [
    "prog_bar = tqdm(trainloader, desc='Training', leave=False)\n",
    "for i, batch in enumerate(prog_bar):\n",
    "    x = batch[0].to(device)\n",
    "\n",
    "    # squeeze y to flatten predictions into 1d tensor\n",
    "    y = batch[1].squeeze().to(device)\n",
    "\n",
    "    pred = model(x.float())\n",
    "\n",
    "    loss = criterion(pred, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    all_loss.append(loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "prog_bar = tqdm(testloader, desc=\"Testing\", leave=False)\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(prog_bar):\n",
    "        x = batch[0].to(device)\n",
    "\n",
    "        y = batch[1].squeeze().to(device)\n",
    "\n",
    "        outs = model(x.float())\n",
    "\n",
    "        _, preds = torch.max(outs, 1)\n",
    "\n",
    "        for label, prediction in zip(y, preds):\n",
    "            # convert label and prediction to current vals\n",
    "            label = le.inverse_transform([label])[0]\n",
    "            prediction = le.inverse_transform([prediction])[0]\n",
    "\n",
    "            y_pred.append(prediction)\n",
    "            y_true.append(label)\n",
    "\n",
    "            if label == prediction:\n",
    "                correct_pred[label] += 1  # this may not work\n",
    "            total_pred[label] += 1\n",
    "\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    # because of unbalanced data, we need to not print out any classes that didn't have any labels\n",
    "    if total_pred[classname] != 0:\n",
    "        accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "        print(f\"Accuracy for class: {classname:5s} is {accuracy:.1f} %\")\n",
    "    else:\n",
    "        accuracy = 0.0\n",
    "        print(f\"CLASS NOT IN TEST BATCH: {classname:5s}\")\n",
    "\n",
    "# build conf matrix\n",
    "conf = confusion_matrix(y_true, y_pred, labels=classes)\n",
    "print(conf)\n",
    "\n",
    "# review the classnames here\n",
    "df_cm = pd.DataFrame(\n",
    "    conf / conf.sum(axis=1)[:, np.newaxis], index=[i for i in classes], columns=[i for i in classes]\n",
    ")\n",
    "\n",
    "# classification report\n",
    "acc_report = classification_report(y_true, y_pred)\n",
    "print(acc_report)\n",
    "\n",
    "# display conf matrix\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "plt.xlabel(\"Ground Truths\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.title(label=\"fDOM Peak Detection Ratio Confusion Matrix\")\n",
    "\n",
    "sn.heatmap(df_cm, annot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement displaying metrics\n",
    "f1_score = f1_score(y_true, y_pred, average=None)\n",
    "bal_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "\n",
    "print(f1_score)\n",
    "print(bal_acc)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ed753961bdc37ee89b4275051722ceb8ec0b57b8793db9d189305c313070a7d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('srrw')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
