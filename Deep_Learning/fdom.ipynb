{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Classification of Anomaly Peaks with 1D resnet\n",
    "Using normal train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "from sklearn import preprocessing\n",
    "from resnet import ResNet1D\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torchsummary import summary\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "sys.path.insert(1, \"../\")\n",
    "\n",
    "from datasets import fdomDataset, fdomAugOnlyDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "WINDOW_SIZE = 15 # the size of each data segment\n",
    "TEST_SIZE = 0.10\n",
    "SEED = 42\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to data files\n",
    "fdom_raw_data = (\n",
    "    \"../Data/converted_data/julian_format/fDOM_raw_10.1.2011-9.4.2020.csv\"\n",
    ")\n",
    "stage_raw_data = \"../Data/converted_data/julian_format/stage_10.1.11-1.1.19.csv\"\n",
    "turb_raw_data = (\n",
    "    \"../Data/converted_data/julian_format/turbidity_raw_10.1.2011_9.4.2020.csv\"\n",
    ")\n",
    "\n",
    "fdom_labeled = \"../Data/labeled_data/ground_truths/fDOM/fDOM_all_julian_0k-300k.csv\"\n",
    "\n",
    "fdom_raw_augmented = \"../Data/augmented_data/fdom/unlabeled/unlabeled_fdom.csv\"\n",
    "fdom_labeled_augmented = \"../Data/augmented_data/fdom/labeled/labeled_fdom_peaks.csv\"\n",
    "\n",
    "turb_augmented_raw_data = \"../Data/augmented_data/fdom/unlabeled/unlabeled_turb.csv\"\n",
    "\n",
    "stage_augmented_data_fn = \"../Data/augmented_data/fdom/unlabeled/unlabeled_stage.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# get device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: shape of a sample is incorrect, not adding it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/../Tools/get_candidates.py:221: PeakPropertyWarning: some peaks have a prominence of 0\n",
      "  peaks, props = find_peaks(\n",
      "/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/../Tools/get_candidates.py:335: PeakPropertyWarning: some peaks have a prominence of 0\n",
      "  peaks, props = find_peaks(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n"
     ]
    }
   ],
   "source": [
    "# create dataset\n",
    "classes = [\"NAP\", \"FSK\", \"FPT\", \"PLP\", \"PP\", \"SKP\"]\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "targets = le.fit_transform(classes)\n",
    "\n",
    "# train on class balanced data\n",
    "train_dataset = fdomAugOnlyDataset(\n",
    "    le,\n",
    "    fdom_raw_augmented,\n",
    "    stage_augmented_data_fn,\n",
    "    turb_augmented_raw_data,\n",
    "    fdom_labeled_augmented,\n",
    "    window_size=WINDOW_SIZE\n",
    ")\n",
    "\n",
    "# test on unbalanced data\n",
    "test_dataset = fdomDataset(\n",
    "    le,\n",
    "    fdom_raw_data,\n",
    "    stage_raw_data,\n",
    "    turb_raw_data,\n",
    "    fdom_labeled,\n",
    "    window_size=WINDOW_SIZE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into training/testing\n",
    "This should not be the final iteration, this is just to get initial results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training / testing\n",
    "\n",
    "# create dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1                [-1, 64, 6]          31,808\n",
      "   MyConv1dPadSame-2                [-1, 64, 6]               0\n",
      "       BatchNorm1d-3                [-1, 64, 6]             128\n",
      "              ReLU-4                [-1, 64, 6]               0\n",
      "            Conv1d-5                [-1, 64, 6]          65,600\n",
      "   MyConv1dPadSame-6                [-1, 64, 6]               0\n",
      "       BatchNorm1d-7                [-1, 64, 6]             128\n",
      "              ReLU-8                [-1, 64, 6]               0\n",
      "           Dropout-9                [-1, 64, 6]               0\n",
      "           Conv1d-10                [-1, 64, 6]          65,600\n",
      "  MyConv1dPadSame-11                [-1, 64, 6]               0\n",
      "       BasicBlock-12                [-1, 64, 6]               0\n",
      "      BatchNorm1d-13                [-1, 64, 6]             128\n",
      "             ReLU-14                [-1, 64, 6]               0\n",
      "          Dropout-15                [-1, 64, 6]               0\n",
      "           Conv1d-16                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-17                [-1, 64, 3]               0\n",
      "      BatchNorm1d-18                [-1, 64, 3]             128\n",
      "             ReLU-19                [-1, 64, 3]               0\n",
      "          Dropout-20                [-1, 64, 3]               0\n",
      "           Conv1d-21                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-22                [-1, 64, 3]               0\n",
      "        MaxPool1d-23                [-1, 64, 3]               0\n",
      "MyMaxPool1dPadSame-24                [-1, 64, 3]               0\n",
      "       BasicBlock-25                [-1, 64, 3]               0\n",
      "      BatchNorm1d-26                [-1, 64, 3]             128\n",
      "             ReLU-27                [-1, 64, 3]               0\n",
      "          Dropout-28                [-1, 64, 3]               0\n",
      "           Conv1d-29                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-30                [-1, 64, 3]               0\n",
      "      BatchNorm1d-31                [-1, 64, 3]             128\n",
      "             ReLU-32                [-1, 64, 3]               0\n",
      "          Dropout-33                [-1, 64, 3]               0\n",
      "           Conv1d-34                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-35                [-1, 64, 3]               0\n",
      "       BasicBlock-36                [-1, 64, 3]               0\n",
      "      BatchNorm1d-37                [-1, 64, 3]             128\n",
      "             ReLU-38                [-1, 64, 3]               0\n",
      "          Dropout-39                [-1, 64, 3]               0\n",
      "           Conv1d-40                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-41                [-1, 64, 3]               0\n",
      "      BatchNorm1d-42                [-1, 64, 3]             128\n",
      "             ReLU-43                [-1, 64, 3]               0\n",
      "          Dropout-44                [-1, 64, 3]               0\n",
      "           Conv1d-45                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-46                [-1, 64, 3]               0\n",
      "       BasicBlock-47                [-1, 64, 3]               0\n",
      "      BatchNorm1d-48                [-1, 64, 3]             128\n",
      "             ReLU-49                [-1, 64, 3]               0\n",
      "          Dropout-50                [-1, 64, 3]               0\n",
      "           Conv1d-51                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-52                [-1, 64, 3]               0\n",
      "      BatchNorm1d-53                [-1, 64, 3]             128\n",
      "             ReLU-54                [-1, 64, 3]               0\n",
      "          Dropout-55                [-1, 64, 3]               0\n",
      "           Conv1d-56                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-57                [-1, 64, 3]               0\n",
      "       BasicBlock-58                [-1, 64, 3]               0\n",
      "      BatchNorm1d-59                [-1, 64, 3]             128\n",
      "             ReLU-60                [-1, 64, 3]               0\n",
      "          Dropout-61                [-1, 64, 3]               0\n",
      "           Conv1d-62                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-63                [-1, 64, 3]               0\n",
      "      BatchNorm1d-64                [-1, 64, 3]             128\n",
      "             ReLU-65                [-1, 64, 3]               0\n",
      "          Dropout-66                [-1, 64, 3]               0\n",
      "           Conv1d-67                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-68                [-1, 64, 3]               0\n",
      "       BasicBlock-69                [-1, 64, 3]               0\n",
      "      BatchNorm1d-70                [-1, 64, 3]             128\n",
      "             ReLU-71                [-1, 64, 3]               0\n",
      "          Dropout-72                [-1, 64, 3]               0\n",
      "           Conv1d-73                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-74                [-1, 64, 3]               0\n",
      "      BatchNorm1d-75                [-1, 64, 3]             128\n",
      "             ReLU-76                [-1, 64, 3]               0\n",
      "          Dropout-77                [-1, 64, 3]               0\n",
      "           Conv1d-78                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-79                [-1, 64, 3]               0\n",
      "       BasicBlock-80                [-1, 64, 3]               0\n",
      "      BatchNorm1d-81                [-1, 64, 3]             128\n",
      "             ReLU-82                [-1, 64, 3]               0\n",
      "          Dropout-83                [-1, 64, 3]               0\n",
      "           Conv1d-84                [-1, 64, 2]          65,600\n",
      "  MyConv1dPadSame-85                [-1, 64, 2]               0\n",
      "      BatchNorm1d-86                [-1, 64, 2]             128\n",
      "             ReLU-87                [-1, 64, 2]               0\n",
      "          Dropout-88                [-1, 64, 2]               0\n",
      "           Conv1d-89                [-1, 64, 2]          65,600\n",
      "  MyConv1dPadSame-90                [-1, 64, 2]               0\n",
      "        MaxPool1d-91                [-1, 64, 2]               0\n",
      "MyMaxPool1dPadSame-92                [-1, 64, 2]               0\n",
      "       BasicBlock-93                [-1, 64, 2]               0\n",
      "      BatchNorm1d-94                [-1, 64, 2]             128\n",
      "             ReLU-95                [-1, 64, 2]               0\n",
      "          Dropout-96                [-1, 64, 2]               0\n",
      "           Conv1d-97                [-1, 64, 2]          65,600\n",
      "  MyConv1dPadSame-98                [-1, 64, 2]               0\n",
      "      BatchNorm1d-99                [-1, 64, 2]             128\n",
      "            ReLU-100                [-1, 64, 2]               0\n",
      "         Dropout-101                [-1, 64, 2]               0\n",
      "          Conv1d-102                [-1, 64, 2]          65,600\n",
      " MyConv1dPadSame-103                [-1, 64, 2]               0\n",
      "      BasicBlock-104                [-1, 64, 2]               0\n",
      "     BatchNorm1d-105                [-1, 64, 2]             128\n",
      "            ReLU-106                [-1, 64, 2]               0\n",
      "         Dropout-107                [-1, 64, 2]               0\n",
      "          Conv1d-108                [-1, 64, 2]          65,600\n",
      " MyConv1dPadSame-109                [-1, 64, 2]               0\n",
      "     BatchNorm1d-110                [-1, 64, 2]             128\n",
      "            ReLU-111                [-1, 64, 2]               0\n",
      "         Dropout-112                [-1, 64, 2]               0\n",
      "          Conv1d-113                [-1, 64, 2]          65,600\n",
      " MyConv1dPadSame-114                [-1, 64, 2]               0\n",
      "      BasicBlock-115                [-1, 64, 2]               0\n",
      "     BatchNorm1d-116                [-1, 64, 2]             128\n",
      "            ReLU-117                [-1, 64, 2]               0\n",
      "         Dropout-118                [-1, 64, 2]               0\n",
      "          Conv1d-119                [-1, 64, 2]          65,600\n",
      " MyConv1dPadSame-120                [-1, 64, 2]               0\n",
      "     BatchNorm1d-121                [-1, 64, 2]             128\n",
      "            ReLU-122                [-1, 64, 2]               0\n",
      "         Dropout-123                [-1, 64, 2]               0\n",
      "          Conv1d-124                [-1, 64, 2]          65,600\n",
      " MyConv1dPadSame-125                [-1, 64, 2]               0\n",
      "      BasicBlock-126                [-1, 64, 2]               0\n",
      "     BatchNorm1d-127                [-1, 64, 2]             128\n",
      "            ReLU-128                [-1, 64, 2]               0\n",
      "         Dropout-129                [-1, 64, 2]               0\n",
      "          Conv1d-130                [-1, 64, 2]          65,600\n",
      " MyConv1dPadSame-131                [-1, 64, 2]               0\n",
      "     BatchNorm1d-132                [-1, 64, 2]             128\n",
      "            ReLU-133                [-1, 64, 2]               0\n",
      "         Dropout-134                [-1, 64, 2]               0\n",
      "          Conv1d-135                [-1, 64, 2]          65,600\n",
      " MyConv1dPadSame-136                [-1, 64, 2]               0\n",
      "      BasicBlock-137                [-1, 64, 2]               0\n",
      "     BatchNorm1d-138                [-1, 64, 2]             128\n",
      "            ReLU-139                [-1, 64, 2]               0\n",
      "         Dropout-140                [-1, 64, 2]               0\n",
      "          Conv1d-141               [-1, 128, 2]         131,200\n",
      " MyConv1dPadSame-142               [-1, 128, 2]               0\n",
      "     BatchNorm1d-143               [-1, 128, 2]             256\n",
      "            ReLU-144               [-1, 128, 2]               0\n",
      "         Dropout-145               [-1, 128, 2]               0\n",
      "          Conv1d-146               [-1, 128, 2]         262,272\n",
      " MyConv1dPadSame-147               [-1, 128, 2]               0\n",
      "      BasicBlock-148               [-1, 128, 2]               0\n",
      "     BatchNorm1d-149               [-1, 128, 2]             256\n",
      "            ReLU-150               [-1, 128, 2]               0\n",
      "         Dropout-151               [-1, 128, 2]               0\n",
      "          Conv1d-152               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-153               [-1, 128, 1]               0\n",
      "     BatchNorm1d-154               [-1, 128, 1]             256\n",
      "            ReLU-155               [-1, 128, 1]               0\n",
      "         Dropout-156               [-1, 128, 1]               0\n",
      "          Conv1d-157               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-158               [-1, 128, 1]               0\n",
      "       MaxPool1d-159               [-1, 128, 1]               0\n",
      "MyMaxPool1dPadSame-160               [-1, 128, 1]               0\n",
      "      BasicBlock-161               [-1, 128, 1]               0\n",
      "     BatchNorm1d-162               [-1, 128, 1]             256\n",
      "            ReLU-163               [-1, 128, 1]               0\n",
      "         Dropout-164               [-1, 128, 1]               0\n",
      "          Conv1d-165               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-166               [-1, 128, 1]               0\n",
      "     BatchNorm1d-167               [-1, 128, 1]             256\n",
      "            ReLU-168               [-1, 128, 1]               0\n",
      "         Dropout-169               [-1, 128, 1]               0\n",
      "          Conv1d-170               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-171               [-1, 128, 1]               0\n",
      "      BasicBlock-172               [-1, 128, 1]               0\n",
      "     BatchNorm1d-173               [-1, 128, 1]             256\n",
      "            ReLU-174               [-1, 128, 1]               0\n",
      "         Dropout-175               [-1, 128, 1]               0\n",
      "          Conv1d-176               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-177               [-1, 128, 1]               0\n",
      "     BatchNorm1d-178               [-1, 128, 1]             256\n",
      "            ReLU-179               [-1, 128, 1]               0\n",
      "         Dropout-180               [-1, 128, 1]               0\n",
      "          Conv1d-181               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-182               [-1, 128, 1]               0\n",
      "      BasicBlock-183               [-1, 128, 1]               0\n",
      "     BatchNorm1d-184               [-1, 128, 1]             256\n",
      "            ReLU-185               [-1, 128, 1]               0\n",
      "         Dropout-186               [-1, 128, 1]               0\n",
      "          Conv1d-187               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-188               [-1, 128, 1]               0\n",
      "     BatchNorm1d-189               [-1, 128, 1]             256\n",
      "            ReLU-190               [-1, 128, 1]               0\n",
      "         Dropout-191               [-1, 128, 1]               0\n",
      "          Conv1d-192               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-193               [-1, 128, 1]               0\n",
      "      BasicBlock-194               [-1, 128, 1]               0\n",
      "     BatchNorm1d-195               [-1, 128, 1]             256\n",
      "            ReLU-196               [-1, 128, 1]               0\n",
      "         Dropout-197               [-1, 128, 1]               0\n",
      "          Conv1d-198               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-199               [-1, 128, 1]               0\n",
      "     BatchNorm1d-200               [-1, 128, 1]             256\n",
      "            ReLU-201               [-1, 128, 1]               0\n",
      "         Dropout-202               [-1, 128, 1]               0\n",
      "          Conv1d-203               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-204               [-1, 128, 1]               0\n",
      "      BasicBlock-205               [-1, 128, 1]               0\n",
      "     BatchNorm1d-206               [-1, 128, 1]             256\n",
      "            ReLU-207               [-1, 128, 1]               0\n",
      "         Dropout-208               [-1, 128, 1]               0\n",
      "          Conv1d-209               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-210               [-1, 128, 1]               0\n",
      "     BatchNorm1d-211               [-1, 128, 1]             256\n",
      "            ReLU-212               [-1, 128, 1]               0\n",
      "         Dropout-213               [-1, 128, 1]               0\n",
      "          Conv1d-214               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-215               [-1, 128, 1]               0\n",
      "      BasicBlock-216               [-1, 128, 1]               0\n",
      "     BatchNorm1d-217               [-1, 128, 1]             256\n",
      "            ReLU-218               [-1, 128, 1]               0\n",
      "         Dropout-219               [-1, 128, 1]               0\n",
      "          Conv1d-220               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-221               [-1, 128, 1]               0\n",
      "     BatchNorm1d-222               [-1, 128, 1]             256\n",
      "            ReLU-223               [-1, 128, 1]               0\n",
      "         Dropout-224               [-1, 128, 1]               0\n",
      "          Conv1d-225               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-226               [-1, 128, 1]               0\n",
      "       MaxPool1d-227               [-1, 128, 1]               0\n",
      "MyMaxPool1dPadSame-228               [-1, 128, 1]               0\n",
      "      BasicBlock-229               [-1, 128, 1]               0\n",
      "     BatchNorm1d-230               [-1, 128, 1]             256\n",
      "            ReLU-231               [-1, 128, 1]               0\n",
      "         Dropout-232               [-1, 128, 1]               0\n",
      "          Conv1d-233               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-234               [-1, 128, 1]               0\n",
      "     BatchNorm1d-235               [-1, 128, 1]             256\n",
      "            ReLU-236               [-1, 128, 1]               0\n",
      "         Dropout-237               [-1, 128, 1]               0\n",
      "          Conv1d-238               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-239               [-1, 128, 1]               0\n",
      "      BasicBlock-240               [-1, 128, 1]               0\n",
      "     BatchNorm1d-241               [-1, 128, 1]             256\n",
      "            ReLU-242               [-1, 128, 1]               0\n",
      "         Dropout-243               [-1, 128, 1]               0\n",
      "          Conv1d-244               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-245               [-1, 128, 1]               0\n",
      "     BatchNorm1d-246               [-1, 128, 1]             256\n",
      "            ReLU-247               [-1, 128, 1]               0\n",
      "         Dropout-248               [-1, 128, 1]               0\n",
      "          Conv1d-249               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-250               [-1, 128, 1]               0\n",
      "      BasicBlock-251               [-1, 128, 1]               0\n",
      "     BatchNorm1d-252               [-1, 128, 1]             256\n",
      "            ReLU-253               [-1, 128, 1]               0\n",
      "         Dropout-254               [-1, 128, 1]               0\n",
      "          Conv1d-255               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-256               [-1, 128, 1]               0\n",
      "     BatchNorm1d-257               [-1, 128, 1]             256\n",
      "            ReLU-258               [-1, 128, 1]               0\n",
      "         Dropout-259               [-1, 128, 1]               0\n",
      "          Conv1d-260               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-261               [-1, 128, 1]               0\n",
      "      BasicBlock-262               [-1, 128, 1]               0\n",
      "     BatchNorm1d-263               [-1, 128, 1]             256\n",
      "            ReLU-264               [-1, 128, 1]               0\n",
      "         Dropout-265               [-1, 128, 1]               0\n",
      "          Conv1d-266               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-267               [-1, 128, 1]               0\n",
      "     BatchNorm1d-268               [-1, 128, 1]             256\n",
      "            ReLU-269               [-1, 128, 1]               0\n",
      "         Dropout-270               [-1, 128, 1]               0\n",
      "          Conv1d-271               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-272               [-1, 128, 1]               0\n",
      "      BasicBlock-273               [-1, 128, 1]               0\n",
      "     BatchNorm1d-274               [-1, 128, 1]             256\n",
      "            ReLU-275               [-1, 128, 1]               0\n",
      "         Dropout-276               [-1, 128, 1]               0\n",
      "          Conv1d-277               [-1, 256, 1]         524,544\n",
      " MyConv1dPadSame-278               [-1, 256, 1]               0\n",
      "     BatchNorm1d-279               [-1, 256, 1]             512\n",
      "            ReLU-280               [-1, 256, 1]               0\n",
      "         Dropout-281               [-1, 256, 1]               0\n",
      "          Conv1d-282               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-283               [-1, 256, 1]               0\n",
      "      BasicBlock-284               [-1, 256, 1]               0\n",
      "     BatchNorm1d-285               [-1, 256, 1]             512\n",
      "            ReLU-286               [-1, 256, 1]               0\n",
      "         Dropout-287               [-1, 256, 1]               0\n",
      "          Conv1d-288               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-289               [-1, 256, 1]               0\n",
      "     BatchNorm1d-290               [-1, 256, 1]             512\n",
      "            ReLU-291               [-1, 256, 1]               0\n",
      "         Dropout-292               [-1, 256, 1]               0\n",
      "          Conv1d-293               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-294               [-1, 256, 1]               0\n",
      "       MaxPool1d-295               [-1, 256, 1]               0\n",
      "MyMaxPool1dPadSame-296               [-1, 256, 1]               0\n",
      "      BasicBlock-297               [-1, 256, 1]               0\n",
      "     BatchNorm1d-298               [-1, 256, 1]             512\n",
      "            ReLU-299               [-1, 256, 1]               0\n",
      "         Dropout-300               [-1, 256, 1]               0\n",
      "          Conv1d-301               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-302               [-1, 256, 1]               0\n",
      "     BatchNorm1d-303               [-1, 256, 1]             512\n",
      "            ReLU-304               [-1, 256, 1]               0\n",
      "         Dropout-305               [-1, 256, 1]               0\n",
      "          Conv1d-306               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-307               [-1, 256, 1]               0\n",
      "      BasicBlock-308               [-1, 256, 1]               0\n",
      "     BatchNorm1d-309               [-1, 256, 1]             512\n",
      "            ReLU-310               [-1, 256, 1]               0\n",
      "         Dropout-311               [-1, 256, 1]               0\n",
      "          Conv1d-312               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-313               [-1, 256, 1]               0\n",
      "     BatchNorm1d-314               [-1, 256, 1]             512\n",
      "            ReLU-315               [-1, 256, 1]               0\n",
      "         Dropout-316               [-1, 256, 1]               0\n",
      "          Conv1d-317               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-318               [-1, 256, 1]               0\n",
      "      BasicBlock-319               [-1, 256, 1]               0\n",
      "     BatchNorm1d-320               [-1, 256, 1]             512\n",
      "            ReLU-321               [-1, 256, 1]               0\n",
      "         Dropout-322               [-1, 256, 1]               0\n",
      "          Conv1d-323               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-324               [-1, 256, 1]               0\n",
      "     BatchNorm1d-325               [-1, 256, 1]             512\n",
      "            ReLU-326               [-1, 256, 1]               0\n",
      "         Dropout-327               [-1, 256, 1]               0\n",
      "          Conv1d-328               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-329               [-1, 256, 1]               0\n",
      "      BasicBlock-330               [-1, 256, 1]               0\n",
      "     BatchNorm1d-331               [-1, 256, 1]             512\n",
      "            ReLU-332               [-1, 256, 1]               0\n",
      "         Dropout-333               [-1, 256, 1]               0\n",
      "          Conv1d-334               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-335               [-1, 256, 1]               0\n",
      "     BatchNorm1d-336               [-1, 256, 1]             512\n",
      "            ReLU-337               [-1, 256, 1]               0\n",
      "         Dropout-338               [-1, 256, 1]               0\n",
      "          Conv1d-339               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-340               [-1, 256, 1]               0\n",
      "      BasicBlock-341               [-1, 256, 1]               0\n",
      "     BatchNorm1d-342               [-1, 256, 1]             512\n",
      "            ReLU-343               [-1, 256, 1]               0\n",
      "         Dropout-344               [-1, 256, 1]               0\n",
      "          Conv1d-345               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-346               [-1, 256, 1]               0\n",
      "     BatchNorm1d-347               [-1, 256, 1]             512\n",
      "            ReLU-348               [-1, 256, 1]               0\n",
      "         Dropout-349               [-1, 256, 1]               0\n",
      "          Conv1d-350               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-351               [-1, 256, 1]               0\n",
      "      BasicBlock-352               [-1, 256, 1]               0\n",
      "     BatchNorm1d-353               [-1, 256, 1]             512\n",
      "            ReLU-354               [-1, 256, 1]               0\n",
      "         Dropout-355               [-1, 256, 1]               0\n",
      "          Conv1d-356               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-357               [-1, 256, 1]               0\n",
      "     BatchNorm1d-358               [-1, 256, 1]             512\n",
      "            ReLU-359               [-1, 256, 1]               0\n",
      "         Dropout-360               [-1, 256, 1]               0\n",
      "          Conv1d-361               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-362               [-1, 256, 1]               0\n",
      "       MaxPool1d-363               [-1, 256, 1]               0\n",
      "MyMaxPool1dPadSame-364               [-1, 256, 1]               0\n",
      "      BasicBlock-365               [-1, 256, 1]               0\n",
      "     BatchNorm1d-366               [-1, 256, 1]             512\n",
      "            ReLU-367               [-1, 256, 1]               0\n",
      "         Dropout-368               [-1, 256, 1]               0\n",
      "          Conv1d-369               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-370               [-1, 256, 1]               0\n",
      "     BatchNorm1d-371               [-1, 256, 1]             512\n",
      "            ReLU-372               [-1, 256, 1]               0\n",
      "         Dropout-373               [-1, 256, 1]               0\n",
      "          Conv1d-374               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-375               [-1, 256, 1]               0\n",
      "      BasicBlock-376               [-1, 256, 1]               0\n",
      "     BatchNorm1d-377               [-1, 256, 1]             512\n",
      "            ReLU-378               [-1, 256, 1]               0\n",
      "         Dropout-379               [-1, 256, 1]               0\n",
      "          Conv1d-380               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-381               [-1, 256, 1]               0\n",
      "     BatchNorm1d-382               [-1, 256, 1]             512\n",
      "            ReLU-383               [-1, 256, 1]               0\n",
      "         Dropout-384               [-1, 256, 1]               0\n",
      "          Conv1d-385               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-386               [-1, 256, 1]               0\n",
      "      BasicBlock-387               [-1, 256, 1]               0\n",
      "     BatchNorm1d-388               [-1, 256, 1]             512\n",
      "            ReLU-389               [-1, 256, 1]               0\n",
      "         Dropout-390               [-1, 256, 1]               0\n",
      "          Conv1d-391               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-392               [-1, 256, 1]               0\n",
      "     BatchNorm1d-393               [-1, 256, 1]             512\n",
      "            ReLU-394               [-1, 256, 1]               0\n",
      "         Dropout-395               [-1, 256, 1]               0\n",
      "          Conv1d-396               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-397               [-1, 256, 1]               0\n",
      "      BasicBlock-398               [-1, 256, 1]               0\n",
      "     BatchNorm1d-399               [-1, 256, 1]             512\n",
      "            ReLU-400               [-1, 256, 1]               0\n",
      "         Dropout-401               [-1, 256, 1]               0\n",
      "          Conv1d-402               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-403               [-1, 256, 1]               0\n",
      "     BatchNorm1d-404               [-1, 256, 1]             512\n",
      "            ReLU-405               [-1, 256, 1]               0\n",
      "         Dropout-406               [-1, 256, 1]               0\n",
      "          Conv1d-407               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-408               [-1, 256, 1]               0\n",
      "      BasicBlock-409               [-1, 256, 1]               0\n",
      "     BatchNorm1d-410               [-1, 256, 1]             512\n",
      "            ReLU-411               [-1, 256, 1]               0\n",
      "         Dropout-412               [-1, 256, 1]               0\n",
      "          Conv1d-413               [-1, 512, 1]       2,097,664\n",
      " MyConv1dPadSame-414               [-1, 512, 1]               0\n",
      "     BatchNorm1d-415               [-1, 512, 1]           1,024\n",
      "            ReLU-416               [-1, 512, 1]               0\n",
      "         Dropout-417               [-1, 512, 1]               0\n",
      "          Conv1d-418               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-419               [-1, 512, 1]               0\n",
      "      BasicBlock-420               [-1, 512, 1]               0\n",
      "     BatchNorm1d-421               [-1, 512, 1]           1,024\n",
      "            ReLU-422               [-1, 512, 1]               0\n",
      "         Dropout-423               [-1, 512, 1]               0\n",
      "          Conv1d-424               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-425               [-1, 512, 1]               0\n",
      "     BatchNorm1d-426               [-1, 512, 1]           1,024\n",
      "            ReLU-427               [-1, 512, 1]               0\n",
      "         Dropout-428               [-1, 512, 1]               0\n",
      "          Conv1d-429               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-430               [-1, 512, 1]               0\n",
      "       MaxPool1d-431               [-1, 512, 1]               0\n",
      "MyMaxPool1dPadSame-432               [-1, 512, 1]               0\n",
      "      BasicBlock-433               [-1, 512, 1]               0\n",
      "     BatchNorm1d-434               [-1, 512, 1]           1,024\n",
      "            ReLU-435               [-1, 512, 1]               0\n",
      "         Dropout-436               [-1, 512, 1]               0\n",
      "          Conv1d-437               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-438               [-1, 512, 1]               0\n",
      "     BatchNorm1d-439               [-1, 512, 1]           1,024\n",
      "            ReLU-440               [-1, 512, 1]               0\n",
      "         Dropout-441               [-1, 512, 1]               0\n",
      "          Conv1d-442               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-443               [-1, 512, 1]               0\n",
      "      BasicBlock-444               [-1, 512, 1]               0\n",
      "     BatchNorm1d-445               [-1, 512, 1]           1,024\n",
      "            ReLU-446               [-1, 512, 1]               0\n",
      "         Dropout-447               [-1, 512, 1]               0\n",
      "          Conv1d-448               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-449               [-1, 512, 1]               0\n",
      "     BatchNorm1d-450               [-1, 512, 1]           1,024\n",
      "            ReLU-451               [-1, 512, 1]               0\n",
      "         Dropout-452               [-1, 512, 1]               0\n",
      "          Conv1d-453               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-454               [-1, 512, 1]               0\n",
      "      BasicBlock-455               [-1, 512, 1]               0\n",
      "     BatchNorm1d-456               [-1, 512, 1]           1,024\n",
      "            ReLU-457               [-1, 512, 1]               0\n",
      "         Dropout-458               [-1, 512, 1]               0\n",
      "          Conv1d-459               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-460               [-1, 512, 1]               0\n",
      "     BatchNorm1d-461               [-1, 512, 1]           1,024\n",
      "            ReLU-462               [-1, 512, 1]               0\n",
      "         Dropout-463               [-1, 512, 1]               0\n",
      "          Conv1d-464               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-465               [-1, 512, 1]               0\n",
      "      BasicBlock-466               [-1, 512, 1]               0\n",
      "     BatchNorm1d-467               [-1, 512, 1]           1,024\n",
      "            ReLU-468               [-1, 512, 1]               0\n",
      "         Dropout-469               [-1, 512, 1]               0\n",
      "          Conv1d-470               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-471               [-1, 512, 1]               0\n",
      "     BatchNorm1d-472               [-1, 512, 1]           1,024\n",
      "            ReLU-473               [-1, 512, 1]               0\n",
      "         Dropout-474               [-1, 512, 1]               0\n",
      "          Conv1d-475               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-476               [-1, 512, 1]               0\n",
      "      BasicBlock-477               [-1, 512, 1]               0\n",
      "     BatchNorm1d-478               [-1, 512, 1]           1,024\n",
      "            ReLU-479               [-1, 512, 1]               0\n",
      "         Dropout-480               [-1, 512, 1]               0\n",
      "          Conv1d-481               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-482               [-1, 512, 1]               0\n",
      "     BatchNorm1d-483               [-1, 512, 1]           1,024\n",
      "            ReLU-484               [-1, 512, 1]               0\n",
      "         Dropout-485               [-1, 512, 1]               0\n",
      "          Conv1d-486               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-487               [-1, 512, 1]               0\n",
      "      BasicBlock-488               [-1, 512, 1]               0\n",
      "     BatchNorm1d-489               [-1, 512, 1]           1,024\n",
      "            ReLU-490               [-1, 512, 1]               0\n",
      "         Dropout-491               [-1, 512, 1]               0\n",
      "          Conv1d-492               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-493               [-1, 512, 1]               0\n",
      "     BatchNorm1d-494               [-1, 512, 1]           1,024\n",
      "            ReLU-495               [-1, 512, 1]               0\n",
      "         Dropout-496               [-1, 512, 1]               0\n",
      "          Conv1d-497               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-498               [-1, 512, 1]               0\n",
      "       MaxPool1d-499               [-1, 512, 1]               0\n",
      "MyMaxPool1dPadSame-500               [-1, 512, 1]               0\n",
      "      BasicBlock-501               [-1, 512, 1]               0\n",
      "     BatchNorm1d-502               [-1, 512, 1]           1,024\n",
      "            ReLU-503               [-1, 512, 1]               0\n",
      "         Dropout-504               [-1, 512, 1]               0\n",
      "          Conv1d-505               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-506               [-1, 512, 1]               0\n",
      "     BatchNorm1d-507               [-1, 512, 1]           1,024\n",
      "            ReLU-508               [-1, 512, 1]               0\n",
      "         Dropout-509               [-1, 512, 1]               0\n",
      "          Conv1d-510               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-511               [-1, 512, 1]               0\n",
      "      BasicBlock-512               [-1, 512, 1]               0\n",
      "     BatchNorm1d-513               [-1, 512, 1]           1,024\n",
      "            ReLU-514               [-1, 512, 1]               0\n",
      "         Dropout-515               [-1, 512, 1]               0\n",
      "          Conv1d-516               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-517               [-1, 512, 1]               0\n",
      "     BatchNorm1d-518               [-1, 512, 1]           1,024\n",
      "            ReLU-519               [-1, 512, 1]               0\n",
      "         Dropout-520               [-1, 512, 1]               0\n",
      "          Conv1d-521               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-522               [-1, 512, 1]               0\n",
      "      BasicBlock-523               [-1, 512, 1]               0\n",
      "     BatchNorm1d-524               [-1, 512, 1]           1,024\n",
      "            ReLU-525               [-1, 512, 1]               0\n",
      "         Dropout-526               [-1, 512, 1]               0\n",
      "          Conv1d-527               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-528               [-1, 512, 1]               0\n",
      "     BatchNorm1d-529               [-1, 512, 1]           1,024\n",
      "            ReLU-530               [-1, 512, 1]               0\n",
      "         Dropout-531               [-1, 512, 1]               0\n",
      "          Conv1d-532               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-533               [-1, 512, 1]               0\n",
      "      BasicBlock-534               [-1, 512, 1]               0\n",
      "     BatchNorm1d-535               [-1, 512, 1]           1,024\n",
      "            ReLU-536               [-1, 512, 1]               0\n",
      "         Dropout-537               [-1, 512, 1]               0\n",
      "          Conv1d-538               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-539               [-1, 512, 1]               0\n",
      "     BatchNorm1d-540               [-1, 512, 1]           1,024\n",
      "            ReLU-541               [-1, 512, 1]               0\n",
      "         Dropout-542               [-1, 512, 1]               0\n",
      "          Conv1d-543               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-544               [-1, 512, 1]               0\n",
      "      BasicBlock-545               [-1, 512, 1]               0\n",
      "     BatchNorm1d-546               [-1, 512, 1]           1,024\n",
      "            ReLU-547               [-1, 512, 1]               0\n",
      "          Linear-548                    [-1, 6]           3,078\n",
      "================================================================\n",
      "Total params: 131,045,062\n",
      "Trainable params: 131,045,062\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.14\n",
      "Params size (MB): 499.90\n",
      "Estimated Total Size (MB): 501.03\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# init model\n",
    "model = ResNet1D(\n",
    "    in_channels=WINDOW_SIZE * 2 + 1,\n",
    "    base_filters=64,\n",
    "    kernel_size=16,\n",
    "    stride=2,\n",
    "    n_block=48,\n",
    "    groups=1,  # check this\n",
    "    n_classes=len(classes),\n",
    "    downsample_gap=6,\n",
    "    increasefilter_gap=12,\n",
    "    verbose=False,\n",
    ").to(device)\n",
    "\n",
    "model = model.float()\n",
    "\n",
    "# print a model summary\n",
    "print(summary(model, (WINDOW_SIZE * 2 + 1, 6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer/criterion\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "all_loss = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    }
   ],
   "source": [
    "prog_bar = tqdm(trainloader, desc='Training', leave=False)\n",
    "for i, batch in enumerate(prog_bar):\n",
    "    x = batch[0].to(device)\n",
    "\n",
    "    # squeeze y to flatten predictions into 1d tensor\n",
    "    y = batch[1].squeeze().to(device)\n",
    "\n",
    "    pred = model(x.float())\n",
    "\n",
    "    loss = criterion(pred, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    all_loss.append(loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: NAP   is 5.1 %\n",
      "Accuracy for class: FSK   is 0.0 %\n",
      "Accuracy for class: FPT   is 0.0 %\n",
      "Accuracy for class: PLP   is 15.4 %\n",
      "Accuracy for class: PP    is 45.9 %\n",
      "Accuracy for class: SKP   is 10.3 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         FPT       0.00      0.00      0.00         1\n",
      "         FSK       0.00      0.00      0.00         1\n",
      "         NAP       0.89      0.05      0.10      1518\n",
      "         PLP       0.01      0.15      0.02        26\n",
      "          PP       0.03      0.46      0.06        61\n",
      "         SKP       0.01      0.10      0.02        29\n",
      "\n",
      "    accuracy                           0.07      1636\n",
      "   macro avg       0.16      0.13      0.03      1636\n",
      "weighted avg       0.82      0.07      0.09      1636\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test model\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "prog_bar = tqdm(testloader, desc=\"Testing\", leave=False)\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(prog_bar):\n",
    "        x = batch[0].to(device)\n",
    "\n",
    "        y = batch[1].squeeze().to(device)\n",
    "\n",
    "        outs = model(x.float())\n",
    "\n",
    "        _, preds = torch.max(outs, 1)\n",
    "\n",
    "        for label, prediction in zip(y, preds):\n",
    "            # convert label and prediction to current vals\n",
    "            label = le.inverse_transform([label])[0]\n",
    "            prediction = le.inverse_transform([prediction])[0]\n",
    "\n",
    "            y_pred.append(prediction)\n",
    "            y_true.append(label)\n",
    "\n",
    "            if label == prediction:\n",
    "                correct_pred[label] += 1  # this may not work\n",
    "            total_pred[label] += 1\n",
    "\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    # because of unbalanced data, we need to not print out any classes that didn't have any labels\n",
    "    if total_pred[classname] != 0:\n",
    "        accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "        print(f\"Accuracy for class: {classname:5s} is {accuracy:.1f} %\")\n",
    "    else:\n",
    "        accuracy = 0.0\n",
    "        print(f\"CLASS NOT IN TEST BATCH: {classname:5s}\")\n",
    "\n",
    "# build conf matrix\n",
    "conf = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# review the classnames here\n",
    "df_cm = pd.DataFrame(\n",
    "    conf / np.sum(conf) * 10, index=[i for i in classes], columns=[i for i in classes]\n",
    ")\n",
    "\n",
    "# classification report\n",
    "acc_report = classification_report(y_true, y_pred)\n",
    "print(acc_report)\n",
    "\n",
    "# display conf matrix\n",
    "plt.figure(figsize=(12, 7))\n",
    "sn.heatmap(df_cm, annot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement displaying metrics"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ed753961bdc37ee89b4275051722ceb8ec0b57b8793db9d189305c313070a7d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('srrw')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
