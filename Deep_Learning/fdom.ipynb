{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Classification of Anomaly Peaks with 1D resnet\n",
    "Using normal train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "from sklearn import preprocessing\n",
    "from resnet import ResNet1D\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torchsummary import summary\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, balanced_accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "sys.path.insert(1, \"../\")\n",
    "\n",
    "from datasets import fdomDataset, fdomAugOnlyDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "WINDOW_SIZE = 15 # the size of each data segment\n",
    "TEST_SIZE = 0.10\n",
    "SEED = 42\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to data files\n",
    "fdom_raw_data = (\n",
    "    \"../Data/converted_data/julian_format/fDOM_raw_10.1.2011-9.4.2020.csv\"\n",
    ")\n",
    "stage_raw_data = \"../Data/converted_data/julian_format/stage_10.1.11-1.1.19.csv\"\n",
    "turb_raw_data = (\n",
    "    \"../Data/converted_data/julian_format/turbidity_raw_10.1.2011_9.4.2020.csv\"\n",
    ")\n",
    "\n",
    "fdom_labeled = \"../Data/labeled_data/ground_truths/fDOM/fDOM_all_julian_0k-300k.csv\"\n",
    "\n",
    "fdom_raw_augmented = \"../Data/augmented_data/fdom/unlabeled/unlabeled_fdom.csv\"\n",
    "fdom_labeled_augmented = \"../Data/augmented_data/fdom/labeled/labeled_fdom_peaks.csv\"\n",
    "\n",
    "turb_augmented_raw_data = \"../Data/augmented_data/fdom/unlabeled/unlabeled_turb.csv\"\n",
    "\n",
    "stage_augmented_data_fn = \"../Data/augmented_data/fdom/unlabeled/unlabeled_stage.csv\"\n",
    "\n",
    "fdom_fpt_lookup_path = \"../Data/augmented_data/fdom/fpt_lookup.csv\"\n",
    "fdom_fsk_lookup_path = \"../Data/augmented_data/fdom/fsk_lookup.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# get device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb Cell 7'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000006?line=4'>5</a>\u001b[0m targets \u001b[39m=\u001b[39m le\u001b[39m.\u001b[39mfit_transform(classes)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000006?line=6'>7</a>\u001b[0m \u001b[39m# # train on class balanced data\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000006?line=7'>8</a>\u001b[0m train_dataset \u001b[39m=\u001b[39m fdomAugOnlyDataset(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000006?line=8'>9</a>\u001b[0m     le,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000006?line=9'>10</a>\u001b[0m     fdom_raw_augmented,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000006?line=10'>11</a>\u001b[0m     stage_augmented_data_fn,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000006?line=11'>12</a>\u001b[0m     turb_augmented_raw_data,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000006?line=12'>13</a>\u001b[0m     fdom_labeled_augmented,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000006?line=13'>14</a>\u001b[0m     window_size\u001b[39m=\u001b[39;49mWINDOW_SIZE,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000006?line=14'>15</a>\u001b[0m     fpt_lookup_filename\u001b[39m=\u001b[39;49mfdom_fpt_lookup_path,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000006?line=15'>16</a>\u001b[0m     fsk_lookup_filename\u001b[39m=\u001b[39;49mfdom_fsk_lookup_path,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000006?line=16'>17</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000006?line=18'>19</a>\u001b[0m \u001b[39m# test on unbalanced data\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000006?line=19'>20</a>\u001b[0m test_dataset \u001b[39m=\u001b[39m fdomDataset(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000006?line=20'>21</a>\u001b[0m     le,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000006?line=21'>22</a>\u001b[0m     fdom_raw_data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000006?line=31'>32</a>\u001b[0m     fsk_lookup_filename\u001b[39m=\u001b[39mfdom_fsk_lookup_path,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/fdom.ipynb#ch0000006?line=32'>33</a>\u001b[0m )\n",
      "File \u001b[0;32m~/Projects/srrw-anomaly-detection/Deep_Learning/datasets.py:255\u001b[0m, in \u001b[0;36mfdomAugOnlyDataset.__init__\u001b[0;34m(self, labeler, fdom_augmented_dir, stage_augmented_dir, turb_augmented_dir, fdom_labeled_aug_dir, fpt_lookup_filename, fsk_lookup_filename, window_size)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/datasets.py?line=251'>252</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfsk_lookup_filename \u001b[39m=\u001b[39m fsk_lookup_filename\n\u001b[1;32m    <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/datasets.py?line=253'>254</a>\u001b[0m \u001b[39m# generate the dataset\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/datasets.py?line=254'>255</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_data(window_size)\n",
      "File \u001b[0;32m~/Projects/srrw-anomaly-detection/Deep_Learning/datasets.py:270\u001b[0m, in \u001b[0;36mfdomAugOnlyDataset.get_data\u001b[0;34m(self, window_size)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/datasets.py?line=266'>267</a>\u001b[0m turb_raw \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(dm\u001b[39m.\u001b[39mread_in_timeseries(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mturb_aug_path, \u001b[39mTrue\u001b[39;00m))\n\u001b[1;32m    <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/datasets.py?line=268'>269</a>\u001b[0m \u001b[39m# get all cands from augmented data, augment cands\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/datasets.py?line=269'>270</a>\u001b[0m peaks \u001b[39m=\u001b[39m get_all_cands_fDOM(\n\u001b[1;32m    <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/datasets.py?line=270'>271</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfdom_aug_path,\n\u001b[1;32m    <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/datasets.py?line=271'>272</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfdom_aug_labeled_path,\n\u001b[1;32m    <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/datasets.py?line=272'>273</a>\u001b[0m     \u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/datasets.py?line=273'>274</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfpt_lookup_filename,\n\u001b[1;32m    <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/datasets.py?line=274'>275</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfsk_lookup_filename,\n\u001b[1;32m    <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/datasets.py?line=275'>276</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/datasets.py?line=277'>278</a>\u001b[0m \u001b[39m# get all truths\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/datasets.py?line=278'>279</a>\u001b[0m truths \u001b[39m=\u001b[39m get_all_truths_fDOM(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfdom_aug_labeled_path, \u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Projects/srrw-anomaly-detection/Deep_Learning/../Tools/get_all_cands.py:70\u001b[0m, in \u001b[0;36mget_all_cands_fDOM\u001b[0;34m(raw_fdom_data_filename, truths_filename, is_augmented, fpt_lookup_filename, fsk_lookup_filename)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/../Tools/get_all_cands.py?line=64'>65</a>\u001b[0m cands_fsk \u001b[39m=\u001b[39m gc\u001b[39m.\u001b[39mget_cands_fDOM_FSK(\n\u001b[1;32m     <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/../Tools/get_all_cands.py?line=65'>66</a>\u001b[0m     raw_fdom_data_filename, truths_filename, is_augmented, fsk_lookup_filename\n\u001b[1;32m     <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/../Tools/get_all_cands.py?line=66'>67</a>\u001b[0m )\n\u001b[1;32m     <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/../Tools/get_all_cands.py?line=68'>69</a>\u001b[0m \u001b[39m# concat dataframes\u001b[39;00m\n\u001b[0;32m---> <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/../Tools/get_all_cands.py?line=69'>70</a>\u001b[0m all_cands \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mconcat(\n\u001b[1;32m     <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/../Tools/get_all_cands.py?line=70'>71</a>\u001b[0m     [cands_skp, cands_plp, cands_pp, cands_fpt, cands_fsk, cands_nap]\n\u001b[1;32m     <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/../Tools/get_all_cands.py?line=71'>72</a>\u001b[0m )\n\u001b[1;32m     <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/../Tools/get_all_cands.py?line=73'>74</a>\u001b[0m all_cands \u001b[39m=\u001b[39m all_cands\u001b[39m.\u001b[39msort_values(by\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39midx_of_peak\u001b[39m\u001b[39m\"\u001b[39m], kind\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstable\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/../Tools/get_all_cands.py?line=75'>76</a>\u001b[0m all_cands \u001b[39m=\u001b[39m all_cands\u001b[39m.\u001b[39mset_index(\u001b[39m\"\u001b[39m\u001b[39midx_of_peak\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/pandas/util/_decorators.py?line=304'>305</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/pandas/util/_decorators.py?line=305'>306</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/pandas/util/_decorators.py?line=306'>307</a>\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/pandas/util/_decorators.py?line=307'>308</a>\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/pandas/util/_decorators.py?line=308'>309</a>\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/pandas/util/_decorators.py?line=309'>310</a>\u001b[0m     )\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/pandas/util/_decorators.py?line=310'>311</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/pandas/core/reshape/concat.py:359\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/pandas/core/reshape/concat.py?line=154'>155</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/pandas/core/reshape/concat.py?line=155'>156</a>\u001b[0m \u001b[39mConcatenate pandas objects along a particular axis with optional set logic\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/pandas/core/reshape/concat.py?line=156'>157</a>\u001b[0m \u001b[39malong the other axes.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/pandas/core/reshape/concat.py?line=343'>344</a>\u001b[0m \u001b[39mValueError: Indexes have overlapping values: ['a']\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/pandas/core/reshape/concat.py?line=344'>345</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/pandas/core/reshape/concat.py?line=345'>346</a>\u001b[0m op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/pandas/core/reshape/concat.py?line=346'>347</a>\u001b[0m     objs,\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/pandas/core/reshape/concat.py?line=347'>348</a>\u001b[0m     axis\u001b[39m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/pandas/core/reshape/concat.py?line=355'>356</a>\u001b[0m     sort\u001b[39m=\u001b[39msort,\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/pandas/core/reshape/concat.py?line=356'>357</a>\u001b[0m )\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/pandas/core/reshape/concat.py?line=358'>359</a>\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/pandas/core/reshape/concat.py:588\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/pandas/core/reshape/concat.py?line=585'>586</a>\u001b[0m         obj_labels \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39maxes[\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m ax]\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/pandas/core/reshape/concat.py?line=586'>587</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m new_labels\u001b[39m.\u001b[39mequals(obj_labels):\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/pandas/core/reshape/concat.py?line=587'>588</a>\u001b[0m             indexers[ax] \u001b[39m=\u001b[39m obj_labels\u001b[39m.\u001b[39;49mget_indexer(new_labels)\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/pandas/core/reshape/concat.py?line=589'>590</a>\u001b[0m     mgrs_indexers\u001b[39m.\u001b[39mappend((obj\u001b[39m.\u001b[39m_mgr, indexers))\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/pandas/core/reshape/concat.py?line=591'>592</a>\u001b[0m new_data \u001b[39m=\u001b[39m concatenate_managers(\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/pandas/core/reshape/concat.py?line=592'>593</a>\u001b[0m     mgrs_indexers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnew_axes, concat_axis\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbm_axis, copy\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/pandas/core/reshape/concat.py?line=593'>594</a>\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/pandas/core/indexes/base.py:3721\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=3717'>3718</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_method(method, limit, tolerance)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=3719'>3720</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_as_unique:\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=3720'>3721</a>\u001b[0m     \u001b[39mraise\u001b[39;00m InvalidIndexError(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_requires_unique_msg)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=3722'>3723</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(target) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=3723'>3724</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mintp)\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "# create dataset\n",
    "classes = [\"NAP\", \"FSK\", \"FPT\", \"PLP\", \"PP\", \"SKP\"]\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "targets = le.fit_transform(classes)\n",
    "\n",
    "# # train on class balanced data\n",
    "train_dataset = fdomAugOnlyDataset(\n",
    "    le,\n",
    "    fdom_raw_augmented,\n",
    "    stage_augmented_data_fn,\n",
    "    turb_augmented_raw_data,\n",
    "    fdom_labeled_augmented,\n",
    "    window_size=WINDOW_SIZE,\n",
    "    fpt_lookup_filename=fdom_fpt_lookup_path,\n",
    "    fsk_lookup_filename=fdom_fsk_lookup_path,\n",
    ")\n",
    "\n",
    "# test on unbalanced data\n",
    "test_dataset = fdomDataset(\n",
    "    le,\n",
    "    fdom_raw_data,\n",
    "    stage_raw_data,\n",
    "    turb_raw_data,\n",
    "    fdom_labeled,\n",
    "    # fdom_raw_augmented,\n",
    "    # stage_augmented_data_fn,\n",
    "    # turb_augmented_raw_data,\n",
    "    # fdom_labeled_augmented,\n",
    "    window_size=WINDOW_SIZE,\n",
    "    fpt_lookup_filename=fdom_fpt_lookup_path,\n",
    "    fsk_lookup_filename=fdom_fsk_lookup_path,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into training/testing\n",
    "This should not be the final iteration, this is just to get initial results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training / testing\n",
    "# train_size = int(0.85 * len(dataset))\n",
    "# test_size = len(dataset) - train_size\n",
    "# train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# create dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1                [-1, 64, 6]          31,808\n",
      "   MyConv1dPadSame-2                [-1, 64, 6]               0\n",
      "       BatchNorm1d-3                [-1, 64, 6]             128\n",
      "              ReLU-4                [-1, 64, 6]               0\n",
      "            Conv1d-5                [-1, 64, 6]          65,600\n",
      "   MyConv1dPadSame-6                [-1, 64, 6]               0\n",
      "       BatchNorm1d-7                [-1, 64, 6]             128\n",
      "              ReLU-8                [-1, 64, 6]               0\n",
      "           Dropout-9                [-1, 64, 6]               0\n",
      "           Conv1d-10                [-1, 64, 6]          65,600\n",
      "  MyConv1dPadSame-11                [-1, 64, 6]               0\n",
      "       BasicBlock-12                [-1, 64, 6]               0\n",
      "      BatchNorm1d-13                [-1, 64, 6]             128\n",
      "             ReLU-14                [-1, 64, 6]               0\n",
      "          Dropout-15                [-1, 64, 6]               0\n",
      "           Conv1d-16                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-17                [-1, 64, 3]               0\n",
      "      BatchNorm1d-18                [-1, 64, 3]             128\n",
      "             ReLU-19                [-1, 64, 3]               0\n",
      "          Dropout-20                [-1, 64, 3]               0\n",
      "           Conv1d-21                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-22                [-1, 64, 3]               0\n",
      "        MaxPool1d-23                [-1, 64, 3]               0\n",
      "MyMaxPool1dPadSame-24                [-1, 64, 3]               0\n",
      "       BasicBlock-25                [-1, 64, 3]               0\n",
      "      BatchNorm1d-26                [-1, 64, 3]             128\n",
      "             ReLU-27                [-1, 64, 3]               0\n",
      "          Dropout-28                [-1, 64, 3]               0\n",
      "           Conv1d-29                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-30                [-1, 64, 3]               0\n",
      "      BatchNorm1d-31                [-1, 64, 3]             128\n",
      "             ReLU-32                [-1, 64, 3]               0\n",
      "          Dropout-33                [-1, 64, 3]               0\n",
      "           Conv1d-34                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-35                [-1, 64, 3]               0\n",
      "       BasicBlock-36                [-1, 64, 3]               0\n",
      "      BatchNorm1d-37                [-1, 64, 3]             128\n",
      "             ReLU-38                [-1, 64, 3]               0\n",
      "          Dropout-39                [-1, 64, 3]               0\n",
      "           Conv1d-40                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-41                [-1, 64, 3]               0\n",
      "      BatchNorm1d-42                [-1, 64, 3]             128\n",
      "             ReLU-43                [-1, 64, 3]               0\n",
      "          Dropout-44                [-1, 64, 3]               0\n",
      "           Conv1d-45                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-46                [-1, 64, 3]               0\n",
      "       BasicBlock-47                [-1, 64, 3]               0\n",
      "      BatchNorm1d-48                [-1, 64, 3]             128\n",
      "             ReLU-49                [-1, 64, 3]               0\n",
      "          Dropout-50                [-1, 64, 3]               0\n",
      "           Conv1d-51                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-52                [-1, 64, 3]               0\n",
      "      BatchNorm1d-53                [-1, 64, 3]             128\n",
      "             ReLU-54                [-1, 64, 3]               0\n",
      "          Dropout-55                [-1, 64, 3]               0\n",
      "           Conv1d-56                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-57                [-1, 64, 3]               0\n",
      "       BasicBlock-58                [-1, 64, 3]               0\n",
      "      BatchNorm1d-59                [-1, 64, 3]             128\n",
      "             ReLU-60                [-1, 64, 3]               0\n",
      "          Dropout-61                [-1, 64, 3]               0\n",
      "           Conv1d-62                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-63                [-1, 64, 3]               0\n",
      "      BatchNorm1d-64                [-1, 64, 3]             128\n",
      "             ReLU-65                [-1, 64, 3]               0\n",
      "          Dropout-66                [-1, 64, 3]               0\n",
      "           Conv1d-67                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-68                [-1, 64, 3]               0\n",
      "       BasicBlock-69                [-1, 64, 3]               0\n",
      "      BatchNorm1d-70                [-1, 64, 3]             128\n",
      "             ReLU-71                [-1, 64, 3]               0\n",
      "          Dropout-72                [-1, 64, 3]               0\n",
      "           Conv1d-73                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-74                [-1, 64, 3]               0\n",
      "      BatchNorm1d-75                [-1, 64, 3]             128\n",
      "             ReLU-76                [-1, 64, 3]               0\n",
      "          Dropout-77                [-1, 64, 3]               0\n",
      "           Conv1d-78                [-1, 64, 3]          65,600\n",
      "  MyConv1dPadSame-79                [-1, 64, 3]               0\n",
      "       BasicBlock-80                [-1, 64, 3]               0\n",
      "      BatchNorm1d-81                [-1, 64, 3]             128\n",
      "             ReLU-82                [-1, 64, 3]               0\n",
      "          Dropout-83                [-1, 64, 3]               0\n",
      "           Conv1d-84                [-1, 64, 2]          65,600\n",
      "  MyConv1dPadSame-85                [-1, 64, 2]               0\n",
      "      BatchNorm1d-86                [-1, 64, 2]             128\n",
      "             ReLU-87                [-1, 64, 2]               0\n",
      "          Dropout-88                [-1, 64, 2]               0\n",
      "           Conv1d-89                [-1, 64, 2]          65,600\n",
      "  MyConv1dPadSame-90                [-1, 64, 2]               0\n",
      "        MaxPool1d-91                [-1, 64, 2]               0\n",
      "MyMaxPool1dPadSame-92                [-1, 64, 2]               0\n",
      "       BasicBlock-93                [-1, 64, 2]               0\n",
      "      BatchNorm1d-94                [-1, 64, 2]             128\n",
      "             ReLU-95                [-1, 64, 2]               0\n",
      "          Dropout-96                [-1, 64, 2]               0\n",
      "           Conv1d-97                [-1, 64, 2]          65,600\n",
      "  MyConv1dPadSame-98                [-1, 64, 2]               0\n",
      "      BatchNorm1d-99                [-1, 64, 2]             128\n",
      "            ReLU-100                [-1, 64, 2]               0\n",
      "         Dropout-101                [-1, 64, 2]               0\n",
      "          Conv1d-102                [-1, 64, 2]          65,600\n",
      " MyConv1dPadSame-103                [-1, 64, 2]               0\n",
      "      BasicBlock-104                [-1, 64, 2]               0\n",
      "     BatchNorm1d-105                [-1, 64, 2]             128\n",
      "            ReLU-106                [-1, 64, 2]               0\n",
      "         Dropout-107                [-1, 64, 2]               0\n",
      "          Conv1d-108                [-1, 64, 2]          65,600\n",
      " MyConv1dPadSame-109                [-1, 64, 2]               0\n",
      "     BatchNorm1d-110                [-1, 64, 2]             128\n",
      "            ReLU-111                [-1, 64, 2]               0\n",
      "         Dropout-112                [-1, 64, 2]               0\n",
      "          Conv1d-113                [-1, 64, 2]          65,600\n",
      " MyConv1dPadSame-114                [-1, 64, 2]               0\n",
      "      BasicBlock-115                [-1, 64, 2]               0\n",
      "     BatchNorm1d-116                [-1, 64, 2]             128\n",
      "            ReLU-117                [-1, 64, 2]               0\n",
      "         Dropout-118                [-1, 64, 2]               0\n",
      "          Conv1d-119                [-1, 64, 2]          65,600\n",
      " MyConv1dPadSame-120                [-1, 64, 2]               0\n",
      "     BatchNorm1d-121                [-1, 64, 2]             128\n",
      "            ReLU-122                [-1, 64, 2]               0\n",
      "         Dropout-123                [-1, 64, 2]               0\n",
      "          Conv1d-124                [-1, 64, 2]          65,600\n",
      " MyConv1dPadSame-125                [-1, 64, 2]               0\n",
      "      BasicBlock-126                [-1, 64, 2]               0\n",
      "     BatchNorm1d-127                [-1, 64, 2]             128\n",
      "            ReLU-128                [-1, 64, 2]               0\n",
      "         Dropout-129                [-1, 64, 2]               0\n",
      "          Conv1d-130                [-1, 64, 2]          65,600\n",
      " MyConv1dPadSame-131                [-1, 64, 2]               0\n",
      "     BatchNorm1d-132                [-1, 64, 2]             128\n",
      "            ReLU-133                [-1, 64, 2]               0\n",
      "         Dropout-134                [-1, 64, 2]               0\n",
      "          Conv1d-135                [-1, 64, 2]          65,600\n",
      " MyConv1dPadSame-136                [-1, 64, 2]               0\n",
      "      BasicBlock-137                [-1, 64, 2]               0\n",
      "     BatchNorm1d-138                [-1, 64, 2]             128\n",
      "            ReLU-139                [-1, 64, 2]               0\n",
      "         Dropout-140                [-1, 64, 2]               0\n",
      "          Conv1d-141               [-1, 128, 2]         131,200\n",
      " MyConv1dPadSame-142               [-1, 128, 2]               0\n",
      "     BatchNorm1d-143               [-1, 128, 2]             256\n",
      "            ReLU-144               [-1, 128, 2]               0\n",
      "         Dropout-145               [-1, 128, 2]               0\n",
      "          Conv1d-146               [-1, 128, 2]         262,272\n",
      " MyConv1dPadSame-147               [-1, 128, 2]               0\n",
      "      BasicBlock-148               [-1, 128, 2]               0\n",
      "     BatchNorm1d-149               [-1, 128, 2]             256\n",
      "            ReLU-150               [-1, 128, 2]               0\n",
      "         Dropout-151               [-1, 128, 2]               0\n",
      "          Conv1d-152               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-153               [-1, 128, 1]               0\n",
      "     BatchNorm1d-154               [-1, 128, 1]             256\n",
      "            ReLU-155               [-1, 128, 1]               0\n",
      "         Dropout-156               [-1, 128, 1]               0\n",
      "          Conv1d-157               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-158               [-1, 128, 1]               0\n",
      "       MaxPool1d-159               [-1, 128, 1]               0\n",
      "MyMaxPool1dPadSame-160               [-1, 128, 1]               0\n",
      "      BasicBlock-161               [-1, 128, 1]               0\n",
      "     BatchNorm1d-162               [-1, 128, 1]             256\n",
      "            ReLU-163               [-1, 128, 1]               0\n",
      "         Dropout-164               [-1, 128, 1]               0\n",
      "          Conv1d-165               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-166               [-1, 128, 1]               0\n",
      "     BatchNorm1d-167               [-1, 128, 1]             256\n",
      "            ReLU-168               [-1, 128, 1]               0\n",
      "         Dropout-169               [-1, 128, 1]               0\n",
      "          Conv1d-170               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-171               [-1, 128, 1]               0\n",
      "      BasicBlock-172               [-1, 128, 1]               0\n",
      "     BatchNorm1d-173               [-1, 128, 1]             256\n",
      "            ReLU-174               [-1, 128, 1]               0\n",
      "         Dropout-175               [-1, 128, 1]               0\n",
      "          Conv1d-176               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-177               [-1, 128, 1]               0\n",
      "     BatchNorm1d-178               [-1, 128, 1]             256\n",
      "            ReLU-179               [-1, 128, 1]               0\n",
      "         Dropout-180               [-1, 128, 1]               0\n",
      "          Conv1d-181               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-182               [-1, 128, 1]               0\n",
      "      BasicBlock-183               [-1, 128, 1]               0\n",
      "     BatchNorm1d-184               [-1, 128, 1]             256\n",
      "            ReLU-185               [-1, 128, 1]               0\n",
      "         Dropout-186               [-1, 128, 1]               0\n",
      "          Conv1d-187               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-188               [-1, 128, 1]               0\n",
      "     BatchNorm1d-189               [-1, 128, 1]             256\n",
      "            ReLU-190               [-1, 128, 1]               0\n",
      "         Dropout-191               [-1, 128, 1]               0\n",
      "          Conv1d-192               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-193               [-1, 128, 1]               0\n",
      "      BasicBlock-194               [-1, 128, 1]               0\n",
      "     BatchNorm1d-195               [-1, 128, 1]             256\n",
      "            ReLU-196               [-1, 128, 1]               0\n",
      "         Dropout-197               [-1, 128, 1]               0\n",
      "          Conv1d-198               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-199               [-1, 128, 1]               0\n",
      "     BatchNorm1d-200               [-1, 128, 1]             256\n",
      "            ReLU-201               [-1, 128, 1]               0\n",
      "         Dropout-202               [-1, 128, 1]               0\n",
      "          Conv1d-203               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-204               [-1, 128, 1]               0\n",
      "      BasicBlock-205               [-1, 128, 1]               0\n",
      "     BatchNorm1d-206               [-1, 128, 1]             256\n",
      "            ReLU-207               [-1, 128, 1]               0\n",
      "         Dropout-208               [-1, 128, 1]               0\n",
      "          Conv1d-209               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-210               [-1, 128, 1]               0\n",
      "     BatchNorm1d-211               [-1, 128, 1]             256\n",
      "            ReLU-212               [-1, 128, 1]               0\n",
      "         Dropout-213               [-1, 128, 1]               0\n",
      "          Conv1d-214               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-215               [-1, 128, 1]               0\n",
      "      BasicBlock-216               [-1, 128, 1]               0\n",
      "     BatchNorm1d-217               [-1, 128, 1]             256\n",
      "            ReLU-218               [-1, 128, 1]               0\n",
      "         Dropout-219               [-1, 128, 1]               0\n",
      "          Conv1d-220               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-221               [-1, 128, 1]               0\n",
      "     BatchNorm1d-222               [-1, 128, 1]             256\n",
      "            ReLU-223               [-1, 128, 1]               0\n",
      "         Dropout-224               [-1, 128, 1]               0\n",
      "          Conv1d-225               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-226               [-1, 128, 1]               0\n",
      "       MaxPool1d-227               [-1, 128, 1]               0\n",
      "MyMaxPool1dPadSame-228               [-1, 128, 1]               0\n",
      "      BasicBlock-229               [-1, 128, 1]               0\n",
      "     BatchNorm1d-230               [-1, 128, 1]             256\n",
      "            ReLU-231               [-1, 128, 1]               0\n",
      "         Dropout-232               [-1, 128, 1]               0\n",
      "          Conv1d-233               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-234               [-1, 128, 1]               0\n",
      "     BatchNorm1d-235               [-1, 128, 1]             256\n",
      "            ReLU-236               [-1, 128, 1]               0\n",
      "         Dropout-237               [-1, 128, 1]               0\n",
      "          Conv1d-238               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-239               [-1, 128, 1]               0\n",
      "      BasicBlock-240               [-1, 128, 1]               0\n",
      "     BatchNorm1d-241               [-1, 128, 1]             256\n",
      "            ReLU-242               [-1, 128, 1]               0\n",
      "         Dropout-243               [-1, 128, 1]               0\n",
      "          Conv1d-244               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-245               [-1, 128, 1]               0\n",
      "     BatchNorm1d-246               [-1, 128, 1]             256\n",
      "            ReLU-247               [-1, 128, 1]               0\n",
      "         Dropout-248               [-1, 128, 1]               0\n",
      "          Conv1d-249               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-250               [-1, 128, 1]               0\n",
      "      BasicBlock-251               [-1, 128, 1]               0\n",
      "     BatchNorm1d-252               [-1, 128, 1]             256\n",
      "            ReLU-253               [-1, 128, 1]               0\n",
      "         Dropout-254               [-1, 128, 1]               0\n",
      "          Conv1d-255               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-256               [-1, 128, 1]               0\n",
      "     BatchNorm1d-257               [-1, 128, 1]             256\n",
      "            ReLU-258               [-1, 128, 1]               0\n",
      "         Dropout-259               [-1, 128, 1]               0\n",
      "          Conv1d-260               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-261               [-1, 128, 1]               0\n",
      "      BasicBlock-262               [-1, 128, 1]               0\n",
      "     BatchNorm1d-263               [-1, 128, 1]             256\n",
      "            ReLU-264               [-1, 128, 1]               0\n",
      "         Dropout-265               [-1, 128, 1]               0\n",
      "          Conv1d-266               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-267               [-1, 128, 1]               0\n",
      "     BatchNorm1d-268               [-1, 128, 1]             256\n",
      "            ReLU-269               [-1, 128, 1]               0\n",
      "         Dropout-270               [-1, 128, 1]               0\n",
      "          Conv1d-271               [-1, 128, 1]         262,272\n",
      " MyConv1dPadSame-272               [-1, 128, 1]               0\n",
      "      BasicBlock-273               [-1, 128, 1]               0\n",
      "     BatchNorm1d-274               [-1, 128, 1]             256\n",
      "            ReLU-275               [-1, 128, 1]               0\n",
      "         Dropout-276               [-1, 128, 1]               0\n",
      "          Conv1d-277               [-1, 256, 1]         524,544\n",
      " MyConv1dPadSame-278               [-1, 256, 1]               0\n",
      "     BatchNorm1d-279               [-1, 256, 1]             512\n",
      "            ReLU-280               [-1, 256, 1]               0\n",
      "         Dropout-281               [-1, 256, 1]               0\n",
      "          Conv1d-282               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-283               [-1, 256, 1]               0\n",
      "      BasicBlock-284               [-1, 256, 1]               0\n",
      "     BatchNorm1d-285               [-1, 256, 1]             512\n",
      "            ReLU-286               [-1, 256, 1]               0\n",
      "         Dropout-287               [-1, 256, 1]               0\n",
      "          Conv1d-288               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-289               [-1, 256, 1]               0\n",
      "     BatchNorm1d-290               [-1, 256, 1]             512\n",
      "            ReLU-291               [-1, 256, 1]               0\n",
      "         Dropout-292               [-1, 256, 1]               0\n",
      "          Conv1d-293               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-294               [-1, 256, 1]               0\n",
      "       MaxPool1d-295               [-1, 256, 1]               0\n",
      "MyMaxPool1dPadSame-296               [-1, 256, 1]               0\n",
      "      BasicBlock-297               [-1, 256, 1]               0\n",
      "     BatchNorm1d-298               [-1, 256, 1]             512\n",
      "            ReLU-299               [-1, 256, 1]               0\n",
      "         Dropout-300               [-1, 256, 1]               0\n",
      "          Conv1d-301               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-302               [-1, 256, 1]               0\n",
      "     BatchNorm1d-303               [-1, 256, 1]             512\n",
      "            ReLU-304               [-1, 256, 1]               0\n",
      "         Dropout-305               [-1, 256, 1]               0\n",
      "          Conv1d-306               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-307               [-1, 256, 1]               0\n",
      "      BasicBlock-308               [-1, 256, 1]               0\n",
      "     BatchNorm1d-309               [-1, 256, 1]             512\n",
      "            ReLU-310               [-1, 256, 1]               0\n",
      "         Dropout-311               [-1, 256, 1]               0\n",
      "          Conv1d-312               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-313               [-1, 256, 1]               0\n",
      "     BatchNorm1d-314               [-1, 256, 1]             512\n",
      "            ReLU-315               [-1, 256, 1]               0\n",
      "         Dropout-316               [-1, 256, 1]               0\n",
      "          Conv1d-317               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-318               [-1, 256, 1]               0\n",
      "      BasicBlock-319               [-1, 256, 1]               0\n",
      "     BatchNorm1d-320               [-1, 256, 1]             512\n",
      "            ReLU-321               [-1, 256, 1]               0\n",
      "         Dropout-322               [-1, 256, 1]               0\n",
      "          Conv1d-323               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-324               [-1, 256, 1]               0\n",
      "     BatchNorm1d-325               [-1, 256, 1]             512\n",
      "            ReLU-326               [-1, 256, 1]               0\n",
      "         Dropout-327               [-1, 256, 1]               0\n",
      "          Conv1d-328               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-329               [-1, 256, 1]               0\n",
      "      BasicBlock-330               [-1, 256, 1]               0\n",
      "     BatchNorm1d-331               [-1, 256, 1]             512\n",
      "            ReLU-332               [-1, 256, 1]               0\n",
      "         Dropout-333               [-1, 256, 1]               0\n",
      "          Conv1d-334               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-335               [-1, 256, 1]               0\n",
      "     BatchNorm1d-336               [-1, 256, 1]             512\n",
      "            ReLU-337               [-1, 256, 1]               0\n",
      "         Dropout-338               [-1, 256, 1]               0\n",
      "          Conv1d-339               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-340               [-1, 256, 1]               0\n",
      "      BasicBlock-341               [-1, 256, 1]               0\n",
      "     BatchNorm1d-342               [-1, 256, 1]             512\n",
      "            ReLU-343               [-1, 256, 1]               0\n",
      "         Dropout-344               [-1, 256, 1]               0\n",
      "          Conv1d-345               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-346               [-1, 256, 1]               0\n",
      "     BatchNorm1d-347               [-1, 256, 1]             512\n",
      "            ReLU-348               [-1, 256, 1]               0\n",
      "         Dropout-349               [-1, 256, 1]               0\n",
      "          Conv1d-350               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-351               [-1, 256, 1]               0\n",
      "      BasicBlock-352               [-1, 256, 1]               0\n",
      "     BatchNorm1d-353               [-1, 256, 1]             512\n",
      "            ReLU-354               [-1, 256, 1]               0\n",
      "         Dropout-355               [-1, 256, 1]               0\n",
      "          Conv1d-356               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-357               [-1, 256, 1]               0\n",
      "     BatchNorm1d-358               [-1, 256, 1]             512\n",
      "            ReLU-359               [-1, 256, 1]               0\n",
      "         Dropout-360               [-1, 256, 1]               0\n",
      "          Conv1d-361               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-362               [-1, 256, 1]               0\n",
      "       MaxPool1d-363               [-1, 256, 1]               0\n",
      "MyMaxPool1dPadSame-364               [-1, 256, 1]               0\n",
      "      BasicBlock-365               [-1, 256, 1]               0\n",
      "     BatchNorm1d-366               [-1, 256, 1]             512\n",
      "            ReLU-367               [-1, 256, 1]               0\n",
      "         Dropout-368               [-1, 256, 1]               0\n",
      "          Conv1d-369               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-370               [-1, 256, 1]               0\n",
      "     BatchNorm1d-371               [-1, 256, 1]             512\n",
      "            ReLU-372               [-1, 256, 1]               0\n",
      "         Dropout-373               [-1, 256, 1]               0\n",
      "          Conv1d-374               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-375               [-1, 256, 1]               0\n",
      "      BasicBlock-376               [-1, 256, 1]               0\n",
      "     BatchNorm1d-377               [-1, 256, 1]             512\n",
      "            ReLU-378               [-1, 256, 1]               0\n",
      "         Dropout-379               [-1, 256, 1]               0\n",
      "          Conv1d-380               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-381               [-1, 256, 1]               0\n",
      "     BatchNorm1d-382               [-1, 256, 1]             512\n",
      "            ReLU-383               [-1, 256, 1]               0\n",
      "         Dropout-384               [-1, 256, 1]               0\n",
      "          Conv1d-385               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-386               [-1, 256, 1]               0\n",
      "      BasicBlock-387               [-1, 256, 1]               0\n",
      "     BatchNorm1d-388               [-1, 256, 1]             512\n",
      "            ReLU-389               [-1, 256, 1]               0\n",
      "         Dropout-390               [-1, 256, 1]               0\n",
      "          Conv1d-391               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-392               [-1, 256, 1]               0\n",
      "     BatchNorm1d-393               [-1, 256, 1]             512\n",
      "            ReLU-394               [-1, 256, 1]               0\n",
      "         Dropout-395               [-1, 256, 1]               0\n",
      "          Conv1d-396               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-397               [-1, 256, 1]               0\n",
      "      BasicBlock-398               [-1, 256, 1]               0\n",
      "     BatchNorm1d-399               [-1, 256, 1]             512\n",
      "            ReLU-400               [-1, 256, 1]               0\n",
      "         Dropout-401               [-1, 256, 1]               0\n",
      "          Conv1d-402               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-403               [-1, 256, 1]               0\n",
      "     BatchNorm1d-404               [-1, 256, 1]             512\n",
      "            ReLU-405               [-1, 256, 1]               0\n",
      "         Dropout-406               [-1, 256, 1]               0\n",
      "          Conv1d-407               [-1, 256, 1]       1,048,832\n",
      " MyConv1dPadSame-408               [-1, 256, 1]               0\n",
      "      BasicBlock-409               [-1, 256, 1]               0\n",
      "     BatchNorm1d-410               [-1, 256, 1]             512\n",
      "            ReLU-411               [-1, 256, 1]               0\n",
      "         Dropout-412               [-1, 256, 1]               0\n",
      "          Conv1d-413               [-1, 512, 1]       2,097,664\n",
      " MyConv1dPadSame-414               [-1, 512, 1]               0\n",
      "     BatchNorm1d-415               [-1, 512, 1]           1,024\n",
      "            ReLU-416               [-1, 512, 1]               0\n",
      "         Dropout-417               [-1, 512, 1]               0\n",
      "          Conv1d-418               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-419               [-1, 512, 1]               0\n",
      "      BasicBlock-420               [-1, 512, 1]               0\n",
      "     BatchNorm1d-421               [-1, 512, 1]           1,024\n",
      "            ReLU-422               [-1, 512, 1]               0\n",
      "         Dropout-423               [-1, 512, 1]               0\n",
      "          Conv1d-424               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-425               [-1, 512, 1]               0\n",
      "     BatchNorm1d-426               [-1, 512, 1]           1,024\n",
      "            ReLU-427               [-1, 512, 1]               0\n",
      "         Dropout-428               [-1, 512, 1]               0\n",
      "          Conv1d-429               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-430               [-1, 512, 1]               0\n",
      "       MaxPool1d-431               [-1, 512, 1]               0\n",
      "MyMaxPool1dPadSame-432               [-1, 512, 1]               0\n",
      "      BasicBlock-433               [-1, 512, 1]               0\n",
      "     BatchNorm1d-434               [-1, 512, 1]           1,024\n",
      "            ReLU-435               [-1, 512, 1]               0\n",
      "         Dropout-436               [-1, 512, 1]               0\n",
      "          Conv1d-437               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-438               [-1, 512, 1]               0\n",
      "     BatchNorm1d-439               [-1, 512, 1]           1,024\n",
      "            ReLU-440               [-1, 512, 1]               0\n",
      "         Dropout-441               [-1, 512, 1]               0\n",
      "          Conv1d-442               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-443               [-1, 512, 1]               0\n",
      "      BasicBlock-444               [-1, 512, 1]               0\n",
      "     BatchNorm1d-445               [-1, 512, 1]           1,024\n",
      "            ReLU-446               [-1, 512, 1]               0\n",
      "         Dropout-447               [-1, 512, 1]               0\n",
      "          Conv1d-448               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-449               [-1, 512, 1]               0\n",
      "     BatchNorm1d-450               [-1, 512, 1]           1,024\n",
      "            ReLU-451               [-1, 512, 1]               0\n",
      "         Dropout-452               [-1, 512, 1]               0\n",
      "          Conv1d-453               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-454               [-1, 512, 1]               0\n",
      "      BasicBlock-455               [-1, 512, 1]               0\n",
      "     BatchNorm1d-456               [-1, 512, 1]           1,024\n",
      "            ReLU-457               [-1, 512, 1]               0\n",
      "         Dropout-458               [-1, 512, 1]               0\n",
      "          Conv1d-459               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-460               [-1, 512, 1]               0\n",
      "     BatchNorm1d-461               [-1, 512, 1]           1,024\n",
      "            ReLU-462               [-1, 512, 1]               0\n",
      "         Dropout-463               [-1, 512, 1]               0\n",
      "          Conv1d-464               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-465               [-1, 512, 1]               0\n",
      "      BasicBlock-466               [-1, 512, 1]               0\n",
      "     BatchNorm1d-467               [-1, 512, 1]           1,024\n",
      "            ReLU-468               [-1, 512, 1]               0\n",
      "         Dropout-469               [-1, 512, 1]               0\n",
      "          Conv1d-470               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-471               [-1, 512, 1]               0\n",
      "     BatchNorm1d-472               [-1, 512, 1]           1,024\n",
      "            ReLU-473               [-1, 512, 1]               0\n",
      "         Dropout-474               [-1, 512, 1]               0\n",
      "          Conv1d-475               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-476               [-1, 512, 1]               0\n",
      "      BasicBlock-477               [-1, 512, 1]               0\n",
      "     BatchNorm1d-478               [-1, 512, 1]           1,024\n",
      "            ReLU-479               [-1, 512, 1]               0\n",
      "         Dropout-480               [-1, 512, 1]               0\n",
      "          Conv1d-481               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-482               [-1, 512, 1]               0\n",
      "     BatchNorm1d-483               [-1, 512, 1]           1,024\n",
      "            ReLU-484               [-1, 512, 1]               0\n",
      "         Dropout-485               [-1, 512, 1]               0\n",
      "          Conv1d-486               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-487               [-1, 512, 1]               0\n",
      "      BasicBlock-488               [-1, 512, 1]               0\n",
      "     BatchNorm1d-489               [-1, 512, 1]           1,024\n",
      "            ReLU-490               [-1, 512, 1]               0\n",
      "         Dropout-491               [-1, 512, 1]               0\n",
      "          Conv1d-492               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-493               [-1, 512, 1]               0\n",
      "     BatchNorm1d-494               [-1, 512, 1]           1,024\n",
      "            ReLU-495               [-1, 512, 1]               0\n",
      "         Dropout-496               [-1, 512, 1]               0\n",
      "          Conv1d-497               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-498               [-1, 512, 1]               0\n",
      "       MaxPool1d-499               [-1, 512, 1]               0\n",
      "MyMaxPool1dPadSame-500               [-1, 512, 1]               0\n",
      "      BasicBlock-501               [-1, 512, 1]               0\n",
      "     BatchNorm1d-502               [-1, 512, 1]           1,024\n",
      "            ReLU-503               [-1, 512, 1]               0\n",
      "         Dropout-504               [-1, 512, 1]               0\n",
      "          Conv1d-505               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-506               [-1, 512, 1]               0\n",
      "     BatchNorm1d-507               [-1, 512, 1]           1,024\n",
      "            ReLU-508               [-1, 512, 1]               0\n",
      "         Dropout-509               [-1, 512, 1]               0\n",
      "          Conv1d-510               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-511               [-1, 512, 1]               0\n",
      "      BasicBlock-512               [-1, 512, 1]               0\n",
      "     BatchNorm1d-513               [-1, 512, 1]           1,024\n",
      "            ReLU-514               [-1, 512, 1]               0\n",
      "         Dropout-515               [-1, 512, 1]               0\n",
      "          Conv1d-516               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-517               [-1, 512, 1]               0\n",
      "     BatchNorm1d-518               [-1, 512, 1]           1,024\n",
      "            ReLU-519               [-1, 512, 1]               0\n",
      "         Dropout-520               [-1, 512, 1]               0\n",
      "          Conv1d-521               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-522               [-1, 512, 1]               0\n",
      "      BasicBlock-523               [-1, 512, 1]               0\n",
      "     BatchNorm1d-524               [-1, 512, 1]           1,024\n",
      "            ReLU-525               [-1, 512, 1]               0\n",
      "         Dropout-526               [-1, 512, 1]               0\n",
      "          Conv1d-527               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-528               [-1, 512, 1]               0\n",
      "     BatchNorm1d-529               [-1, 512, 1]           1,024\n",
      "            ReLU-530               [-1, 512, 1]               0\n",
      "         Dropout-531               [-1, 512, 1]               0\n",
      "          Conv1d-532               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-533               [-1, 512, 1]               0\n",
      "      BasicBlock-534               [-1, 512, 1]               0\n",
      "     BatchNorm1d-535               [-1, 512, 1]           1,024\n",
      "            ReLU-536               [-1, 512, 1]               0\n",
      "         Dropout-537               [-1, 512, 1]               0\n",
      "          Conv1d-538               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-539               [-1, 512, 1]               0\n",
      "     BatchNorm1d-540               [-1, 512, 1]           1,024\n",
      "            ReLU-541               [-1, 512, 1]               0\n",
      "         Dropout-542               [-1, 512, 1]               0\n",
      "          Conv1d-543               [-1, 512, 1]       4,194,816\n",
      " MyConv1dPadSame-544               [-1, 512, 1]               0\n",
      "      BasicBlock-545               [-1, 512, 1]               0\n",
      "     BatchNorm1d-546               [-1, 512, 1]           1,024\n",
      "            ReLU-547               [-1, 512, 1]               0\n",
      "          Linear-548                    [-1, 6]           3,078\n",
      "================================================================\n",
      "Total params: 131,045,062\n",
      "Trainable params: 131,045,062\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.14\n",
      "Params size (MB): 499.90\n",
      "Estimated Total Size (MB): 501.03\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# init model\n",
    "model = ResNet1D(\n",
    "    in_channels=WINDOW_SIZE * 2 + 1,\n",
    "    base_filters=64,\n",
    "    kernel_size=16,\n",
    "    stride=2,\n",
    "    n_block=48,\n",
    "    groups=1,  # check this\n",
    "    n_classes=len(classes),\n",
    "    downsample_gap=6,\n",
    "    increasefilter_gap=12,\n",
    "    verbose=False,\n",
    ").to(device)\n",
    "\n",
    "model = model.float()\n",
    "\n",
    "# print a model summary\n",
    "print(summary(model, (WINDOW_SIZE * 2 + 1, 6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer/criterion\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "all_loss = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    }
   ],
   "source": [
    "prog_bar = tqdm(trainloader, desc='Training', leave=False)\n",
    "for i, batch in enumerate(prog_bar):\n",
    "    x = batch[0].to(device)\n",
    "\n",
    "    # squeeze y to flatten predictions into 1d tensor\n",
    "    y = batch[1].squeeze().to(device)\n",
    "\n",
    "    pred = model(x.float())\n",
    "\n",
    "    loss = criterion(pred, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    all_loss.append(loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: NAP   is 23.9 %\n",
      "Accuracy for class: FSK   is 0.0 %\n",
      "Accuracy for class: FPT   is 0.0 %\n",
      "Accuracy for class: PLP   is 30.8 %\n",
      "Accuracy for class: PP    is 27.9 %\n",
      "Accuracy for class: SKP   is 13.8 %\n",
      "[[363   0   0 733 242 180]\n",
      " [  0   0   0   1   0   0]\n",
      " [  0   0   0   0   0   1]\n",
      " [  9   0   0   8   5   4]\n",
      " [ 10   0   0  26  17   8]\n",
      " [  6   0   0  13   6   4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         FPT       0.00      0.00      0.00         1\n",
      "         FSK       0.00      0.00      0.00         1\n",
      "         NAP       0.94      0.24      0.38      1518\n",
      "         PLP       0.01      0.31      0.02        26\n",
      "          PP       0.06      0.28      0.10        61\n",
      "         SKP       0.02      0.14      0.04        29\n",
      "\n",
      "    accuracy                           0.24      1636\n",
      "   macro avg       0.17      0.16      0.09      1636\n",
      "weighted avg       0.87      0.24      0.36      1636\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'fDOM Peak Detection Ratio Confusion Matrix'}>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test model\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "prog_bar = tqdm(testloader, desc=\"Testing\", leave=False)\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(prog_bar):\n",
    "        x = batch[0].to(device)\n",
    "\n",
    "        y = batch[1].squeeze().to(device)\n",
    "\n",
    "        outs = model(x.float())\n",
    "\n",
    "        _, preds = torch.max(outs, 1)\n",
    "\n",
    "        for label, prediction in zip(y, preds):\n",
    "            # convert label and prediction to current vals\n",
    "            label = le.inverse_transform([label])[0]\n",
    "            prediction = le.inverse_transform([prediction])[0]\n",
    "\n",
    "            y_pred.append(prediction)\n",
    "            y_true.append(label)\n",
    "\n",
    "            if label == prediction:\n",
    "                correct_pred[label] += 1  # this may not work\n",
    "            total_pred[label] += 1\n",
    "\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    # because of unbalanced data, we need to not print out any classes that didn't have any labels\n",
    "    if total_pred[classname] != 0:\n",
    "        accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "        print(f\"Accuracy for class: {classname:5s} is {accuracy:.1f} %\")\n",
    "    else:\n",
    "        accuracy = 0.0\n",
    "        print(f\"CLASS NOT IN TEST BATCH: {classname:5s}\")\n",
    "\n",
    "# build conf matrix\n",
    "conf = confusion_matrix(y_true, y_pred, labels=classes)\n",
    "print(conf)\n",
    "\n",
    "# review the classnames here\n",
    "df_cm = pd.DataFrame(\n",
    "    conf / conf.sum(axis=1)[:, np.newaxis], index=[i for i in classes], columns=[i for i in classes]\n",
    ")\n",
    "\n",
    "# classification report\n",
    "acc_report = classification_report(y_true, y_pred)\n",
    "print(acc_report)\n",
    "\n",
    "# display conf matrix\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "plt.xlabel(\"Ground Truths\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.title(label=\"fDOM Peak Detection Ratio Confusion Matrix\")\n",
    "\n",
    "sn.heatmap(df_cm, annot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.38090241 0.01982652 0.10271903 0.03539823]\n",
      "0.16057371692463981\n"
     ]
    }
   ],
   "source": [
    "# TODO: implement displaying metrics\n",
    "f1_score = f1_score(y_true, y_pred, average=None)\n",
    "bal_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "\n",
    "print(f1_score)\n",
    "print(bal_acc)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ed753961bdc37ee89b4275051722ceb8ec0b57b8793db9d189305c313070a7d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('srrw')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
