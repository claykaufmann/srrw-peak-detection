{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import sys\n",
    "from sklearn import preprocessing\n",
    "from resnet import ResNet1D\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torchsummary import summary\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "sys.path.insert(1, \"../\")\n",
    "\n",
    "from datasets import turbAugOnlyDataset\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "WINDOW_SIZE = 15  # the size of each data segment\n",
    "SEED = 42\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# this is the number of epochs per fold, but because data is already batched,\n",
    "#   when larger than 1, training takes a long time\n",
    "EPOCHS = 2\n",
    "\n",
    "SPLITS = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to data files\n",
    "fdom_raw_data = \"../Data/converted_data/julian_format/fDOM_raw_10.1.2011-9.4.2020.csv\"\n",
    "stage_raw_data = \"../Data/converted_data/julian_format/stage_10.1.11-1.1.19.csv\"\n",
    "turb_raw_data = (\n",
    "    \"../Data/converted_data/julian_format/turbidity_raw_10.1.2011_9.4.2020.csv\"\n",
    ")\n",
    "\n",
    "turb_labeled = \"../Data/labeled_data/ground_truths/turb/turb_all_julian_0k-300k.csv\"\n",
    "\n",
    "fdom_raw_augmented = \"../Data/augmented_data/turb/unlabeled/unlabeled_fdom.csv\"\n",
    "turb_labeled_augmented = \"../Data/augmented_data/turb/labeled/labeled_turb_peaks.csv\"\n",
    "\n",
    "turb_augmented_raw_data = \"../Data/augmented_data/turb/unlabeled/unlabeled_turb.csv\"\n",
    "\n",
    "stage_augmented_data_fn = \"../Data/augmented_data/turb/unlabeled/unlabeled_stage.csv\"\n",
    "\n",
    "turb_fpt_lookup_path = \"../Data/augmented_data/turb/fpt_lookup.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# util functions\n",
    "def reset_weights(model):\n",
    "    for layer in model.children():\n",
    "        if hasattr(layer, \"reset_parameters\"):\n",
    "            print(f\"reset trainable params of layer = {layer}\")\n",
    "            layer.reset_parameters()\n",
    "\n",
    "\n",
    "def collate_fn_pad(batch):\n",
    "    \"\"\"\n",
    "    Pads batch of variable length\n",
    "    \"\"\"\n",
    "\n",
    "    label_list, sample_list, lengths = [], [], []\n",
    "\n",
    "    for (sample, label) in batch:\n",
    "        label_list.append(label)\n",
    "        # convert sample to tensor\n",
    "        sample = torch.tensor(\n",
    "            sample, dtype=torch.float64\n",
    "        ).T  # tranpose to send in data, pad_sequences won't accept original\n",
    "\n",
    "        # append to lengths\n",
    "        lengths.append(sample.shape[0])\n",
    "\n",
    "        sample_list.append(sample)\n",
    "\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "\n",
    "    sample_list = torch.nn.utils.rnn.pad_sequence(\n",
    "        sample_list, batch_first=True, padding_value=0\n",
    "    )\n",
    "\n",
    "    # re-tranpose list, so we go back to a 4 channel dataset\n",
    "    sample_list = sample_list.transpose(1, 2)\n",
    "\n",
    "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
    "\n",
    "    return [sample_list.to(device), label_list.to(device), lengths]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"NAP\", \"FPT\", \"PP\", \"SKP\"]\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "targets = le.fit_transform(classes)\n",
    "\n",
    "dataset = turbAugOnlyDataset(\n",
    "    le,\n",
    "    fdom_raw_augmented,\n",
    "    stage_augmented_data_fn,\n",
    "    turb_augmented_raw_data,\n",
    "    turb_labeled_augmented,\n",
    "    turb_fpt_lookup_path,\n",
    "    WINDOW_SIZE,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "results = {}\n",
    "\n",
    "tss = TimeSeriesSplit(SPLITS)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold training\n",
    "conf_matrices = {}\n",
    "accumulated_metrics = {}\n",
    "\n",
    "for fold, (train_ids, test_ids) in enumerate(tss.split(dataset)):\n",
    "    print(f\"FOLD {fold}\")\n",
    "\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        sampler=train_subsampler,\n",
    "        collate_fn=collate_fn_pad,\n",
    "    )\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        sampler=test_subsampler,\n",
    "        collate_fn=collate_fn_pad,\n",
    "    )\n",
    "\n",
    "    # init model\n",
    "    model = ResNet1D(\n",
    "        in_channels=4,\n",
    "        base_filters=64,\n",
    "        kernel_size=16,\n",
    "        stride=2,\n",
    "        n_block=48,\n",
    "        groups=1,  # check this\n",
    "        n_classes=len(classes),\n",
    "        downsample_gap=6,\n",
    "        increasefilter_gap=12,\n",
    "        verbose=False,\n",
    "    ).to(device)\n",
    "\n",
    "    # set model to use float instead of doubles to prevent errors\n",
    "    model = model.float()\n",
    "\n",
    "    # init optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    for epoch in range(0, EPOCHS):\n",
    "        print(f\"Starting epoch {epoch + 1}\")\n",
    "\n",
    "        current_loss = 0\n",
    "\n",
    "        # prog bar\n",
    "        prog_bar = tqdm(trainloader, desc=\"Training\", leave=False)\n",
    "        for i, data in enumerate(prog_bar):\n",
    "            x = data[0].to(device)\n",
    "            y = data[1].squeeze().to(device)\n",
    "\n",
    "            if i == len(prog_bar) - 1:\n",
    "                break\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred = model(x.float())\n",
    "            loss = criterion(pred, y)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print stats\n",
    "            current_loss += loss.item()\n",
    "            if i % 500 == 499:\n",
    "                print(\"Loss after mini-batch %5d: %.3f\" % (i + 1, current_loss / 500))\n",
    "                current_loss = 0.0\n",
    "\n",
    "    # completed training, now test\n",
    "    print(f\"Training for fold {fold} has completed, now testing\")\n",
    "\n",
    "    # save best params\n",
    "    save_path = f\"./results/models/turb/kfold/may-9-model-fold={fold}.pth\"\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "\n",
    "    total, correct = 0, 0\n",
    "\n",
    "    # for checking correct and incorrect preds\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    prog_bar = tqdm(testloader, desc=\"Testing\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(prog_bar):\n",
    "            x = data[0].to(device)\n",
    "            y = data[1].squeeze().to(device)\n",
    "\n",
    "            outputs = model(x.float())\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for label, prediction in zip(y, preds):\n",
    "                # convert label and prediction to current vals\n",
    "                label = le.inverse_transform([label])[0]\n",
    "                prediction = le.inverse_transform([prediction])[0]\n",
    "\n",
    "                # for confusion matrices\n",
    "                y_pred.append(prediction)\n",
    "                y_true.append(label)\n",
    "\n",
    "                if label == prediction:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "\n",
    "        # Print rough general accuracy\n",
    "        print(\"Accuracy for fold %d: %d %%\" % (fold, 100.0 * correct / total))\n",
    "        print(\"--------------------------------\")\n",
    "        results[fold] = 100.0 * (correct / total)\n",
    "\n",
    "        # make classification report\n",
    "        acc_report = classification_report(y_true, y_pred)\n",
    "        print(acc_report)\n",
    "\n",
    "        # get acc score\n",
    "        acc_score = accuracy_score(y_true, y_pred)\n",
    "\n",
    "        bal_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "\n",
    "        f1 = f1_score(\n",
    "            y_true,\n",
    "            y_pred,\n",
    "            average=\"weighted\",\n",
    "        )\n",
    "\n",
    "        precision = precision_score(\n",
    "            y_true,\n",
    "            y_pred,\n",
    "            average=\"weighted\",\n",
    "        )\n",
    "\n",
    "        # make conf matrix\n",
    "        matrix = confusion_matrix(y_true, y_pred, labels=classes)\n",
    "\n",
    "        # save conf matrix\n",
    "        conf_matrices[fold] = copy.deepcopy(matrix)\n",
    "\n",
    "        # save accumulated metrics\n",
    "        accumulated_metrics[fold] = {\n",
    "            \"f1\": f1,\n",
    "            \"acc\": acc_score,\n",
    "            \"ba\": bal_acc,\n",
    "            \"precision\": precision,\n",
    "        }\n",
    "\n",
    "# Print fold results\n",
    "print(\"\\n\")\n",
    "print(f\"K-FOLD CROSS VALIDATION RESULTS FOR {SPLITS} FOLDS\")\n",
    "print(\"--------------------------------\")\n",
    "sum = 0.0\n",
    "for key, value in results.items():\n",
    "    print(f\"Fold {key}: {value} %\")\n",
    "    sum += value\n",
    "print(f\"Average: {sum/len(results.items())} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save accumulated metrics\n",
    "mean_f1 = 0\n",
    "mean_ba = 0\n",
    "mean_precision = 0\n",
    "mean_acc = 0\n",
    "\n",
    "for key in accumulated_metrics:\n",
    "    metrics = accumulated_metrics[key]\n",
    "\n",
    "    mean_f1 += metrics[\"f1\"]\n",
    "    mean_ba += metrics[\"ba\"]\n",
    "    mean_precision += metrics[\"precision\"]\n",
    "    mean_acc += metrics[\"acc\"]\n",
    "\n",
    "print(\"Mean Test F1: \", mean_f1 / len(accumulated_metrics))\n",
    "print(\"Mean Test BA: \", mean_ba / len(accumulated_metrics))\n",
    "print(\"Mean Test Acc: \", mean_acc / len(accumulated_metrics))\n",
    "print(\"Mean Test Precision: \", mean_precision / len(accumulated_metrics))\n",
    "\n",
    "# make mean confusion matrix\n",
    "mean_cfmx = np.zeros((len(classes), len(classes)))\n",
    "for key in conf_matrices.keys():\n",
    "    mean_cfmx += conf_matrices[key]\n",
    "\n",
    "mean_cfmx = mean_cfmx / len(conf_matrices)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(label=\"Turbidity Peak Detection Ratio Confusion Matrix KFold\")\n",
    "\n",
    "sn.set(font_scale=1.5)\n",
    "\n",
    "plot = sn.heatmap(\n",
    "    pd.DataFrame(\n",
    "        mean_cfmx.astype(\"float\") / mean_cfmx.sum(axis=1)[:, np.newaxis],\n",
    "        index=classes,\n",
    "        columns=classes,\n",
    "    ),\n",
    "    annot=True,\n",
    "    annot_kws={\"size\": 16},\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Ground Truths\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.show()\n",
    "\n",
    "plot.get_figure().savefig(\n",
    "    \"./results/graphics/turb/kfold/may-9-conf-ratio-balanced-test.png\"\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(label=\"Turbidity Peak Detection Totals Confusion Matrix KFold\")\n",
    "\n",
    "sn.set(font_scale=1.5)\n",
    "\n",
    "plot = sn.heatmap(\n",
    "    pd.DataFrame(\n",
    "        mean_cfmx,\n",
    "        index=classes,\n",
    "        columns=classes,\n",
    "    ),\n",
    "    annot=True,\n",
    "    annot_kws={\"size\": 16},\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Ground Truths\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.show()\n",
    "\n",
    "plot.get_figure().savefig(\n",
    "    \"./results/graphics/turb/kfold/may-9-conf-totals-balanced-test.png\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ed753961bdc37ee89b4275051722ceb8ec0b57b8793db9d189305c313070a7d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('srrw')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
