{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9719753c-7293-4597-b0f5-426519cfadcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data \n",
    "import datetime\n",
    "import csv\n",
    "import copy\n",
    "import dateutil.parser\n",
    "import sys\n",
    "sys.path.insert(1,'../')\n",
    "import Tools.data_processing as dp\n",
    "# In the future we should use multiple files for annotating as some anomaly types conflict: \n",
    "# Single_point/Plummeting/Skyrocketing/TurbSpike in one file \n",
    "# Titled/3Peak/ NormalPeak in another file \n",
    "# Peak (reguardless of anomlous status) \n",
    "# spikes_fname = '../Data/data_annotating/non_processed_annotated/_.csv'\n",
    "# anomalous_peaks_fname = '../Data/data_annotating/non_processed_annotated/_.csv'\n",
    "# normal_peaks_fname = '../Data/data_annotating/non_processed_annotated/_.csv'\n",
    "\n",
    "# fname1 = '/Users/zachfogg/Desktop/DB-SRRW/Data/manual_annotating_data/annotated_data/turb_pp/turb_PP_Labeled_0k-100k-2.csv'\n",
    "# fname2 = '/Users/zachfogg/Desktop/DB-SRRW/Data/manual_annotating_data/annotated_data/turb_pp/turb_PP_Labeled_100k-200k-2.csv'\n",
    "# fname3 = '/Users/zachfogg/Desktop/DB-SRRW/Data/manual_annotating_data/annotated_data/turb_pp/turb_PP_Labeled_200k-300k-2.csv'\n",
    "# fname1 = \"/Users/zachfogg/Desktop/DB-SRRW/Data/labeled_data/messy_labeled_data/fDOM/fDOM_Plummeting_Peaks/fDOM_plum_0k-100k-labeled.csv\"\n",
    "# fname2 = \"/Users/zachfogg/Desktop/DB-SRRW/Data/labeled_data/messy_labeled_data/fDOM/fDOM_Plummeting_Peaks/fDOM_plum_100k-200k-labeled.csv\"\n",
    "# fname3 = \"/Users/zachfogg/Desktop/DB-SRRW/Data/labeled_data/messy_labeled_data/fDOM/fDOM_Plummeting_Peaks/fDOM_plum_200k-300k-labeled.csv\"\n",
    "fname1 = \"/Users/zachfogg/Desktop/DB-SRRW/Data/labeled_data/messy_labeled_data/fDOM/fDOM_Phantom_Peaks/fDOM_PP_smoothed_0k-100k-labeled.csv\"\n",
    "fname2 = \"/Users/zachfogg/Desktop/DB-SRRW/Data/labeled_data/messy_labeled_data/fDOM/fDOM_Phantom_Peaks/fDOM_PP_smoothed_100k-200k-labeled.csv\"\n",
    "fname3 = \"/Users/zachfogg/Desktop/DB-SRRW/Data/labeled_data/messy_labeled_data/fDOM/fDOM_Phantom_Peaks/fDOM_PP_smoothed_200k-300k-labeled.csv\"\n",
    "# fname1 = '/Users/zachfogg/Desktop/newly_lab_turb_PPP/turb_PPP_0k-100K.csv'\n",
    "# fname2 = '/Users/zachfogg/Desktop/newly_lab_turb_PPP/turb_PPP_100k-200K.csv'\n",
    "# fname3 = '/Users/zachfogg/Desktop/newly_lab_turb_PPP/turb_PPP_200k-300K.csv'\n",
    "# out_file_fname = './data_annotating/processed_annotated/timeseries_0-100000k-annoated.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc69bea3-4d7b-43bb-9074-55c80bab1e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data in fDOM, stage, turb \n",
    "turb_data = []\n",
    "stage_data= []\n",
    "fDOM_data = []\n",
    "with open(fname1, newline='') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ',')\n",
    "    next(csv_reader,None) # skip headers \n",
    "    count = 0\n",
    "    for row in csv_reader: \n",
    "        if count%3 == 0:\n",
    "            fDOM_data.append([row[1],row[2],row[3]])\n",
    "        elif count%3 == 1:\n",
    "            stage_data.append([row[1],row[2],row[3]])\n",
    "        elif count%3 == 2:\n",
    "            turb_data.append([row[1],row[2],row[3]])\n",
    "        count +=1 \n",
    "    csv_file.close()\n",
    "with open(fname2, newline='') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ',')\n",
    "    next(csv_reader,None) # skip headers \n",
    "    count = 0\n",
    "    for row in csv_reader: \n",
    "        if count%3 == 0:\n",
    "            fDOM_data.append([row[1],row[2],row[3]])\n",
    "        elif count%3 == 1:\n",
    "            stage_data.append([row[1],row[2],row[3]])\n",
    "        elif count%3 == 2:\n",
    "            turb_data.append([row[1],row[2],row[3]])\n",
    "        count +=1 \n",
    "    csv_file.close()\n",
    "with open(fname3, newline='') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ',')\n",
    "    next(csv_reader,None) # skip headers \n",
    "    count = 0\n",
    "    for row in csv_reader: \n",
    "        if count%3 == 0:\n",
    "            fDOM_data.append([row[1],row[2],row[3]])\n",
    "        elif count%3 == 1:\n",
    "            stage_data.append([row[1],row[2],row[3]])\n",
    "        elif count%3 == 2:\n",
    "            turb_data.append([row[1],row[2],row[3]])\n",
    "        count +=1 \n",
    "    csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b21f4ca6-c3b6-4b0e-b198-2eab7edb4908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229620\n",
      "229620\n",
      "229620\n"
     ]
    }
   ],
   "source": [
    "# Check data read\n",
    "print(len(fDOM_data))\n",
    "print(len(turb_data))\n",
    "print(len(stage_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7aa9d740-fa01-49e2-b1eb-fa73e540a802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'left_base', 'NPP', 'right_base', 'PP']\n"
     ]
    }
   ],
   "source": [
    "# Determine lable names \n",
    "discovered = []\n",
    "for row in fDOM_data:\n",
    "    val = row[2]\n",
    "    if val not in discovered:\n",
    "        discovered.append(val)\n",
    "print(discovered)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9dc899d1-1a01-45b7-927b-e6d71f6b39db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229620 229620\n"
     ]
    }
   ],
   "source": [
    "# Merge turb PPP and PP data\n",
    "print(len(turb_data), len(turb_data_PPP))\n",
    "for i,row in enumerate(turb_data_PPP):\n",
    "    if row[2] == 'PPP':\n",
    "        if turb_data[i][2] == 'nt_pp' or turb_data[i][2] == 'sky_dr_st' or turb_data[i][2] == 'PPP':\n",
    "            turb_data[i][2] = 'PPP'\n",
    "        else:\n",
    "            print(turb_data[i],'   ', turb_data_PPP[i])\n",
    "            break\n",
    "    elif row[2] == 'NPP' and turb_data[i][2] != 'nt_pp' and turb_data[i][2] != 'sky_dr_st':\n",
    "        print(turb_data[i],'   ', turb_data_PPP[i])\n",
    "    elif row[2] == 'PP' and turb_data[i][2] != 't_pp' :\n",
    "        print(turb_data[i],'   ', turb_data_PPP[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34f5615-f13b-4a16-853c-6f7b30e0876d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f57e19f3-8187-428b-b614-25817d2403a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "turb_data = [[row[0],row[1],row[2],i] for i,row in enumerate(turb_data)]\n",
    "fDOM_data = [[row[0],row[1],row[2],i] for i,row in enumerate(fDOM_data)]\n",
    "# Filter for entries that have a label \n",
    "fDOM_data_filtered = list(filter(lambda row: row[2] != '', fDOM_data))\n",
    "turb_data_filtered = list(filter(lambda row: row[2] != '', turb_data))\n",
    "\n",
    "# Convert ISO timestamp format to python datetime obj and then string\n",
    "fDOM_data_converted = [[dateutil.parser.isoparse(row[0][:-5]),row[1],row[2],row[3]] for row in fDOM_data_filtered]\n",
    "turb_data_converted = [[dateutil.parser.isoparse(row[0][:-5]),row[1],row[2],row[3]] for row in turb_data_filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "136f288d-c01c-45aa-b330-ee9ae3261a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_base  :  408\n",
      "NPP  :  441\n",
      "right_base  :  409\n",
      "PP  :  73\n"
     ]
    }
   ],
   "source": [
    "num_each = {}\n",
    "for row in fDOM_data_filtered:\n",
    "    if row[2] in num_each:\n",
    "        num_each[row[2]] = num_each[row[2]]+ 1\n",
    "    else:\n",
    "        num_each[row[2]] = 1\n",
    "for key in num_each:\n",
    "    print(key, \" : \", num_each[key])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "352cff87-584b-46c8-8d49-af502d1a25d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map to convert label names\n",
    "# map_labels = {'intf' : 'NPLP', 'nplum_nintf' : 'NPLP', 'plum' : 'PLP'}\n",
    "map_labels = {'NPP' : 'NPP', 'PP' : 'PP'}\n",
    "\n",
    "\n",
    "\n",
    "relevant_points = list(map_labels.keys())\n",
    "out_f = '../Data/labeled_data/ground_truths/fDOM/fDOM_Phantom_Peaks/julian_time/fDOM_PP_0k-300k.csv'\n",
    "\n",
    "fDOM_data_final = list(filter(lambda row: row[2] in relevant_points, fDOM_data_converted))\n",
    "\n",
    "with open(out_f, 'w', newline = '') as f: \n",
    "    writer = csv.writer(f, delimiter = ',')\n",
    "    writer.writerow(['timestamp_of_peak', 'value_of_peak','label_of_peak','idx_of_peak'])\n",
    "    for row in fDOM_data_final:\n",
    "        writer.writerow([dp.datetime_to_julian(row[0]), row[1], map_labels[row[2]], row[3]])\n",
    "    f.close()\n",
    "    \n",
    "# Write out turb pp lables: [timestamp, indx, label]\n",
    "out_f = '../Data/labeled_data/ground_truths/fDOM/fDOM_Phantom_Peaks/datetime/fDOM_PP_0k-300k.csv'\n",
    "# Filter to just pp and npp \n",
    "with open(out_f, 'w', newline = '') as f: \n",
    "    writer = csv.writer(f, delimiter = ',')\n",
    "    writer.writerow(['timestamp_of_peak', 'value_of_peak','label_of_peak','idx_of_peak'])\n",
    "    for row in fDOM_data_final:\n",
    "        writer.writerow([row[0],row[1],map_labels[row[2]],row[3]])\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
