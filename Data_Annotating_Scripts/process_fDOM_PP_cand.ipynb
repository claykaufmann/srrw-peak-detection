{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea423583-700f-49d6-a7d2-bc06de1ad219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data \n",
    "import datetime\n",
    "import csv\n",
    "import copy\n",
    "import dateutil.parser\n",
    "import sys\n",
    "sys.path.insert(1,'../')\n",
    "import Tools.data_processing as dp\n",
    "# In the future we should use multiple files for annotating as some anomaly types conflict: \n",
    "# Single_point/Plummeting/Skyrocketing/TurbSpike in one file \n",
    "# Titled/3Peak/ NormalPeak in another file \n",
    "# Peak (reguardless of anomlous status) \n",
    "# spikes_fname = '../Data/data_annotating/non_processed_annotated/_.csv'\n",
    "# anomalous_peaks_fname = '../Data/data_annotating/non_processed_annotated/_.csv'\n",
    "# normal_peaks_fname = '../Data/data_annotating/non_processed_annotated/_.csv'\n",
    "\n",
    "fname1 = '/Users/zachfogg/Desktop/fDOM_cand_0k-100k-labeled_semi_final.csv'\n",
    "fname2 = '/Users/zachfogg/Desktop/fDOM_cand_100k-200k-labeled_semi_final.csv'\n",
    "fname3 = '/Users/zachfogg/Desktop/fDOM_cand_200k-300k-labeled_semi-final.csv'\n",
    "\n",
    "# Separate data in fDOM, stage, turb \n",
    "turb_data = []\n",
    "stage_data= []\n",
    "fDOM_data = []\n",
    "with open(fname1, newline='') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ',')\n",
    "    next(csv_reader,None) # skip headers \n",
    "    count = 0\n",
    "    for row in csv_reader: \n",
    "        if count%3 == 0:\n",
    "            fDOM_data.append([row[1],row[2],row[3]])\n",
    "        elif count%3 == 1:\n",
    "            stage_data.append([row[1],row[2],row[3]])\n",
    "        elif count%3 == 2:\n",
    "            turb_data.append([row[1],row[2],row[3]])\n",
    "        count +=1 \n",
    "    csv_file.close()\n",
    "with open(fname2, newline='') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ',')\n",
    "    next(csv_reader,None) # skip headers \n",
    "    count = 0\n",
    "    for row in csv_reader: \n",
    "        if count%3 == 0:\n",
    "            fDOM_data.append([row[1],row[2],row[3]])\n",
    "        elif count%3 == 1:\n",
    "            stage_data.append([row[1],row[2],row[3]])\n",
    "        elif count%3 == 2:\n",
    "            turb_data.append([row[1],row[2],row[3]])\n",
    "        count +=1 \n",
    "    csv_file.close()\n",
    "with open(fname3, newline='') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ',')\n",
    "    next(csv_reader,None) # skip headers \n",
    "    count = 0\n",
    "    for row in csv_reader: \n",
    "        if count%3 == 0:\n",
    "            fDOM_data.append([row[1],row[2],row[3]])\n",
    "        elif count%3 == 1:\n",
    "            stage_data.append([row[1],row[2],row[3]])\n",
    "        elif count%3 == 2:\n",
    "            turb_data.append([row[1],row[2],row[3]])\n",
    "        count +=1 \n",
    "    csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "896c0132-a132-4fc9-b2f8-5a59ccfc96fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['left_base', 'cand_npp', 'right_base', 'cand_pp', 'shallow_npp', 'ncand_plum', 'ncand_below_fl', 'ncand_shal_plum', 'sky_int_staRise']\n"
     ]
    }
   ],
   "source": [
    "# Determine lable names \n",
    "discovered = []\n",
    "for row in fDOM_data_filtered:\n",
    "    val = row[2]\n",
    "    if val not in discovered:\n",
    "        discovered.append(val)\n",
    "print(discovered)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "373ace19-2b0a-4fc0-9778-d00f12223dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_base  :  693\n",
      "cand_npp  :  341\n",
      "right_base  :  806\n",
      "cand_pp  :  342\n",
      "shallow_npp  :  40\n",
      "ncand_plum  :  14\n",
      "ncand_below_fl  :  50\n",
      "ncand_shal_plum  :  22\n",
      "sky_int_staRise  :  7\n"
     ]
    }
   ],
   "source": [
    "num_each = {}\n",
    "for row in fDOM_data_filtered:\n",
    "    if row[2] in num_each:\n",
    "        num_each[row[2]] = num_each[row[2]]+ 1\n",
    "    else:\n",
    "        num_each[row[2]] = 1\n",
    "for key in num_each:\n",
    "    print(key, \" : \", num_each[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eae51cf9-7460-4157-93b6-428329dc7b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "fDOM_data = [[row[0],row[1],row[2],i] for i,row in enumerate(fDOM_data)]\n",
    "# Filter for entries that have a label \n",
    "fDOM_data_filtered = list(filter(lambda row: row[2] != '', fDOM_data))\n",
    "fDOM_data_filtered = list(filter(lambda row: row[2] != 'remove', fDOM_data_filtered))\n",
    "\n",
    "# Convert ISO timestamp format to python datetime obj and then string\n",
    "fDOM_data_converted = [[dateutil.parser.isoparse(row[0][:-5]),row[1],row[2],row[3]] for row in fDOM_data_filtered]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e7bbca61-3f54-40fb-a1b8-8e5aa1adcef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map to convert label names\n",
    "map_labels = {'cand_npp' : 'cand',\n",
    "             'cand_pp': 'cand',\n",
    "             'shallow_npp' :'cand',\n",
    "             'ncand_plum' : 'ncand',\n",
    "             'ncand_below_fl' : 'ncand',\n",
    "             'ncand_shal_plum' :'ncand',\n",
    "             'sky_int_staRise' :'ncand'} \n",
    "\n",
    "relevant_points = list(map_labels.keys())\n",
    "out_f = '../Data/labeled_data/ground_truths/fDOM/fDOM_PP/julian_time/fDOM_PP_cand_0k-300k.csv'\n",
    "\n",
    "fDOM_data_final = list(filter(lambda row: row[2] in relevant_points, fDOM_data_converted))\n",
    "\n",
    "with open(out_f, 'w', newline = '') as f: \n",
    "    writer = csv.writer(f, delimiter = ',')\n",
    "    writer.writerow(['timestamp_of_peak', 'value_of_peak','label_of_peak','idx_of_peak'])\n",
    "    for row in fDOM_data_final:\n",
    "        writer.writerow([dp.datetime_to_julian(row[0]), row[1], map_labels[row[2]], row[3]])\n",
    "    f.close()\n",
    "    \n",
    "# Write out turb pp lables: [timestamp, indx, label]\n",
    "out_f = '../Data/labeled_data/ground_truths/fDOM/fDOM_PP/datetime/fDOM_PP_cand_0k-300k.csv'\n",
    "\n",
    "# Filter to just pp and npp \n",
    "with open(out_f, 'w', newline = '') as f: \n",
    "    writer = csv.writer(f, delimiter = ',')\n",
    "    writer.writerow(['timestamp_of_peak', 'value_of_peak','label_of_peak','idx_of_peak'])\n",
    "    for row in fDOM_data_final:\n",
    "        writer.writerow([row[0],row[1],map_labels[row[2]],row[3]])\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
