{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn import preprocessing\n",
    "from Anomaly_Detection.Deep_Learning.resnet import ResNet1D\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torchsummary import summary\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from Anomaly_Detection.Deep_Learning.datasets import turbAugOnlyDataset, collate_fn_pad\n",
    "import copy\n",
    "from functools import partial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "WINDOW_SIZE = 15  # the size of each data segment\n",
    "SEED = 42\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# this is the number of epochs per fold, but because data is already batched,\n",
    "#   when larger than 1, training takes a long time\n",
    "EPOCHS = 2\n",
    "\n",
    "SPLITS = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to data files\n",
    "fdom_raw_data = \"Data/converted_data/julian_format/fDOM_raw_10.1.2011-9.4.2020.csv\"\n",
    "stage_raw_data = \"Data/converted_data/julian_format/stage_10.1.11-1.1.19.csv\"\n",
    "turb_raw_data = \"Data/converted_data/julian_format/turbidity_raw_10.1.2011_9.4.2020.csv\"\n",
    "\n",
    "turb_labeled = \"Data/labeled_data/ground_truths/turb/turb_all_julian_0k-300k.csv\"\n",
    "\n",
    "fdom_raw_augmented = \"Data/augmented_data/turb/unlabeled/unlabeled_fdom.csv\"\n",
    "turb_labeled_augmented = \"Data/augmented_data/turb/labeled/labeled_turb_peaks.csv\"\n",
    "\n",
    "turb_augmented_raw_data = \"Data/augmented_data/turb/unlabeled/unlabeled_turb.csv\"\n",
    "\n",
    "stage_augmented_data_fn = \"Data/augmented_data/turb/unlabeled/unlabeled_stage.csv\"\n",
    "\n",
    "turb_fpt_lookup_path = \"Data/augmented_data/turb/fpt_lookup.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# util functions\n",
    "def reset_weights(model):\n",
    "    for layer in model.children():\n",
    "        if hasattr(layer, \"reset_parameters\"):\n",
    "            print(f\"reset trainable params of layer = {layer}\")\n",
    "            layer.reset_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# get device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3169 candidates found in class-balanced augmented dataset.\n"
     ]
    }
   ],
   "source": [
    "classes = [\"NAP\", \"FPT\", \"PP\", \"SKP\"]\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "targets = le.fit_transform(classes)\n",
    "\n",
    "dataset = turbAugOnlyDataset(\n",
    "    le,\n",
    "    fdom_raw_augmented,\n",
    "    stage_augmented_data_fn,\n",
    "    turb_augmented_raw_data,\n",
    "    turb_labeled_augmented,\n",
    "    turb_fpt_lookup_path,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "results = {}\n",
    "\n",
    "tss = TimeSeriesSplit(SPLITS)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "Starting epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/17 [00:00<?, ?it/s]/var/folders/3w/lhkpgfc505n81_2vs8svxfpr0000gn/T/ipykernel_42898/575108583.py:28: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /Users/runner/miniforge3/conda-bld/pytorch-recipe_1647804309932/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  label_list = torch.tensor(label_list, dtype=torch.int64)\n",
      "                                                         \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/claykaufmann/Projects/srrw-anomaly-detection/turbidity_kfold_classifier_DL.ipynb Cell 8'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/turbidity_kfold_classifier_DL.ipynb#ch0000007?line=56'>57</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/turbidity_kfold_classifier_DL.ipynb#ch0000007?line=58'>59</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/turbidity_kfold_classifier_DL.ipynb#ch0000007?line=60'>61</a>\u001b[0m pred \u001b[39m=\u001b[39m model(x\u001b[39m.\u001b[39;49mfloat())\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/turbidity_kfold_classifier_DL.ipynb#ch0000007?line=61'>62</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(pred, y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/claykaufmann/Projects/srrw-anomaly-detection/turbidity_kfold_classifier_DL.ipynb#ch0000007?line=63'>64</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Projects/srrw-anomaly-detection/Deep_Learning/resnet.py:306\u001b[0m, in \u001b[0;36mResNet1D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/resnet.py?line=299'>300</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n\u001b[1;32m    <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/resnet.py?line=300'>301</a>\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/resnet.py?line=301'>302</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mi_block: \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m, in_channels: \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m, out_channels: \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m, downsample: \u001b[39m\u001b[39m{3}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/resnet.py?line=302'>303</a>\u001b[0m             i_block, net\u001b[39m.\u001b[39min_channels, net\u001b[39m.\u001b[39mout_channels, net\u001b[39m.\u001b[39mdownsample\n\u001b[1;32m    <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/resnet.py?line=303'>304</a>\u001b[0m         )\n\u001b[1;32m    <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/resnet.py?line=304'>305</a>\u001b[0m     )\n\u001b[0;32m--> <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/resnet.py?line=305'>306</a>\u001b[0m out \u001b[39m=\u001b[39m net(out)\n\u001b[1;32m    <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/resnet.py?line=306'>307</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n\u001b[1;32m    <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/resnet.py?line=307'>308</a>\u001b[0m     \u001b[39mprint\u001b[39m(out\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Projects/srrw-anomaly-detection/Deep_Learning/resnet.py:148\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/resnet.py?line=145'>146</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_do:\n\u001b[1;32m    <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/resnet.py?line=146'>147</a>\u001b[0m         out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdo1(out)\n\u001b[0;32m--> <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/resnet.py?line=147'>148</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(out)\n\u001b[1;32m    <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/resnet.py?line=149'>150</a>\u001b[0m \u001b[39m# the second conv\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/resnet.py?line=150'>151</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_bn:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Projects/srrw-anomaly-detection/Deep_Learning/resnet.py:44\u001b[0m, in \u001b[0;36mMyConv1dPadSame.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/resnet.py?line=40'>41</a>\u001b[0m pad_right \u001b[39m=\u001b[39m p \u001b[39m-\u001b[39m pad_left\n\u001b[1;32m     <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/resnet.py?line=41'>42</a>\u001b[0m net \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mpad(net, (pad_left, pad_right), \u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[0;32m---> <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/resnet.py?line=43'>44</a>\u001b[0m net \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv(net)\n\u001b[1;32m     <a href='file:///Users/claykaufmann/Projects/srrw-anomaly-detection/Deep_Learning/resnet.py?line=45'>46</a>\u001b[0m \u001b[39mreturn\u001b[39;00m net\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/conv.py:302\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/conv.py?line=300'>301</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/conv.py?line=301'>302</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/conv.py:298\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/conv.py?line=293'>294</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/conv.py?line=294'>295</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/conv.py?line=295'>296</a>\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/conv.py?line=296'>297</a>\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/conv.py?line=297'>298</a>\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/torch/nn/modules/conv.py?line=298'>299</a>\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# K-fold training\n",
    "conf_matrices = {}\n",
    "accumulated_metrics = {}\n",
    "\n",
    "for fold, (train_ids, test_ids) in enumerate(tss.split(dataset)):\n",
    "    print(f\"FOLD {fold}\")\n",
    "\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        sampler=train_subsampler,\n",
    "        collate_fn=partial(collate_fn_pad, device=device),\n",
    "    )\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        sampler=test_subsampler,\n",
    "        collate_fn=partial(collate_fn_pad, device=device),\n",
    "    )\n",
    "\n",
    "    # init model\n",
    "    model = ResNet1D(\n",
    "        in_channels=4,\n",
    "        base_filters=64,\n",
    "        kernel_size=16,\n",
    "        stride=2,\n",
    "        n_block=48,\n",
    "        groups=1,  # check this\n",
    "        n_classes=len(classes),\n",
    "        downsample_gap=6,\n",
    "        increasefilter_gap=12,\n",
    "        verbose=False,\n",
    "    ).to(device)\n",
    "\n",
    "    # set model to use float instead of doubles to prevent errors\n",
    "    model = model.float()\n",
    "\n",
    "    # init optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    for epoch in range(0, EPOCHS):\n",
    "        print(f\"Starting epoch {epoch + 1}\")\n",
    "\n",
    "        current_loss = 0\n",
    "\n",
    "        # prog bar\n",
    "        prog_bar = tqdm(trainloader, desc=\"Training\", leave=False)\n",
    "        for i, data in enumerate(prog_bar):\n",
    "            x = data[0].to(device)\n",
    "            y = data[1].squeeze().to(device)\n",
    "\n",
    "            if i == len(prog_bar) - 1:\n",
    "                break\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred = model(x.float())\n",
    "            loss = criterion(pred, y)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print stats\n",
    "            current_loss += loss.item()\n",
    "            if i % 500 == 499:\n",
    "                print(\"Loss after mini-batch %5d: %.3f\" % (i + 1, current_loss / 500))\n",
    "                current_loss = 0.0\n",
    "\n",
    "    # completed training, now test\n",
    "    print(f\"Training for fold {fold} has completed, now testing\")\n",
    "\n",
    "    # save best params\n",
    "    save_path = f\"./results/models/turb/kfold/may-9-model-fold={fold}.pth\"\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "\n",
    "    total, correct = 0, 0\n",
    "\n",
    "    # for checking correct and incorrect preds\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    prog_bar = tqdm(testloader, desc=\"Testing\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(prog_bar):\n",
    "            x = data[0].to(device)\n",
    "            y = data[1].squeeze().to(device)\n",
    "\n",
    "            outputs = model(x.float())\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for label, prediction in zip(y, preds):\n",
    "                # convert label and prediction to current vals\n",
    "                label = le.inverse_transform([label])[0]\n",
    "                prediction = le.inverse_transform([prediction])[0]\n",
    "\n",
    "                # for confusion matrices\n",
    "                y_pred.append(prediction)\n",
    "                y_true.append(label)\n",
    "\n",
    "                if label == prediction:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "\n",
    "        # Print rough general accuracy\n",
    "        print(\"Accuracy for fold %d: %d %%\" % (fold, 100.0 * correct / total))\n",
    "        print(\"--------------------------------\")\n",
    "        results[fold] = 100.0 * (correct / total)\n",
    "\n",
    "        # make classification report\n",
    "        acc_report = classification_report(y_true, y_pred)\n",
    "        print(acc_report)\n",
    "\n",
    "        # get acc score\n",
    "        acc_score = accuracy_score(y_true, y_pred)\n",
    "\n",
    "        bal_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "\n",
    "        f1 = f1_score(\n",
    "            y_true,\n",
    "            y_pred,\n",
    "            average=\"weighted\",\n",
    "        )\n",
    "\n",
    "        precision = precision_score(\n",
    "            y_true,\n",
    "            y_pred,\n",
    "            average=\"weighted\",\n",
    "        )\n",
    "\n",
    "        # make conf matrix\n",
    "        matrix = confusion_matrix(y_true, y_pred, labels=classes)\n",
    "\n",
    "        # save conf matrix\n",
    "        conf_matrices[fold] = copy.deepcopy(matrix)\n",
    "\n",
    "        # save accumulated metrics\n",
    "        accumulated_metrics[fold] = {\n",
    "            \"f1\": f1,\n",
    "            \"acc\": acc_score,\n",
    "            \"ba\": bal_acc,\n",
    "            \"precision\": precision,\n",
    "        }\n",
    "\n",
    "# Print fold results\n",
    "print(\"\\n\")\n",
    "print(f\"K-FOLD CROSS VALIDATION RESULTS FOR {SPLITS} FOLDS\")\n",
    "print(\"--------------------------------\")\n",
    "sum = 0.0\n",
    "for key, value in results.items():\n",
    "    print(f\"Fold {key}: {value} %\")\n",
    "    sum += value\n",
    "print(f\"Average: {sum/len(results.items())} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save accumulated metrics\n",
    "mean_f1 = 0\n",
    "mean_ba = 0\n",
    "mean_precision = 0\n",
    "mean_acc = 0\n",
    "\n",
    "for key in accumulated_metrics:\n",
    "    metrics = accumulated_metrics[key]\n",
    "\n",
    "    mean_f1 += metrics[\"f1\"]\n",
    "    mean_ba += metrics[\"ba\"]\n",
    "    mean_precision += metrics[\"precision\"]\n",
    "    mean_acc += metrics[\"acc\"]\n",
    "\n",
    "print(\"Mean Test F1: \", mean_f1 / len(accumulated_metrics))\n",
    "print(\"Mean Test BA: \", mean_ba / len(accumulated_metrics))\n",
    "print(\"Mean Test Acc: \", mean_acc / len(accumulated_metrics))\n",
    "print(\"Mean Test Precision: \", mean_precision / len(accumulated_metrics))\n",
    "\n",
    "# make mean confusion matrix\n",
    "mean_cfmx = np.zeros((len(classes), len(classes)))\n",
    "for key in conf_matrices.keys():\n",
    "    mean_cfmx += conf_matrices[key]\n",
    "\n",
    "mean_cfmx = mean_cfmx / len(conf_matrices)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(label=\"Turbidity Peak Detection Ratio Confusion Matrix KFold\")\n",
    "\n",
    "sn.set(font_scale=1.5)\n",
    "\n",
    "plot = sn.heatmap(\n",
    "    pd.DataFrame(\n",
    "        mean_cfmx.astype(\"float\") / mean_cfmx.sum(axis=1)[:, np.newaxis],\n",
    "        index=classes,\n",
    "        columns=classes,\n",
    "    ),\n",
    "    annot=True,\n",
    "    annot_kws={\"size\": 16},\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Ground Truths\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.show()\n",
    "\n",
    "plot.get_figure().savefig(\n",
    "    \"./results/graphics/turb/kfold/may-9-conf-ratio-balanced-test.png\"\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(label=\"Turbidity Peak Detection Totals Confusion Matrix KFold\")\n",
    "\n",
    "sn.set(font_scale=1.5)\n",
    "\n",
    "plot = sn.heatmap(\n",
    "    pd.DataFrame(\n",
    "        mean_cfmx,\n",
    "        index=classes,\n",
    "        columns=classes,\n",
    "    ),\n",
    "    annot=True,\n",
    "    annot_kws={\"size\": 16},\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Ground Truths\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.show()\n",
    "\n",
    "plot.get_figure().savefig(\n",
    "    \"./results/graphics/turb/kfold/may-9-conf-totals-balanced-test.png\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ed753961bdc37ee89b4275051722ceb8ec0b57b8793db9d189305c313070a7d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('srrw')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
