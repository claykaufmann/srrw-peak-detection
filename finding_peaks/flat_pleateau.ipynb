{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Flat Plateaus in fDOM and turbidity\n",
    "This will be used to label flat plateaus in the data.\n",
    "\n",
    "NOTE: fDOM version not currently functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import math\n",
    "import copy\n",
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "from Tools import auxiliary_functions\n",
    "import Tools.data_movement as dm\n",
    "import Tools.data_processing as dp\n",
    "\n",
    "# better print options for checking dataframes\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.colheader_justify', 'center')\n",
    "pd.set_option('display.precision', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in data\n",
    "fDOM_data = dm.read_in_preprocessed_timeseries('../Data/converted_data/julian_format/fDOM_raw_10.1.2011-9.4.2020.csv')\n",
    "turb_data = dm.read_in_preprocessed_timeseries('../Data/converted_data/julian_format/turbidity_raw_10.1.2011_9.4.2020.csv')\n",
    "stage_data = dm.read_in_preprocessed_timeseries('../Data/converted_data/julian_format/stage_10.1.11-1.1.19.csv')\n",
    "stage_data = dp.align_stage_to_fDOM(fDOM_data, stage_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fDOM Plateaus\n",
    "We need to come up with a function that will find plateaus  \n",
    "Zach wrote a rudimentary one, needs work\n",
    "\n",
    "The dataframe this section produces, the index of the peak is the left base (AKA START OF PEAK)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base function attempt\n",
    "# FIXME: this does not correctly detect any\n",
    "cands = auxiliary_functions.detect_flat_plat(fDOM_data, 100, 40)\n",
    "\n",
    "indices = []\n",
    "for i in range(cands.shape[0]):\n",
    "    if cands[i] == 1:\n",
    "        indices.append(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe\n",
    "# get the beginning and ending of each plateau\n",
    "last_val = -1\n",
    "start_idx = -1\n",
    "end_idx = -1\n",
    "\n",
    "start_indices = []\n",
    "end_indices = []\n",
    "\n",
    "for idx, val in enumerate(indices):\n",
    "    if val != last_val + 1:\n",
    "        # we are now in a new peak, save stuff\n",
    "        start_idx = val\n",
    "        start_indices.append(start_idx)\n",
    "\n",
    "        end_idx = last_val\n",
    "        end_indices.append(end_idx)\n",
    "\n",
    "    elif idx + 1 == len(indices):\n",
    "        end_indices.append(val)\n",
    "\n",
    "    # set last val\n",
    "    last_val = val\n",
    "\n",
    "# drop first index in end indices\n",
    "del end_indices[0]\n",
    "\n",
    "cands = [[]]\n",
    "for i in range(len(start_indices)):\n",
    "    cands.append([start_indices[i], start_indices[i], end_indices[i]])\n",
    "\n",
    "# create dataframe\n",
    "cands_df_fdom = pd.DataFrame(cands)\n",
    "cands_df_fdom.columns = [\"idx_of_peak\", \"left_base\", \"right_base\"]\n",
    "\n",
    "# drop first row\n",
    "cands_df_fdom = cands_df_fdom.drop([0])\n",
    "\n",
    "# set index\n",
    "cands_df_fdom = cands_df_fdom.set_index(\"idx_of_peak\")\n",
    "\n",
    "# merge raw data with candidates on peak index\n",
    "raw_fdom_df = pd.DataFrame(fDOM_data)\n",
    "raw_fdom_df.columns = [\"timestamp_of_peak\", \"value_of_peak\"]\n",
    "total_df_fdom = cands_df_fdom.join(raw_fdom_df)\n",
    "\n",
    "# reset index\n",
    "total_df_fdom = total_df_fdom.reset_index()\n",
    "\n",
    "# drop unneedeed cols\n",
    "del total_df_fdom['left_base']\n",
    "del total_df_fdom['right_base']\n",
    "\n",
    "total_df_fdom['label_of_peak'] = \"NFPT\" # set label to be not a flat plateau\n",
    "\n",
    "total_df_fdom = total_df_fdom.reindex(columns=['timestamp_of_peak', 'value_of_peak', 'label_of_peak', \"idx_of_peak\"])\n",
    "\n",
    "print(total_df_fdom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create julian and datetime format df's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "julian_fdom = copy.deepcopy(total_df_fdom)\n",
    "datetime_fdom = copy.deepcopy(total_df_fdom)\n",
    "\n",
    "for i, row in datetime_fdom.iterrows():\n",
    "    jul_time = datetime_fdom.loc[i, \"timestamp_of_peak\"]\n",
    "\n",
    "    dt = dp.julian_to_datetime(jul_time)\n",
    "    dt = dt.isoformat()\n",
    "\n",
    "    # set new time\n",
    "    datetime_fdom.loc[i, \"timestamp_of_peak\"] = dt\n",
    "\n",
    "print(julian_fdom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turbidity Plateaus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get candidate list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base function attempt\n",
    "cands = auxiliary_functions.detect_flat_plat(turb_data, 100, 40)\n",
    "\n",
    "turb_flat_plat_indxs = []\n",
    "for i in range(cands.shape[0]):\n",
    "    if cands[i] == 1:\n",
    "        turb_flat_plat_indxs.append(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "last_val = -1\n",
    "start_idx = -1\n",
    "end_idx = -1\n",
    "\n",
    "start_indices = []\n",
    "end_indices = []\n",
    "\n",
    "for idx, val in enumerate(turb_flat_plat_indxs):\n",
    "    if val != last_val + 1:\n",
    "        # we are now in a new peak, save stuff\n",
    "        start_idx = val\n",
    "        start_indices.append(start_idx)\n",
    "\n",
    "        end_idx = last_val\n",
    "        end_indices.append(end_idx)\n",
    "\n",
    "    elif idx + 1 == len(turb_flat_plat_indxs):\n",
    "        end_indices.append(val)\n",
    "\n",
    "    # set last val\n",
    "    last_val = val\n",
    "\n",
    "# drop first index in end indices\n",
    "del end_indices[0]\n",
    "\n",
    "cands = [[]]\n",
    "for i in range(len(start_indices)):\n",
    "    cands.append([start_indices[i], start_indices[i], end_indices[i]])\n",
    "\n",
    "# create dataframe\n",
    "cands_df_turb = pd.DataFrame(cands)\n",
    "cands_df_turb.columns = [\"idx_of_peak\", \"left_base\", \"right_base\"]\n",
    "\n",
    "# drop first row\n",
    "cands_df_turb = cands_df_turb.drop([0])\n",
    "\n",
    "# set index\n",
    "cands_df_turb = cands_df_turb.set_index(\"idx_of_peak\")\n",
    "\n",
    "# merge raw data with candidates on peak index\n",
    "raw_turb_df = pd.DataFrame(turb_data)\n",
    "raw_turb_df.columns = [\"timestamp_of_peak\", \"value_of_peak\"]\n",
    "total_df_turb = cands_df_turb.join(raw_turb_df)\n",
    "\n",
    "# reset index\n",
    "total_df_turb = total_df_turb.reset_index()\n",
    "\n",
    "# drop unneedeed cols\n",
    "del total_df_turb['left_base']\n",
    "del total_df_turb['right_base']\n",
    "\n",
    "total_df_turb['label_of_peak'] = \"NFPT\" # set label to be not a flat plateau\n",
    "\n",
    "total_df_turb = total_df_turb.reindex(columns=['timestamp_of_peak', 'value_of_peak', 'label_of_peak', \"idx_of_peak\"])\n",
    "\n",
    "print(total_df_turb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create julian and datetime formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "julian_turb = copy.deepcopy(total_df_turb)\n",
    "datetime_turb = copy.deepcopy(total_df_turb)\n",
    "\n",
    "for i, row in datetime_turb.iterrows():\n",
    "    jul_time = datetime_turb.loc[i, \"timestamp_of_peak\"]\n",
    "\n",
    "    dt = dp.julian_to_datetime(jul_time)\n",
    "    dt = dt.isoformat()\n",
    "\n",
    "    # set new time\n",
    "    datetime_turb.loc[i, \"timestamp_of_peak\"] = dt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set index to be timestamp of peak\n",
    "\n",
    "# fDOM\n",
    "julian_fdom = julian_fdom.set_index(\"timestamp_of_peak\")\n",
    "datetime_fdom = datetime_fdom.set_index(\"timestamp_of_peak\")\n",
    "\n",
    "# turbidity\n",
    "julian_turb = julian_turb.set_index(\"timestamp_of_peak\")\n",
    "datetime_turb = datetime_turb.set_index(\"timestamp_of_peak\")\n",
    "\n",
    "# set path\n",
    "csv_path_julian_fdom = \"../Data/labeled_data/ground_truths/fDOM/fDOM_FPT/julian_time/fDOM_FPT_0k-300k.csv\"\n",
    "csv_path_datetime_fdom = \"../Data/labeled_data/ground_truths/fDOM/fDOM_FPT/datetime/fDOM_FPT_0k-300k.csv\"\n",
    "\n",
    "csv_path_julian_turb = \"../Data/labeled_data/ground_truths/turb/turb_fpt/julian_time/turb_FPT_0k-300k_labeled.csv\"\n",
    "csv_path_datetime_turb = \"../Data/labeled_data/ground_truths/turb/turb_fpt/datetime/turb_FPT_0k-300k_labeled.csv\"\n",
    "\n",
    "# write to csv \n",
    "# NOTE: commented out, as that would remove data\n",
    "julian_fdom.to_csv(csv_path_julian_fdom)\n",
    "datetime_fdom.to_csv(csv_path_datetime_fdom)\n",
    "\n",
    "# julian_turb.to_csv(csv_path_julian_turb)\n",
    "# #datetime_turb.to_csv(csv_path_datetime_turb)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ed753961bdc37ee89b4275051722ceb8ec0b57b8793db9d189305c313070a7d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('srrw')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
