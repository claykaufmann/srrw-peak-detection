{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fDOM Data Merging\n",
    "This file's main goal is to merge all labeled timeline data into a single source to allow for easier data augmentation, as well a classifier that can detect all types of anomalies in one, rather than one classifier for each one. This specific file merges fDOM labeled data into a single file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions are helpers for the rest of the merging process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_entire_df(dataframe):\n",
    "    \"\"\"Print out the entire contents of a dataframe, useful if you need to see differences (WARNING: ENTIRE OUTPUT WILL GO INTO GITHUB IF FILE COMMITTED WITH CELL OUTPUT\"\"\"\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "        print(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in all of the datasets:\n",
    "fDOM_PLP_path = '../Data/labeled_data/ground_truths/fDOM/fDOM_PLP/julian_time/fDOM_PLP_0k-300k.csv'\n",
    "fDOM_SKP_path = '../Data/labeled_data/ground_truths/fDOM/fDOM_SKP/julian_time/fDOM_SKP_0k-300k.csv'\n",
    "fDOM_PP_path = '../Data/labeled_data/ground_truths/fDOM/fDOM_PP/julian_time/fDOM_PP_0k-300k.csv'\n",
    "fDOM_FPT_path = '../Data/labeled_data/ground_truths/fDOM/fDOM_FPT/julian_time/fDOM_FPT_0k-300k.csv'\n",
    "fDOM_FSK_path = '../Data/labeled_data/ground_truths/fDOM/fDOM_FSK/julian_time/fDOM_FSK_0k-300k.csv'\n",
    "\n",
    "# Load in dataframes\n",
    "fDOM_PLP_df = pd.read_csv(fDOM_PLP_path)\n",
    "fDOM_SKP_df = pd.read_csv(fDOM_SKP_path)\n",
    "fDOM_PP_df = pd.read_csv(fDOM_PP_path)\n",
    "fDOM_FPT_df = pd.read_csv(fDOM_FPT_path)\n",
    "fDOM_FSK_df = pd.read_csv(fDOM_FSK_path)\n",
    "\n",
    "# update indices to use timestamp\n",
    "fDOM_PLP_df.set_index('timestamp_of_peak', inplace=True)\n",
    "fDOM_SKP_df.set_index('timestamp_of_peak', inplace=True)\n",
    "fDOM_PP_df.set_index('timestamp_of_peak', inplace=True)\n",
    "fDOM_FPT_df.set_index('timestamp_of_peak', inplace=True)\n",
    "fDOM_FSK_df.set_index('timestamp_of_peak', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize these dataframes\n",
    "print(\"PLP Head:\")\n",
    "print(fDOM_PLP_df.head())\n",
    "\n",
    "print(\"\\nSKP Head:\")\n",
    "print(fDOM_SKP_df.head())\n",
    "\n",
    "print(\"\\nPP Head:\")\n",
    "print(fDOM_PP_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peak Precendence\n",
    "The following code block sets the order precendence of peaks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET PRECENDENCE OF PEAKS\n",
    "# skyrocketing <- phantom <- plummeting <- flat plateau <- flat sink\n",
    "TOP = fDOM_PP_df\n",
    "SECOND = fDOM_SKP_df\n",
    "THIRD = fDOM_PLP_df\n",
    "FOURTH = fDOM_FPT_df\n",
    "FIFTH = fDOM_FSK_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Data\n",
    "We concat all values into a single dataframe, stable sort by timestamp, and then drop all duplicates.\n",
    "Following this, we then rename all labels starting with N to be NAP (not anomaly peaks)\n",
    "\n",
    "Using the stable sorting method keeps the indices in the correct order, so when we drop duplicates our peak precendence is saved should there be any overlapping ones.\n",
    "Following t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat all three dataframes\n",
    "df = pd.concat([TOP, SECOND, THIRD, FOURTH, FIFTH])\n",
    "\n",
    "# sort values\n",
    "df = df.sort_values(by=['timestamp_of_peak'], kind='stable')\n",
    "\n",
    "# remove duplicates\n",
    "df = df[~df.index.duplicated(keep='first')]\n",
    "\n",
    "# rename all labels that start with N to be NAP using regex\n",
    "final_data = df.replace(to_replace='N(.*)', value=\"NAP\", regex=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output to CSV\n",
    "The following codeblock exports the newly created timeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the name and path of the file\n",
    "filename = '../Data/labeled_data/ground_truths/fDOM/fDOM_all_julian_0k-300k.csv'\n",
    "\n",
    "# write to csv\n",
    "final_data.to_csv(filename)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ed753961bdc37ee89b4275051722ceb8ec0b57b8793db9d189305c313070a7d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('srrw')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
