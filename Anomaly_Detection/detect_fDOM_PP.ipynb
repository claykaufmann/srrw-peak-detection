{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f0e86851-71cb-4325-9962-e4c30f9b978c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and data \n",
    "import scipy.io as sio\n",
    "import copy\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "from os.path import dirname, join as pjoin\n",
    "import datetime\n",
    "import csv\n",
    "import math\n",
    "import sys\n",
    "sys.path.insert(1,'../')\n",
    "import Tools.data_processing as dp\n",
    "import Tools.data_movement as dm \n",
    "from auxiliary_functions import get_candidates, detect_flat_plat, detect_stage_rises\n",
    "\n",
    "fDOM_data = dm.read_in_preprocessed_timeseries('../Data/converted_data/julian_format/fDOM_raw_10.1.2011-9.4.2020.csv')\n",
    "stage_data = dm.read_in_preprocessed_timeseries('../Data/converted_data/julian_format/stage_10.1.11-1.1.19.csv')\n",
    "turb_data = dm.read_in_preprocessed_timeseries('../Data/converted_data/julian_format/turbidity_raw_10.1.2011_9.4.2020.csv')\n",
    "stage_data = dp.align_stage_to_fDOM(fDOM_data, stage_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10c75a7-266d-427e-93b2-c29511391080",
   "metadata": {},
   "source": [
    "### Detect and process stage rises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5c0d3353-8353-43ff-8906-ec0c5d5e17fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get stage rises\n",
    "s_indices = detect_stage_rises(stage_data[:,1])\n",
    "\n",
    "# Process stage rises so that each index displays distance to next stage rise in positive and negative direction\n",
    "y = s_indices.shape[0] -1 \n",
    "s_indexed = np.zeros((s_indices.shape[0],2))\n",
    "x_count = -1 \n",
    "y_count = -1\n",
    "for x in range(s_indices.shape[0]):\n",
    "    # X Block \n",
    "    \n",
    "    # When x encounters first stage rise, start x counter\n",
    "    if x_count == -1 and s_indices[x] == 1:\n",
    "        x_count = 0\n",
    "    if x_count != -1:\n",
    "        if s_indices[x] == 1:\n",
    "            x_count = 0\n",
    "            s_indexed[x,0] = x_count\n",
    "        else:\n",
    "            x_count += 1\n",
    "            s_indexed[x,0] = x_count\n",
    "    else:\n",
    "        s_indexed[x,0] = -1\n",
    "            \n",
    "    # Y Block\n",
    "    if y_count == -1 and s_indices[y] == 1:\n",
    "        y_count = 0\n",
    "    if y_count != -1:\n",
    "        if s_indices[y] == 1:\n",
    "            y_count = 0\n",
    "            s_indexed[y,1] = y_count\n",
    "        else:\n",
    "            y_count += 1\n",
    "            s_indexed[y,1] = y_count\n",
    "    else: \n",
    "        s_indexed[y,1] = -1\n",
    "        \n",
    "    y-=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1666c9-1294-4df9-96fc-68af6e6281ae",
   "metadata": {},
   "source": [
    "### Get optimal fDOM candidate sets\n",
    "\n",
    "Methods to reduce fDOM candidate: <br>\n",
    "\n",
    "- Combat detecting shallow peaks by making two calls to find_peaks with different parameters\n",
    "\n",
    "- Combat detecting \"peaks\" formed by plummeting peaks by not considering peaks where both start and end are significantly below floating mean of data within recent past\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "11bb57a1-a0f8-44eb-97e3-34f18e86ca88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "821\n",
      "818\n"
     ]
    }
   ],
   "source": [
    "large_peaks_params = {'prom' : [8,None],\n",
    "                    'width': [15, None],\n",
    "                    'wlen' : 200,\n",
    "                    'dist' : 1,\n",
    "                    'rel_h': .6}\n",
    "\n",
    "small_peaks_params = {'prom' : [3,None],\n",
    "                    'width': [0, 15],\n",
    "                    'wlen' : 200,\n",
    "                    'dist' : 1,\n",
    "                    'rel_h': .6}\n",
    "\n",
    "large_peaks, large_props = get_candidates(fDOM_data, large_peaks_params)\n",
    "small_peaks, small_props = get_candidates(fDOM_data, small_peaks_params)\n",
    "\n",
    "# Remove peaks from missing data error range: 12-10-27 14:00:00 -> 12-10-31 18:00 \n",
    "\n",
    "# Peaks will be deleted, so get the relevant properties right now\n",
    "temp_large = []\n",
    "large_indices = set()\n",
    "for i in range(len(large_peaks)):\n",
    "    temp_large.append([large_peaks[i], large_props['prominences'][i], large_props['widths'][i], large_props['left_ips'][i],large_props['right_ips'][i]])\n",
    "    large_indices.add(large_peaks[i])\n",
    "large_peaks = temp_large\n",
    "\n",
    "temp_small = []\n",
    "small_indices = set()\n",
    "for i in range(len(small_peaks)):\n",
    "    temp_small.append([small_peaks[i], small_props['prominences'][i], small_props['widths'][i], small_props['left_ips'][i],small_props['right_ips'][i]])\n",
    "    small_indices.add(small_peaks[i])\n",
    "small_peaks = temp_small\n",
    "\n",
    "# Combine both lists of peak, if there are duplicates, prefer the information from the larger peak\n",
    "del_indices = large_indices.intersection(small_indices)\n",
    "if len(del_indices):\n",
    "    print(len(del_indices))\n",
    "    raise Exception(\"Sets should not overlap\")\n",
    "    \n",
    "fDOM_cands = large_peaks + small_peaks\n",
    "\n",
    "def sortCands(cand):\n",
    "    return cand[0]\n",
    "fDOM_cands.sort(key = sortCands)\n",
    "\n",
    "print(len(fDOM_cands))\n",
    "\n",
    "temp = []\n",
    "for peak in fDOM_cands:\n",
    "    if not(peak[0] > 17816 and peak[0] < 17849):\n",
    "        temp.append(peak)\n",
    "\n",
    "fDOM_cands = copy.deepcopy(temp)\n",
    "print(len(fDOM_cands))\n",
    "\n",
    "# removed_peaks = []\n",
    "# non_removed_peaks = []\n",
    "\n",
    "# For each peak, determine if its left ips and right ips are both below half of the last min(1000 points, start of data to peak)\n",
    "# for peak in fDOM_cands:\n",
    "#     window_back = min(peak[0], 5000)\n",
    "    \n",
    "#     mean = np.mean(fDOM_data[peak[0] - window_back: peak[0], 1]) * .8\n",
    "#     if fDOM_data[math.floor(peak[3]),1] < mean and fDOM_data[math.ceil(peak[4]),1] < mean:\n",
    "#         removed_peaks.append(peak)\n",
    "#     else:\n",
    "#         non_removed_peaks.append(peak)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1da1586f-0a58-466b-995f-1fee72b0078f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If peak is very near mean for past x points, then it is likely not a peak we want\n",
    "removed_peaks = []\n",
    "non_removed_peaks = []\n",
    "win_len = 60\n",
    "tolerance  = 2\n",
    "for peak in fDOM_cands: \n",
    "    if peak[0] - win_len > 0 and peak[0] + win_len < fDOM_data.shape[0]:\n",
    "        mean = np.mean(fDOM_data[peak[0] - win_len: peak[0] + win_len, 1])\n",
    "#         print(\"Mean: \", mean, \" Value of peak: \", fDOM_data[peak[0],1])\n",
    "        if abs(mean - fDOM_data[peak[0],1]) < tolerance and np.std(fDOM_data[peak[0] - win_len: peak[0] + win_len,1]) < 4:\n",
    "            removed_peaks.append(peak)\n",
    "        else: \n",
    "            non_removed_peaks.append(peak)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "581d4f43-b281-4b5a-ae3e-3d78bb1f28cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "818\n"
     ]
    }
   ],
   "source": [
    "print(len(removed_peaks))\n",
    "print(len(non_removed_peaks))\n",
    "print(len(fDOM_cands))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c42d5f-234f-44a1-b853-01965f007de9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2256b6c6-05ee-4266-95ed-3743efcaa8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9529820448307408\n",
      "0.4444444444444446\n",
      "0.8694362691525639\n"
     ]
    }
   ],
   "source": [
    "# Experiment with calculating a peaks smoothness\n",
    "def calc_roughness(x):\n",
    "    first_derivative = np.diff(x)\n",
    "    std = np.std(first_derivative)\n",
    "    if std:\n",
    "        normalized_first_derivative = (first_derivative - np.mean(first_derivative)) / std\n",
    "        roughness = (np.diff(normalized_first_derivative) ** 2) / 4\n",
    "        return np.mean(roughness)\n",
    "    \n",
    "    return 0 \n",
    "\n",
    "\n",
    "arr1 = np.array([0,2,-1,4,1,6,2,8,1,10])\n",
    "arr2 = np.array([0,2,3,4,5])\n",
    "arr3 = np.array([0,-22,3,110,-1000,6,-1,8,9,110])\n",
    "\n",
    "print(calc_roughness(arr1))\n",
    "print(calc_roughness(arr2))\n",
    "print(calc_roughness(arr3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1bca7b52-f5bd-4a6a-af1c-cabcbf773571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0909090909090908\n",
      "0.0\n",
      "12.285714285714286\n"
     ]
    }
   ],
   "source": [
    "def calc_roughness3(x):\n",
    "    fod = np.diff(x)\n",
    "    return(np.mean(fod))\n",
    "arr1 = np.array([0,2,3,4,5,6,7,8,9,10,11,12])\n",
    "arr2 = np.array([0,0,0])\n",
    "arr3 = np.array([0,-22,3,1,5,6,-1,8,9,110,110,110,110,110,110])\n",
    "print(calc_roughness3(arr1))\n",
    "print(calc_roughness3(arr2))\n",
    "print(calc_roughness3(arr3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a8f06ecd-7c74-4706-bdc2-576f08f871df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_roughness4(x):\n",
    "    fod = np.diff(x)\n",
    "    num_switch = 0 \n",
    "    for i in range(len(fod)-1): \n",
    "        if np.sign(fod[i]) != np.sign(fod[i+1]) and np.sign(fod[i+1]) != 0:\n",
    "            num_switch +=1\n",
    "    print(num_switch)\n",
    "    return num_switch / len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7b7ef303-9f6a-411a-a0cc-ce96bb97cd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.675467891024384\n",
      "0.34641016151377546\n",
      "41.05140297176716\n"
     ]
    }
   ],
   "source": [
    "def calc_roughness2(x):\n",
    "    fod = np.diff(x)\n",
    "    mean_fod = np.mean(fod)\n",
    "    if mean_fod:\n",
    "        return np.std(fod)/ np.abs(mean_fod)\n",
    "    return 0\n",
    "\n",
    "arr1 = np.array([0,2,-1,4,1,6,2,8,1,10])\n",
    "arr2 = np.array([0,2,3,4,5])\n",
    "arr3 = np.array([0,-22,3,110,-1000,6,-1,8,9,110])\n",
    "\n",
    "print(calc_roughness2(arr1))\n",
    "print(calc_roughness2(arr2))\n",
    "print(calc_roughness2(arr3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "caf1267c-af7d-4578-af25-3ab503b228c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17816\n",
      "17849\n"
     ]
    }
   ],
   "source": [
    "x1 = '12/10/27/14:00:00'\n",
    "x2 = '12/10/31/18:00:00'\n",
    "\n",
    "print(time_to_idx(x1))\n",
    "print(time_to_idx(x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b431fe0d-9252-4125-9896-8d533e602db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_idx(time):\n",
    "    time = datetime.datetime.strptime(time, '%y/%m/%d/%X')\n",
    "    time = dp.datetime_to_julian(time)\n",
    "    for i,row in enumerate(turb_data):\n",
    "        if row[0] == time:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "# end = time_to_idx('12/08/09/15:30:00') \n",
    "# start = time_to_idx('12/08/08/18:15:00') \n",
    "# test_arr = turb_data[start:end+1, 1]\n",
    "# print(calc_roughness4(np.around(test_arr,10)))\n",
    "\n",
    "\n",
    "# start = time_to_idx('12/08/09/16:00:00')\n",
    "# end = time_to_idx('12/08/10/00:30:00')\n",
    "# test_arr = turb_data[start:end+1, 1]\n",
    "# print(calc_roughness4(np.around(test_arr,10)))\n",
    "\n",
    "# start = time_to_idx('12/08/02/18:30:00')\n",
    "# end = time_to_idx('12/08/03/05:00:00')\n",
    "# test_arr = turb_data[start:end+1, 1]\n",
    "# print(calc_roughness4(np.around(test_arr,10)))\n",
    "\n",
    "# start = time_to_idx('12/07/04/03:30:00')\n",
    "# end = time_to_idx('12/07/04/14:45:00')\n",
    "# test_arr = turb_data[start:end+1, 1]\n",
    "# print(calc_roughness4(np.around(test_arr,10)))\n",
    "\n",
    "# start = time_to_idx('12/06/25/14:15:00')\n",
    "# end = time_to_idx('12/06/25/23:15:00')\n",
    "# test_arr = turb_data[start:end+1, 1]\n",
    "# print(calc_roughness4(np.around(test_arr,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ff1d4a93-cfd3-4c1f-bcb6-f5b228471f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[      0       3      -2       4       1 -100006  100008    1001    -899]\n",
      "12.222222222222221\n",
      "[1.01226672e-09 2.81185201e-09 4.04906690e-09 1.01226672e-09\n",
      " 1.12489827e+00 4.49959309e+00 1.10251436e+00 4.06031430e-04]\n",
      "0.8409264705134258\n"
     ]
    }
   ],
   "source": [
    "arr3 = np.array([0,0,3,1,5,6,-100000,8,1009,110])\n",
    "fd = np.diff(arr3)\n",
    "m = np.mean(fd)\n",
    "std = np.std(fd)\n",
    "x = (fd - m)/std\n",
    "\n",
    "r = (np.diff(x) ** 2)/4\n",
    "print(fd)\n",
    "print(m)\n",
    "print(r)\n",
    "print(np.mean(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4e934b95-17d3-4c22-ad05-4d663f5ac38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14781603361113027\n"
     ]
    }
   ],
   "source": [
    "print(np.std(fDOM_data[0:10,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "44f31e37-59e8-4bca-bcc7-eb830f9455e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n",
      "2012-08-26 13:15:00\n",
      "2012-08-27 09:15:00\n",
      "2012-09-01 08:45:00\n",
      "2012-11-06 14:45:00\n",
      "2012-11-06 15:45:00\n",
      "2012-11-06 16:30:00\n",
      "2012-11-06 17:15:00\n",
      "2013-04-13 16:15:00\n",
      "2013-04-13 17:15:00\n",
      "2013-04-13 19:45:00\n",
      "2013-04-13 21:15:00\n",
      "2013-04-14 01:00:00\n",
      "2013-04-14 19:30:00\n",
      "2013-04-14 21:30:00\n",
      "2013-04-14 22:15:00\n",
      "2013-04-14 23:30:00\n",
      "2013-04-17 09:00:00\n",
      "2013-04-17 11:00:00\n",
      "2013-04-18 06:30:00\n",
      "2013-09-10 14:00:00\n",
      "2013-10-16 12:30:00\n",
      "2014-04-29 14:45:00\n",
      "2014-07-22 13:15:00\n",
      "2015-04-14 14:45:00\n",
      "2015-09-22 13:00:00\n",
      "2015-12-04 05:45:00\n",
      "2016-12-12 09:00:00\n",
      "2017-04-24 13:15:00\n",
      "2017-12-15 07:30:00\n",
      "2017-12-15 08:15:00\n",
      "2017-12-15 09:00:00\n",
      "2017-12-15 09:45:00\n",
      "2017-12-15 10:30:00\n",
      "2017-12-15 11:30:00\n",
      "2017-12-15 12:30:00\n",
      "2017-12-15 13:30:00\n",
      "2017-12-15 14:30:00\n",
      "2017-12-15 15:30:00\n",
      "2017-12-18 02:45:00\n",
      "2017-12-18 03:15:00\n",
      "2017-12-18 06:30:00\n",
      "2017-12-18 07:00:00\n",
      "2018-01-30 11:45:00\n",
      "2018-01-30 17:30:00\n",
      "2018-03-04 14:15:00\n",
      "2018-04-25 14:00:00\n",
      "2018-04-26 00:45:00\n",
      "2018-08-13 05:15:00\n",
      "2018-08-13 07:00:00\n",
      "2018-08-14 10:00:00\n",
      "2018-09-16 07:45:00\n",
      "2018-09-16 09:45:00\n",
      "2018-09-16 10:30:00\n"
     ]
    }
   ],
   "source": [
    "print(len(removed_peaks)) \n",
    "for peak in removed_peaks:\n",
    "    print(dp.julian_to_datetime(fDOM_data[peak[0],0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "35aff846-ff10-4135-be89-309f661f9880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# disp_peaks = non_removed_peaks\n",
    "disp_peaks = fDOM_cands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfaaf02-ef5d-4387-b753-1f69df72d945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "81caebc8-e48f-4cb1-86ed-bb940017b7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[616, 10.488100619999997, 45.436164568494746, 606.1435361583116, 651.5797007268063]\n",
      "[616, 10.488100619999997, 45.436164568494746, 606.1435361583116, 651.5797007268063]\n"
     ]
    }
   ],
   "source": [
    "print(disp_peaks[0])\n",
    "print(fDOM_cands[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb33bd5-c0ab-4f48-a89f-613816ef682f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9b22e4a0-77ed-4a37-bc3c-18429f0f613f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert peaks and props to useable structure and assign values from s_indexed\n",
    "fDOM_cands = [[peak[0], peak[3],peak[4],s_indexed[peak[0],0], s_indexed[peak[0],1]] for peak in disp_peaks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "47c6b173-6838-4b54-9890-ce32513b22e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "print(len(fDOM_cands))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ca78d92d-5349-4a54-bade-8bea572d3347",
   "metadata": {},
   "outputs": [],
   "source": [
    "turb_cand_params = {'prom' : [6,None],\n",
    "                    'width': [None, None],\n",
    "                    'wlen' : 200,\n",
    "                    'dist' : 1,\n",
    "                    'rel_h': .6}\n",
    "\n",
    "# Get fDOM and turb candiate peaks\n",
    "turb_peaks, turb_props = get_candidates(turb_data, turb_cand_params)\n",
    "\n",
    "# Remove peaks that occur during a flat plateau \n",
    "turb_flat_plat = detect_flat_plat(turb_data, 100, 40)\n",
    "turb_flat_plat_indxs = []\n",
    "for i in range(turb_flat_plat.shape[0]):\n",
    "    if turb_flat_plat[i] == 1:\n",
    "        turb_flat_plat_indxs.append(i)\n",
    "\n",
    "take_indices = []\n",
    "for i,peak in enumerate(turb_peaks):\n",
    "    if peak not in turb_flat_plat_indxs:\n",
    "        take_indices.append(i)\n",
    "\n",
    "turb_peaks = np.take(turb_peaks, take_indices)\n",
    "for key in turb_props:\n",
    "    turb_props[key] = np.take(turb_props[key], take_indices)\n",
    "\n",
    "# Iterate through peaks and turn into short 3 point \"events\" by flagging the data point to either side of a peak\n",
    "fDOM_events = []\n",
    "fDOM_lb = []\n",
    "fDOM_rb = []\n",
    "\n",
    "for i,cand in enumerate(fDOM_cands):\n",
    "            fDOM_events.append(np.array((fDOM_data[cand[0]])))\n",
    "            fDOM_lb.append(fDOM_data[math.floor(cand[1]),0])\n",
    "            fDOM_rb.append(fDOM_data[math.ceil(cand[2]),0])\n",
    "            \n",
    "fDOM_lb = list(set(fDOM_lb))\n",
    "fDOM_lb.sort()\n",
    "fDOM_rb = list(set(fDOM_rb))\n",
    "fDOM_rb.sort()\n",
    "\n",
    "turb_events = []\n",
    "turb_lb = []\n",
    "turb_rb = []\n",
    "for i,peak in enumerate(turb_peaks):\n",
    "            turb_events.append(np.array((turb_data[peak])))\n",
    "            turb_lb.append(turb_data[math.floor(turb_props['left_ips'][i]),0])\n",
    "            turb_rb.append(turb_data[math.ceil(turb_props['right_ips'][i]),0])\n",
    "            \n",
    "turb_lb = list(set(turb_lb))\n",
    "turb_lb.sort()\n",
    "turb_rb = list(set(turb_rb))\n",
    "turb_rb.sort()            \n",
    "\n",
    "fDOM_merged = dp.merge_data(fDOM_data, fDOM_events, 'f_opp', '')\n",
    "turb_merged = dp.merge_data(turb_data, turb_events, 't_opp', '')\n",
    "\n",
    "fDOM_merged = dp.merge_additional_data(fDOM_merged, fDOM_lb, 'left_base')\n",
    "fDOM_merged = dp.merge_additional_data(fDOM_merged, fDOM_rb, 'right_base')\n",
    "\n",
    "turb_merged = dp.merge_additional_data(turb_merged, turb_lb, 'left_base')\n",
    "turb_merged = dp.merge_additional_data(turb_merged, turb_rb, 'right_base')\n",
    "\n",
    "\n",
    "stage_edge_data = dp.stage_rises_to_data(s_indices, stage_data)\n",
    "stage_data_merged = dp.merge_data(stage_data, stage_edge_data, 'rise','')\n",
    "\n",
    "dm.write_data_to_trainset(fDOM_merged,\n",
    "                          stage_data_merged,\n",
    "                          turb_merged,\n",
    "                          '/Users/zachfogg/Desktop/DB-SRRW/Data/plot/fDOM_cand_200k-300k.csv',\n",
    "                          True,\n",
    "                          True,\n",
    "                          200000,\n",
    "                          300000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4d754ebf-6e35-432c-a396-f63a94b467dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229620\n",
      "229620\n"
     ]
    }
   ],
   "source": [
    "print(len(stage_data))\n",
    "print(len(fDOM_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2364d54-695a-46e3-bd7f-85a8ed20295a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "print(list(range(0,10)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
