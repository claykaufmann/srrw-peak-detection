{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8247738-805b-47f2-b7fb-3cf7c17dca72",
   "metadata": {},
   "source": [
    "### Import and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a11ba09b-c596-4cbd-9dd7-75a37054f417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and data \n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import pandas as pd\n",
    "import copy\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "from os.path import dirname, join as pjoin\n",
    "import datetime\n",
    "import csv\n",
    "import math\n",
    "import sys\n",
    "sys.path.insert(1,'../')\n",
    "import Tools.data_processing as dp\n",
    "import Tools.data_movement as dm \n",
    "from auxiliary_functions import get_candidates, detect_flat_plat\n",
    "\n",
    "fDOM_raw_data = dm.read_in_preprocessed_timeseries('../Data/converted_data/julian_format/fDOM_raw_10.1.2011-9.4.2020.csv')\n",
    "stage_data = dm.read_in_preprocessed_timeseries('../Data/converted_data/julian_format/stage_10.1.11-1.1.19.csv')\n",
    "turb_data = dm.read_in_preprocessed_timeseries('../Data/converted_data/julian_format/turbidity_raw_10.1.2011_9.4.2020.csv')\n",
    "stage_data = dp.align_stage_to_fDOM(fDOM_raw_data, stage_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e60ee9a-6243-4ca8-b925-689d8ae56857",
   "metadata": {},
   "source": [
    "### Detect Stage Rise Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1a9d91-2f03-48fd-badf-f7a31d1d5535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4744c6b6-d07d-4232-b1c4-62473f721dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slopes:  [ 1  1  1  0  1  1 -2 -1 -1 -1  1  1  0 -1]\n",
      "Contin:  [1. 2. 3. 0. 1. 2. 0. 0. 0. 0. 1. 2. 0. 0.]\n",
      "[1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([0,1,2,3,3,4,5,3,2,1,0,1,2,2,1])\n",
    "params = {'slope_threshold' : 1, 'duration_threshold' : 3}\n",
    "print(detect_stage_rises_one_window(x, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7357aea-578f-46b6-a7ec-b868d8bf9540",
   "metadata": {},
   "source": [
    "### Import Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17661be-5cc9-4b30-89cd-5100526df37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ground truth values \n",
    "ground_truth_path = '/Users/zachfogg/Desktop/DB-SRRW/Data/manual_annotating_data/annotated_data/Stage_Rise/stage_algo_auto_labeled/stage_rises_0k-300k.csv'\n",
    "ground_truth_signals = np.zeros(len(stage_data))\n",
    "with open(ground_truth_path, 'r', newline = '') as gt_file:\n",
    "    reader = csv.reader(gt_file, delimiter = ',')\n",
    "    idx = 0 \n",
    "    for row in reader:\n",
    "        if row[0] == 'Stage':\n",
    "            if row[3] == 'rise':\n",
    "                ground_truth_signals[idx] = 1\n",
    "            idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e34e4bf-4961-4b48-9fef-d2e2992b7b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground_truth_path = '/Users/zachfogg/Desktop/newnew/stage_rise_labeled_0k-300k.csv'\n",
    "ground_truth_path = \"/Users/zachfogg/Desktop/StageFinalOct21/stage_rise_labeled_0k-300k.csv\"\n",
    "ground_truth_signals = np.zeros(len(stage_data))\n",
    "with open(ground_truth_path, 'r', newline = '') as gt_file:\n",
    "    reader = csv.reader(gt_file, delimiter = ',')\n",
    "    idx = 0 \n",
    "    for row in reader:\n",
    "        if row[0] == 'Stage':\n",
    "            if row[3] == 'TP':\n",
    "                ground_truth_signals[idx] = 1\n",
    "            idx+=1\n",
    "\n",
    "for i in range(1,len(ground_truth_signals)-1):\n",
    "    if ground_truth_signals[i-1] == ground_truth_signals[i+1] == 0 and ground_truth_signals[i] == 1:\n",
    "        ground_truth_signals[i] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6d5e13-64c3-4ff8-9aab-ec1a4a239510",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0 \n",
    "for x in ground_truth_signals:\n",
    "    if x == 1: count +=1 \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd167f0f-95b5-4f92-9508-17f526ca1ecc",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde7b5e9-ccae-4719-8202-c9ad281f24df",
   "metadata": {},
   "source": [
    "### Nested K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d90b988c-70b9-4630-9057-a048bf405df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Bounds \n",
    "\n",
    "win_threshold_bounds = (0,.075) # Stage rarely even rises above 1 so this range is more than generous\n",
    "adj_threshold_bounds = (0,.02)\n",
    "remove_end_threshold_bounds = (.0005,.003)\n",
    "\n",
    "small_window_bounds = (3,6) # There are rises that are 3 long which need to be captured \n",
    "large_window_bounds = (5,10) # Should not overlap with small window\n",
    "\n",
    "best_params = {'small_adj_threshold' : 0,\n",
    "               'large_adj_threshold' : 0,\n",
    "               'small_win_threshold' : 0,\n",
    "               'large_win_threshold' : 0,\n",
    "               'remove_end_threshold' : 0,\n",
    "               'small_window' : 0,\n",
    "               'large_window' : 0}\n",
    "\n",
    "iterations = 688\n",
    "\n",
    "def label_positives_negatives(predictions, ground_truths):\n",
    "    TP = TN = FP = FN = 0\n",
    "    results = []\n",
    "    for i in range(len(predictions)):\n",
    "        prediction = predictions[i]\n",
    "        ground_truth = ground_truths[i]\n",
    "\n",
    "        if prediction == 1 and ground_truth == 1:\n",
    "            results.append([prediction, 'TP'])\n",
    "            TP +=1 \n",
    "        elif prediction == 1 and ground_truth == 0:\n",
    "            results.append([prediction, 'FP'])\n",
    "            FP +=1 \n",
    "        elif prediction == 0 and ground_truth == 1:\n",
    "            results.append([prediction,'FN'])\n",
    "            FN +=1 \n",
    "        else:\n",
    "            results.append([prediction, 'TN'])\n",
    "            TN +=1\n",
    "    return (TP,TN,FP,FN,results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "987b2d86-e85e-4099-b327-529a56282484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split:  1\n",
      "\n",
      "Iteration: 344\n",
      "\n",
      "Split: 1  F1: 0.9081 BA: 0.9965  Params: {'small_adj_threshold': 0.005891945916528088, 'large_adj_threshold': 0.036666764265943876, 'small_win_threshold': 0.006433802857818498, 'large_win_threshold': 0.00192329051780195, 'remove_end_threshold': 0.001409927973476543, 'small_window': 6, 'large_window': 6}  TP: 1141 TN: 36898 FP: 230 FN: 1  Time: 0:02:32.966884\n",
      "Split:  2\n",
      "\n",
      "Iteration: 344\n",
      "\n",
      "Split: 2  F1: 0.9399 BA: 0.9897  Params: {'small_adj_threshold': 0.030932123139539452, 'large_adj_threshold': 0.03393799750447163, 'small_win_threshold': 0.01644315173095221, 'large_win_threshold': 0.016895229904613996, 'remove_end_threshold': 0.002530308806212348, 'small_window': 3, 'large_window': 9}  TP: 931 TN: 37220 FP: 102 FN: 17  Time: 0:05:14.469071\n",
      "Split:  3\n",
      "\n",
      "Iteration: 344\n",
      "\n",
      "Split: 3  F1: 0.9328 BA: 0.9782  Params: {'small_adj_threshold': 0.057292307272747506, 'large_adj_threshold': 0.02947951604022098, 'small_win_threshold': 0.009903615261395887, 'large_win_threshold': 0.005438475338202229, 'remove_end_threshold': 0.0017318504731037067, 'small_window': 3, 'large_window': 8}  TP: 986 TN: 37142 FP: 100 FN: 42  Time: 0:12:45.943935\n",
      "Split:  4\n",
      "\n",
      "Iteration: 344\n",
      "\n",
      "Split: 4  F1: 0.9084 BA: 0.9573  Params: {'small_adj_threshold': 0.04536854141467405, 'large_adj_threshold': 0.05388677176067321, 'small_win_threshold': 0.015568263960458864, 'large_win_threshold': 0.013067705054321569, 'remove_end_threshold': 0.002389191947859445, 'small_window': 4, 'large_window': 7}  TP: 1190 TN: 36840 FP: 134 FN: 106  Time: 0:14:05.323435\n",
      "Split:  5\n",
      "\n",
      "Iteration: 344\n",
      "\n",
      "Split: 5  F1: 0.9507 BA: 0.9936  Params: {'small_adj_threshold': 0.05829611549790172, 'large_adj_threshold': 0.01330364938021289, 'small_win_threshold': 0.008389746551646891, 'large_win_threshold': 0.00029634546449478275, 'remove_end_threshold': 0.0005125984969705742, 'small_window': 6, 'large_window': 10}  TP: 1090 TN: 37067 FP: 102 FN: 11  Time: 0:13:27.180405\n",
      "Mean Test F1:  0.9279905223187178\n",
      "Mean Test BA:  0.9830573492653677\n",
      "0:48:06.405353\n"
     ]
    }
   ],
   "source": [
    "num_splits = 5 # Number of train/val/test folds\n",
    "\n",
    "# df = pd.DataFrame(data = {'data' : stage_data[:,1], 'label' : ground_truth_signals}) # Create training set from data and ground truth\n",
    "\n",
    "train_test_split = TimeSeriesSplit(num_splits).split(stage_data[:,1])\n",
    "\n",
    "accumulated_test_metrics = {}\n",
    "\n",
    "accumulated_test_results = {}\n",
    "\n",
    "overall_start = datetime.datetime.now()\n",
    "\n",
    "accumulated_best_params = {}\n",
    "\n",
    "split = 1 \n",
    "\n",
    "for train_val_indices, test_indices in train_test_split: # Outer loop performs the \"Forward-Chaining\"\n",
    "    \n",
    "    # Get appropriate data subset\n",
    "    X_train, y_train = np.take(stage_data[:,1], train_val_indices), np.take(ground_truth_signals, train_val_indices)\n",
    "    X_test, y_test = np.take(stage_data[:,1], test_indices), np.take(ground_truth_signals, test_indices)\n",
    "\n",
    "   \n",
    "    max_fold_metric = 0\n",
    "    max_result = None  \n",
    "    max_acc = 0\n",
    "    print(\"Split: \",split)\n",
    "    # Optimize hyper parameters to the training data\n",
    "    split_start = datetime.datetime.now()\n",
    "    for iteration in range(iterations):\n",
    "        \n",
    "        # Random grid search\n",
    "        params = {}\n",
    "        params['small_adj_threshold'] = np.random.uniform(win_threshold_bounds[0], win_threshold_bounds[1])\n",
    "        params['large_adj_threshold'] = np.random.uniform(win_threshold_bounds[0], win_threshold_bounds[1])\n",
    "\n",
    "        params['small_win_threshold'] = np.random.uniform(adj_threshold_bounds[0], adj_threshold_bounds[1])\n",
    "        params['large_win_threshold'] = np.random.uniform(adj_threshold_bounds[0], adj_threshold_bounds[1])\n",
    "\n",
    "        params['remove_end_threshold'] = np.random.uniform(remove_end_threshold_bounds[0],remove_end_threshold_bounds[1])\n",
    "\n",
    "        params['small_window'] = np.random.randint(small_window_bounds[0], small_window_bounds[1]+1)\n",
    "        params['large_window'] = np.random.randint(large_window_bounds[0], large_window_bounds[1]+1)\n",
    "        \n",
    "        # Detect stage rises \n",
    "        detected_signals = detect_stage_rises(X_train, params)\n",
    "        \n",
    "        # Results will hold: [signal, result in comparison to ground truth]\n",
    "        TP,TN,FP,FN,results = label_positives_negatives(detected_signals, y_train)\n",
    "        \n",
    "        TPR = TP/(TP + FN)\n",
    "        TNR = TN/(TN + FP)\n",
    "        bal_acc = (TPR + TNR)/2 \n",
    "        f1_score = (2 * TP)/((2 * TP) + FP + FN)\n",
    "\n",
    "        acc = f1_score\n",
    "        if iteration and iteration % int(iterations/2) == 0: print(\"\\nIteration: {}\\n\".format(iteration))\n",
    "        if acc > max_acc: \n",
    "            max_acc = acc\n",
    "            max_result = copy.deepcopy(results)\n",
    "            best_params = copy.deepcopy(params)\n",
    "#             print('I: {}  F1: {:.4f} BA: {:.4f}  Params: {}  TP: {} TN: {} FP: {} FN: {}'.format(iteration, f1_score, bal_acc, params, TP, TN, FP, FN))\n",
    "        \n",
    "    # Test best parameters on testing data \n",
    "    predicted_signals = detect_stage_rises(X_test, best_params)\n",
    "    \n",
    "    TP,TN,FP,FN,results = label_positives_negatives(predicted_signals, y_test)\n",
    "    \n",
    "    TPR = TP/(TP + FN)\n",
    "    TNR = TN/(TN + FP)\n",
    "    \n",
    "    bal_acc = (TPR + TNR)/2 \n",
    "    f1_score = (2 * TP)/((2 * TP) + FP + FN)\n",
    "    \n",
    "#     print(\"Split: {} test scores, f1: {} BA: {} Time: {}\".format(split, f1_score, bal_acc, datetime.datetime.now() - split_start))\n",
    "    print('Split: {}  F1: {:.4f} BA: {:.4f}  Params: {}  TP: {} TN: {} FP: {} FN: {}  Time: {}'.format(split, f1_score, bal_acc, params, TP, TN, FP, FN, datetime.datetime.now() - split_start))\n",
    "    accumulated_test_metrics[split] = [f1_score, bal_acc] # Record test metrics of each split\n",
    "    accumulated_test_results[split] = copy.deepcopy(results) # Record test results (FP,FN,TP,TN for each datapoint) for each split\n",
    "    accumulated_best_params[split] = copy.deepcopy(best_params) # Record params uses in testing for each split\n",
    "    \n",
    "    split+=1\n",
    "\n",
    "mean_f1 = 0\n",
    "mean_ba = 0 \n",
    "\n",
    "for key in accumulated_test_metrics:\n",
    "    metrics = accumulated_test_metrics[key]\n",
    "    mean_f1+=metrics[0]\n",
    "    mean_ba+=metrics[1]\n",
    "\n",
    "print(\"Mean Test F1: \", mean_f1/len(accumulated_test_metrics))\n",
    "print(\"Mean Test BA: \", mean_ba/len(accumulated_test_metrics))\n",
    "\n",
    "print(datetime.datetime.now() - overall_start)\n",
    "\n",
    "# Pickle params from last fold\n",
    "with open('./stage_algo_exp_results/algo1_best_params.pkl', 'wb') as pck_file:\n",
    "    pickle.dump(accumulated_best_params[num_splits], pck_file)\n",
    "    pck_file.close()\n",
    "    \n",
    "# Pickle results from last fold \n",
    "with open('./stage_algo_exp_results/algo1_test_results.pkl', 'wb') as pck_file:\n",
    "    pickle.dump(accumulated_test_results[num_splits], pck_file)\n",
    "    pck_file.close()\n",
    "\n",
    "# Pickle results from last fold \n",
    "with open('./stage_algo_exp_results/algo1_test_metrics.pkl', 'wb') as pck_file:\n",
    "    pickle.dump(accumulated_test_metrics, pck_file)\n",
    "    pck_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d78997e5-fca6-475e-bae9-7137da63a008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test F1:  0.872022667989554\n",
      "Mean Test BA:  0.9335898150778146\n"
     ]
    }
   ],
   "source": [
    "with open('./stage_algo_exp_results/algo4_test_metrics.pkl', 'rb') as pck_file:\n",
    "    accumulated_test_metrics = pickle.load(pck_file)\n",
    "    pck_file.close()\n",
    "\n",
    "mean_f1 = 0\n",
    "mean_ba = 0 \n",
    "\n",
    "for key in accumulated_test_metrics:\n",
    "    metrics = accumulated_test_metrics[key]\n",
    "    mean_f1+=metrics[0]\n",
    "    mean_ba+=metrics[1]\n",
    "\n",
    "print(\"Mean Test F1: \", mean_f1/len(accumulated_test_metrics))\n",
    "print(\"Mean Test BA: \", mean_ba/len(accumulated_test_metrics))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c38e37fd-a08e-4d3a-ba21-3b227fbeb594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
      "\u001b[K     |████████████████████████████████| 292 kB 3.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=2.2 in /Users/zachfogg/opt/anaconda3/envs/xeus-python/lib/python3.9/site-packages (from seaborn) (3.4.2)\n",
      "Requirement already satisfied: numpy>=1.15 in /Users/zachfogg/opt/anaconda3/envs/xeus-python/lib/python3.9/site-packages (from seaborn) (1.21.0)\n",
      "Requirement already satisfied: pandas>=0.23 in /Users/zachfogg/opt/anaconda3/envs/xeus-python/lib/python3.9/site-packages (from seaborn) (1.3.3)\n",
      "Requirement already satisfied: scipy>=1.0 in /Users/zachfogg/opt/anaconda3/envs/xeus-python/lib/python3.9/site-packages (from seaborn) (1.7.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/zachfogg/opt/anaconda3/envs/xeus-python/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/zachfogg/opt/anaconda3/envs/xeus-python/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (2.8.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/zachfogg/opt/anaconda3/envs/xeus-python/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/zachfogg/opt/anaconda3/envs/xeus-python/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/zachfogg/opt/anaconda3/envs/xeus-python/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (8.3.1)\n",
      "Requirement already satisfied: six in /Users/zachfogg/opt/anaconda3/envs/xeus-python/lib/python3.9/site-packages (from cycler>=0.10->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/zachfogg/opt/anaconda3/envs/xeus-python/lib/python3.9/site-packages (from pandas>=0.23->seaborn) (2021.1)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.11.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "!pip3 install seaborn\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pred = np.array([row[0] for row in accumulated_test_results[num_splits][0]])\n",
    "\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "\n",
    "sn.heatmap(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "18a6a967-73e1-4c9b-a038-d885c43a630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_params = copy.deepcopy(best_params)\n",
    "# save_result = copy.deepcopy(max_result)\n",
    "# save_params2 = copy.deepcopy(best_params)\n",
    "# save_result2 = copy.deepcopy(max_result)\n",
    "save_params3 = copy.deepcopy(best_params)\n",
    "save_result3 = copy.deepcopy(max_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fec3da5d-4375-4f38-8f2e-afab149f33ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'w1_slope_threshold': 0.08897139651302588, 'w1_duration_threshold': 18, 'w2_slope_threshold': 0.0443535992752028, 'w2_duration_threshold': 6, 'min_height': 0.06586482147779672}  TP: 820 TN: 37042 FP: 16 FN: 392  Time: 0:01:38.449921\n",
    "predicted_signals = detect_stage_rises(stage_data[:,1], params)\n",
    "    \n",
    "TP,TN,FP,FN,results = label_positives_negatives(predicted_signals, ground_truth_signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e8a763dd-32ea-411e-8379-a79dd423cfed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8918977626529578\n"
     ]
    }
   ],
   "source": [
    "print((2 * TP)/((2 * TP) + FP + FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "92b92bab-2f1e-4b8a-ab52-277a822308d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out signals to reconsider labels\n",
    "# Get stage rises\n",
    "# fDOM_cand_params = {'prom' : [4,None],\n",
    "#                     'width': [None, None],   These are the params for fDOM pp cand\n",
    "#                     'wlen' : 200,\n",
    "#                     'dist' : 1,\n",
    "#                     'rel_h': .6}\n",
    "\n",
    "fDOM_cand_params = {'prom' : [4,None],\n",
    "                    'width': [None, 2],\n",
    "                    'wlen' : 200,\n",
    "                    'dist' : 1,\n",
    "                    'rel_h': .6}\n",
    "\n",
    "# turb_cand_params = {'prom' : [6,None],       These are the params that were used to label turb cand 0-100k\n",
    "#                     'width': [None, None],\n",
    "#                     'wlen' : 200,\n",
    "#                     'dist' : 1,\n",
    "#                     'rel_h': .6}\n",
    "\n",
    "turb_cand_params = {'prom' : [6,None],\n",
    "                    'width': [None, None],    # was 2 for skyrocketing\n",
    "                    'wlen' : 200,\n",
    "                    'dist' : 1,\n",
    "                    'rel_h': .6}   # was .5 for skyrocketing \n",
    "\n",
    "# Get fDOM and turb candiate peaks\n",
    "fDOM_peaks, fDOM_props = get_candidates(fDOM_raw_data, fDOM_cand_params)\n",
    "turb_peaks, turb_props = get_candidates(turb_data, turb_cand_params)\n",
    "\n",
    "# Remove peaks that occur during a flat plateau \n",
    "turb_flat_plat = detect_flat_plat(turb_data, 100, 40)\n",
    "turb_flat_plat_indxs = []\n",
    "for i in range(turb_flat_plat.shape[0]):\n",
    "    if turb_flat_plat[i] == 1:\n",
    "        turb_flat_plat_indxs.append(i)\n",
    "\n",
    "take_indices = []\n",
    "for i,peak in enumerate(turb_peaks):\n",
    "    if peak not in turb_flat_plat_indxs:\n",
    "        take_indices.append(i)\n",
    "\n",
    "turb_peaks = np.take(turb_peaks, take_indices)\n",
    "for key in turb_props:\n",
    "    turb_props[key] = np.take(turb_props[key], take_indices)\n",
    "\n",
    "# Iterate through peaks and turn into short 3 point \"events\" by flagging the data point to either side of a peak\n",
    "# fDOM_events = []\n",
    "# for peak in fDOM_peaks:\n",
    "#             fDOM_events.append(np.array((fDOM_raw_data[peak-1], fDOM_raw_data[peak], fDOM_raw_data[peak+1])))\n",
    "fDOM_events = []\n",
    "fDOM_lb = []\n",
    "fDOM_rb = []\n",
    "\n",
    "for i,peak in enumerate(fDOM_peaks):\n",
    "            fDOM_events.append(np.array((fDOM_raw_data[peak])))\n",
    "#             fDOM_lb.append(fDOM_raw_data[fDOM_props['left_bases'][i],0])\n",
    "#             fDOM_rb.append(fDOM_raw_data[fDOM_props['right_bases'][i],0])\n",
    "            fDOM_lb.append(fDOM_raw_data[math.floor(fDOM_props['left_ips'][i]),0])\n",
    "            fDOM_rb.append(fDOM_raw_data[math.ceil(fDOM_props['right_ips'][i]),0])\n",
    "            \n",
    "fDOM_lb = list(set(fDOM_lb))\n",
    "fDOM_lb.sort()\n",
    "fDOM_rb = list(set(fDOM_rb))\n",
    "fDOM_rb.sort()\n",
    "\n",
    "turb_events = []\n",
    "turb_lb = []\n",
    "turb_rb = []\n",
    "for i,peak in enumerate(turb_peaks):\n",
    "            turb_events.append(np.array((turb_data[peak])))\n",
    "            turb_lb.append(turb_data[math.floor(turb_props['left_ips'][i]),0])\n",
    "            turb_rb.append(turb_data[math.ceil(turb_props['right_ips'][i]),0])\n",
    "            \n",
    "turb_lb = list(set(turb_lb))\n",
    "turb_lb.sort()\n",
    "turb_rb = list(set(turb_rb))\n",
    "turb_rb.sort()            \n",
    "\n",
    "fDOM_merged = dp.merge_data(fDOM_raw_data, fDOM_events, 'f_opp', '')\n",
    "turb_merged = dp.merge_data(turb_data, turb_events, 't_opp', '')\n",
    "\n",
    "fDOM_merged = dp.merge_additional_data(fDOM_merged, fDOM_lb, 'left_base')\n",
    "fDOM_merged = dp.merge_additional_data(fDOM_merged, fDOM_rb, 'right_base')\n",
    "\n",
    "turb_merged = dp.merge_additional_data(turb_merged, turb_lb, 'left_base')\n",
    "turb_merged = dp.merge_additional_data(turb_merged, turb_rb, 'right_base')\n",
    "\n",
    "\n",
    "stage_data_merged = []\n",
    "for i in range(len(results)):\n",
    "    stage_data_merged.append([stage_data[i,0],stage_data[i,1],results[i][1]])\n",
    "\n",
    "dm.write_data_to_trainset(fDOM_merged,\n",
    "                          stage_data_merged,\n",
    "                          turb_merged,\n",
    "                          '../Data/anomaly_data/temp_data/stage_rise_algo_200k-300k.csv',\n",
    "                          True,\n",
    "                          True,\n",
    "                          200000,\n",
    "                          300000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
