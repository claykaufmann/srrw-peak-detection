{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bebbf0d-e1fa-43be-bbdb-902ad47db3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and data \n",
    "import scipy.io as sio\n",
    "import pickle \n",
    "import math\n",
    "import copy\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "from os.path import dirname, join as pjoin\n",
    "import datetime\n",
    "import csv\n",
    "import sys\n",
    "sys.path.insert(1,'../')\n",
    "import Tools.data_processing as dp\n",
    "import Tools.data_movement as dm \n",
    "from Tools.auxiliary_functions import get_stage_events, detect_edges\n",
    "\n",
    "fDOM_raw_data = dm.read_in_preprocessed_timeseries('/Users/zachfogg/Desktop/DB-SRRW/Data/converted_data/julian_format/fDOM_raw_10.1.2011-9.4.2020.csv')\n",
    "stage_data = dm.read_in_preprocessed_timeseries('/Users/zachfogg/Desktop/DB-SRRW/Data/converted_data/julian_format/stage_10.1.11-1.1.19.csv')\n",
    "turb_data = dm.read_in_preprocessed_timeseries('/Users/zachfogg/Desktop/DB-SRRW/Data/converted_data/julian_format/turbidity_raw_10.1.2011_9.4.2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb554cf6-f247-42f0-876e-9312361db543",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_edge_indices = detect_edges(stage_data[:,1], 5, 3.5, .5)['signals']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4e25f1b-9de5-4029-8b94-b97ad584dd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rise_indices = []\n",
    "for i in range(len(stage_edge_indices)):\n",
    "    if stage_edge_indices[i] == 1: \n",
    "        rise_indices.append(i)\n",
    "        \n",
    "starts = [stage_data[rise_indices[0],0]]\n",
    "ends = []\n",
    "for i,indx in enumerate(rise_indices):\n",
    "    # If this condition is true, then this point is the end of an edge(it can also be the start in case of 1 data point edge)\n",
    "    if(i < len(rise_indices)-1) and rise_indices[i+1] - 1 != indx:\n",
    "        # Designate this point as an end and next point at a start, but also evaluate next point as it could be both a start and an end\n",
    "        ends.append(stage_data[indx,0])\n",
    "        starts.append(stage_data[rise_indices[i+1],0])\n",
    "ends.append(stage_data[rise_indices[-1],0])\n",
    "np.array()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ed014d-8b3a-403e-886e-9c1012c5671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_edge_data = np.take(stage_data, starts, 0)\n",
    "end_data = np.take(stage_data, ends, 0)\n",
    "\n",
    "for i in range(10):\n",
    "    print(dp.julian_to_datetime(stage_edge_data[i,0]),\"  |  \" , dp.julian_to_datetime(end_data[i,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcd5b6e-6456-4b32-911f-5d37ddd963af",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta15 = datetime.timedelta(minutes = 15)\n",
    "\n",
    "for i,indx in enumerate(rise_indices):\n",
    "    print(dp.julian_to_datetime(stage_data[indx,0]))\n",
    "    if(i < len(rise_indices)-1) and dp.julian_to_datetime(stage_data[rise_indices[i+1],0]) - delta15 != dp.julian_to_datetime(stage_data[indx,0]):\n",
    "        print(\"\\n\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2515aa-d62b-4643-83bc-a3bd080137fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in labeled data \n",
    "gt_fname = \"/Users/zachfogg/Desktop/DB-SRRW/Data/manual_annotating_data/processed_data/stage_rises_0k-300k.csv\"\n",
    "\n",
    "gt_data = []\n",
    "with open(gt_fname, 'r', newline = '') as gt_file:\n",
    "    reader = csv.reader(gt_file, delimiter = ',')\n",
    "    for row in reader:\n",
    "        gt_data.append((dp.datetime_to_julian(datetime.datetime.strptime(row[0],\"%Y-%m-%d %H:%M:%S\")),\n",
    "                        dp.datetime_to_julian(datetime.datetime.strptime(row[1],\"%Y-%m-%d %H:%M:%S\"))))\n",
    "    \n",
    "gt_data = np.array(gt_data)\n",
    "\n",
    "iterations = 400 # based on the confidence of parameters optimality desired\n",
    "\n",
    "# Hyper params based on reasonable estimations \n",
    "lag_bounds = (1,20) \n",
    "threshold_bounds = (0,20)\n",
    "influence_bounds = (0,1)                        \n",
    "\n",
    "best_params = {'lag': 0,\n",
    "               'threshold' : 0,\n",
    "               'influence' : 0}\n",
    "\n",
    "max_acc = 0\n",
    "max_result = None\n",
    "max_de_data = None\n",
    "for i in range(iterations):\n",
    "    \n",
    "    # Randomize hyper params within set bounds \n",
    "    lag = np.random.randint(lag_bounds[0], lag_bounds[1]+1)\n",
    "    threshold = np.random.uniform(threshold_bounds[0],threshold_bounds[1])\n",
    "    influence = np.random.uniform(influence_bounds[0],influence_bounds[1])\n",
    "                        \n",
    "    # Generate stage rises\n",
    "    stage_edges = detect_edges(stage_data[:,1], lag, threshold, influence)['signals']\n",
    "    # Process into start and end timestamps for each edge\n",
    "    rise_indices = []\n",
    "    for j in range(len(stage_edges)):\n",
    "        if stage_edges[j] == 1: \n",
    "            rise_indices.append(j)\n",
    "    starts = [stage_data[rise_indices[0],0]]\n",
    "    ends = []\n",
    "    for j,indx in enumerate(rise_indices):\n",
    "        # If this condition is true, then this point is the end of an edge(it can also be the start in case of 1 data point edge)\n",
    "        if(j < len(rise_indices)-1) and rise_indices[j+1] - 1 != indx:\n",
    "            # Designate this point as an end and next point at a start, but also evaluate next point as it could be both a start and an end\n",
    "            ends.append(stage_data[indx,0])\n",
    "            starts.append(stage_data[rise_indices[j+1],0])\n",
    "    ends.append(stage_data[rise_indices[-1],0])\n",
    "    \n",
    "    de_data = np.transpose(np.array((starts,ends)))\n",
    "    \n",
    "    # Algo to compare generated to ground truth \n",
    "    result = determine_stage_rise_metric(de_data,gt_data)\n",
    "    metric = result['metric']\n",
    "    \n",
    "#     if i%10 == 0: \n",
    "#         print('{} Metric: {:.4f}   Lag: {}   Influence: {:.4f}   Threshold: {:.4f}   Max Acc: {:.4f}'.format(i, metric,lag,influence,threshold,max_acc))\n",
    "#         print('TP Rate: {}/{}   FP Rate: {}/{}   FN Rate: {}/{}'.format(result['TP'],len(starts), result['FP'], len(starts), result['FN'], gt_data.shape[0]))\n",
    "        \n",
    "    if metric > max_acc:\n",
    "        max_acc = metric\n",
    "        best_params['lag'] = lag\n",
    "        best_params['threshold'] = threshold \n",
    "        best_params['influence'] = influence\n",
    "        max_result = result\n",
    "        max_de_data = de_data\n",
    "        \n",
    "        print(\"New Max:\")\n",
    "        print('{} Metric: {:.4f}   Lag: {}   Influence: {:.4f}   Threshold: {:.4f}   Max Acc: {:.4f}'.format(i, metric,lag,influence,threshold,max_acc))\n",
    "        print('TP Rate: {}/{}   FP Rate: {}/{}   FN Rate: {}/{}'.format(result['TP'],len(starts), result['FP'], len(starts), result['FN'], gt_data.shape[0]))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "# Write out data to file \n",
    "out_fname = './Stage_Rise_Hyperparam_Opt.txt'\n",
    "\n",
    "with open(out_fname, \"w\") as out_file:\n",
    "    out_file.write('Max Metric Achieved: {:.3f}\\n'.format(max_acc))\n",
    "    out_file.write('Lag: {} , Influence: {:.6f} , Theshold: {:.6f}\\n'.format(best_params['lag'], best_params['influence'], best_params['threshold']))\n",
    "    out_file.write('TP Rate: {}/{}   FP Rate: {}/{}   FN Rate: {}/{}\\n'.format(max_result['TP'],\n",
    "                                                                               max_result['TP'] + max_result['FP'], \n",
    "                                                                               max_result['FP'], \n",
    "                                                                               max_result['TP'] + max_result['FP'], \n",
    "                                                                               max_result['FN'], \n",
    "                                                                               gt_data.shape[0]))\n",
    "# Pickle list/array data \n",
    "results_dict = {'de_determ' : max_result['de_determ'],\n",
    "                'gt_determ' : max_result['gt_determ'],\n",
    "                'de_data' : de_data,\n",
    "                'gt_data' : gt_data}\n",
    "\n",
    "with open('./Stage_Rise_Hyperparam_Pickle.pkl', 'wb') as pck_file:\n",
    "    pickle.dump(results_dict, pck_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "abdda509-2d13-4526-b8be-d787278d58c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Stage_Rise_Hyperparam_Pickle.pkl', 'rb') as in_file:\n",
    "    result_dict = pickle.load(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "bf8eef5f-ae7a-4530-9540-48168095ddcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot most accurate\n",
    "# {'lag': 57, 'threshold': 3.7924543867919214, 'influence': 0.0035763313257395346}\n",
    "# Generate stage rises again by using best params \n",
    "stage_edge_indices = detect_edges(stage_data[:,1], best_params['lag'], best_params['threshold'], best_params['influence'])['signals']\n",
    "\n",
    "take_indices = []\n",
    "for i in range(len(stage_edge_indices)):\n",
    "    if stage_edge_indices[i] == 1:\n",
    "        take_indices.append(i)\n",
    "stage_edge_data = np.take(stage_data,take_indices, 0)\n",
    "stage_data_merged = dp.merge_data(stage_data, stage_edge_data, 'rise','')\n",
    "\n",
    "fDOM_merged = dp.add_flags(fDOM_raw_data, '')\n",
    "turb_merged = dp.add_flags(turb_data,'')\n",
    "\n",
    "# Write out to trainset \n",
    "dm.write_data_to_trainset(fDOM_merged,\n",
    "                          stage_data_merged,\n",
    "                          turb_merged,\n",
    "                          '/Users/zachfogg/Desktop/DB-SRRW/Data/manual_annotating_data/non_annotated_data/stage_rise_search_0k-100k.csv',\n",
    "                          True,\n",
    "                          True,\n",
    "                          0,\n",
    "                          100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6f7e5e8-11ec-4a78-a398-f67ff89f8eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_edge(edge_1 : np.ndarray, edge_2 : np.ndarray) -> int:\n",
    "    \"\"\"\n",
    "    Compare edge_1 to edge_2 to see if edge_1 intersects \n",
    "    with edge_2, appears before edge_2, or appears after edge_2\n",
    "    \n",
    "    edge_1 : edge in timeseries represented by start and end timestamp (julian time)\n",
    "    edge_2 : edge in timeseries represented by start and end timestamp (julian time)\n",
    "    return : -1 == edge_1 comes before edge_2 \n",
    "              0 == edge_1 intersects with edge_2 \n",
    "              1 == edge_1 comes after edge_2 \n",
    "    \"\"\"\n",
    "    # If start or end of edge_1 is within/equal start and end of edge_2, then match\n",
    "    # If start e1 before start e2 and end e1 after end e2, then match\n",
    "    if ((edge_1[0] >= edge_2[0] and edge_1[0] <= edge_2[1]) \n",
    "        or (edge_1[1] >= edge_2[0] and edge_1[1] <= edge_2[1])\n",
    "        or edge_1[0] < edge_2[0] and edge_1[1] > edge_2[1]): \n",
    "        return 0 \n",
    "    # If end of edge_1 is before or equal to start of edge_2, then before \n",
    "    elif edge_1[1] <= edge_2[0]:\n",
    "        return -1 \n",
    "    elif edge_1[0] >= edge_2[1]:\n",
    "        return 1\n",
    "    else: \n",
    "        print(dp.julian_to_datetime(edge_1[0]), \" \", dp.julian_to_datetime(edge_1[1]))\n",
    "        print(dp.julian_to_datetime(edge_2[0]), \" \", dp.julian_to_datetime(edge_2[1]))\n",
    "        raise IndexError(\"No determination made on edge\")\n",
    "# 2012-05-16 16:30:00   2012-05-16 17:30:00\n",
    "# 2012-05-16 16:45:00   2012-05-16 17:15:00\n",
    "def event_binary_search(single_edge, list_edges):\n",
    "    \"\"\" \n",
    "    Given a single edge and a sorted list of edges,\n",
    "    use binary search like algorithm to find a possible \n",
    "    match if it exists\n",
    "    \"\"\"\n",
    "    if list_edges.shape[0] == 0 :\n",
    "        return False\n",
    "    mid = math.ceil(len(list_edges)/2) - 1\n",
    "    result = compare_edge(single_edge, list_edges[mid])\n",
    "    if result == 0:\n",
    "        return True\n",
    "    elif result == 1:\n",
    "        return event_binary_search(single_edge, list_edges[mid+1:len(list_edges)])\n",
    "    else:\n",
    "        return event_binary_search(single_edge, list_edges[0:mid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb0389c7-8070-4351-a8ac-751bed5c5524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_stage_rise_metric(list_de, list_gt):\n",
    "    \"\"\"\n",
    "    Given a list of detected edges(de) and a list of ground truth edges(gt)\n",
    "    determine the accuracy of the detected edges... Not sure by what metric yet \n",
    "    A de can either be a TP or FP. If a gt edge has no corresponding de edge, then\n",
    "    the gt edge becomes a FN in the de list. NLog(N) time complexity\n",
    "    \n",
    "    list_de: list of detected edges to compare to ground truth  \n",
    "    list_gt: list of ground truth edges by which to judge the detected edges \n",
    "    \n",
    "    return: dict containing: overall accuracy of detected edges \n",
    "                             list_de with determinations attached to each edge (TP,FP)\n",
    "                             list_gt with determination attached to each edge (FN, NFN(Not False Negative))\n",
    "    \"\"\"\n",
    "    \n",
    "    # Determine FP,TP in detected edges \n",
    "    de_determinations = []\n",
    "    for i, edge in enumerate(list_de):\n",
    "        result = event_binary_search(edge, list_gt)\n",
    "        if result:\n",
    "            de_determinations.append('TP')\n",
    "        else:\n",
    "            de_determinations.append('FP')\n",
    "    \n",
    "    # Determine FN in detected edges \n",
    "    gt_determinations = []\n",
    "    for i, edge in enumerate(list_gt):\n",
    "        result = event_binary_search(edge, list_de)\n",
    "        if result:\n",
    "            gt_determinations.append('NFN')\n",
    "        else:\n",
    "            gt_determinations.append('FN')\n",
    "     \n",
    "    # Use determinations to calculate accuracy metric of some sort \n",
    "    FP = de_determinations.count('FP')\n",
    "    TP = de_determinations.count('TP')\n",
    "    FN = gt_determinations.count('FN')\n",
    "    \n",
    "    FN_weight = 1.0\n",
    "    FP_weight = 1.0\n",
    "    \n",
    "    metric = TP/(TP+(FN * FN_weight) + (FP * FP_weight))\n",
    "    \n",
    "    return {'metric' : metric,\n",
    "                'de_determ' : de_determinations,\n",
    "                'gt_determ' : gt_determinations,\n",
    "                'FP' : FP,\n",
    "                'TP' : TP,\n",
    "                'FN' : FN}\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fc53a938-4765-4db5-877d-b89b9bffbac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1,2,3,1,1,2,3]\n",
    "x.count(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
