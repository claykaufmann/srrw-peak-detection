{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turbidity Deep Learning Peak Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "from sklearn import preprocessing\n",
    "from resnet import ResNet1D\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torchsummary import summary\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    f1_score,\n",
    "    balanced_accuracy_score,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "sys.path.insert(1, \"../\")\n",
    "\n",
    "from datasets import turbidityDataset, turbAugOnlyDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "WINDOW_SIZE = 15  # the size of each data segment\n",
    "TEST_SIZE = 0.10\n",
    "SEED = 42\n",
    "BATCH_SIZE = 32\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to data files\n",
    "fdom_raw_data = \"../Data/converted_data/julian_format/fDOM_raw_10.1.2011-9.4.2020.csv\"\n",
    "stage_raw_data = \"../Data/converted_data/julian_format/stage_10.1.11-1.1.19.csv\"\n",
    "turb_raw_data = (\n",
    "    \"../Data/converted_data/julian_format/turbidity_raw_10.1.2011_9.4.2020.csv\"\n",
    ")\n",
    "\n",
    "turb_labeled = \"../Data/labeled_data/ground_truths/turb/turb_all_julian_0k-300k.csv\"\n",
    "\n",
    "fdom_raw_augmented = \"../Data/augmented_data/turb/unlabeled/unlabeled_fdom.csv\"\n",
    "turb_labeled_augmented = \"../Data/augmented_data/turb/labeled/labeled_turb_peaks.csv\"\n",
    "\n",
    "turb_augmented_raw_data = \"../Data/augmented_data/turb/unlabeled/unlabeled_turb.csv\"\n",
    "\n",
    "stage_augmented_data_fn = \"../Data/augmented_data/turb/unlabeled/unlabeled_stage.csv\"\n",
    "\n",
    "turb_fpt_lookup_path = \"../Data/augmented_data/turb/fpt_lookup.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# get device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3169 candidates found in class-balanced augmented dataset.\n",
      "1253 candidates found in test dataset.\n"
     ]
    }
   ],
   "source": [
    "classes = [\"NAP\", \"FPT\", \"PP\", \"SKP\"]\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "targets = le.fit_transform(classes)\n",
    "\n",
    "train_dataset = turbAugOnlyDataset(\n",
    "    le,\n",
    "    fdom_raw_augmented,\n",
    "    stage_augmented_data_fn,\n",
    "    turb_augmented_raw_data,\n",
    "    turb_labeled_augmented,\n",
    "    turb_fpt_lookup_path,\n",
    "    WINDOW_SIZE,\n",
    ")\n",
    "\n",
    "test_dataset = turbidityDataset(\n",
    "    le,\n",
    "    fdom_raw_data,\n",
    "    stage_raw_data,\n",
    "    turb_raw_data,\n",
    "    turb_labeled,\n",
    "    window_size=WINDOW_SIZE,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collate function\n",
    "\n",
    "This pads the dataset so we can use variable length peak data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_pad(batch):\n",
    "    \"\"\"\n",
    "    Pads batch of variable length\n",
    "    \"\"\"\n",
    "\n",
    "    label_list, sample_list, lengths = [], [], []\n",
    "\n",
    "    for (sample, label) in batch:\n",
    "        label_list.append(label)\n",
    "        # convert sample to tensor\n",
    "        sample = torch.tensor(\n",
    "            sample, dtype=torch.float64\n",
    "        ).T  # tranpose to send in data, pad_sequences won't accept original\n",
    "\n",
    "        # append to lengths\n",
    "        lengths.append(sample.shape[0])\n",
    "\n",
    "        sample_list.append(sample)\n",
    "\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "\n",
    "    sample_list = torch.nn.utils.rnn.pad_sequence(\n",
    "        sample_list, batch_first=True, padding_value=0\n",
    "    )\n",
    "\n",
    "    # re-tranpose list, so we go back to a 4 channel dataset\n",
    "    sample_list = sample_list.transpose(1, 2)\n",
    "\n",
    "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
    "\n",
    "    return [sample_list.to(device), label_list.to(device), lengths]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloaders\n",
    "\n",
    "These batchify the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training / testing\n",
    "# train_size = int(0.85 * len(dataset))\n",
    "# test_size = len(dataset) - train_size\n",
    "# train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# create dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn_pad\n",
    ")\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn_pad\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1              [-1, 64, 716]           4,160\n",
      "   MyConv1dPadSame-2              [-1, 64, 716]               0\n",
      "       BatchNorm1d-3              [-1, 64, 716]             128\n",
      "              ReLU-4              [-1, 64, 716]               0\n",
      "            Conv1d-5              [-1, 64, 716]          65,600\n",
      "   MyConv1dPadSame-6              [-1, 64, 716]               0\n",
      "       BatchNorm1d-7              [-1, 64, 716]             128\n",
      "              ReLU-8              [-1, 64, 716]               0\n",
      "           Dropout-9              [-1, 64, 716]               0\n",
      "           Conv1d-10              [-1, 64, 716]          65,600\n",
      "  MyConv1dPadSame-11              [-1, 64, 716]               0\n",
      "       BasicBlock-12              [-1, 64, 716]               0\n",
      "      BatchNorm1d-13              [-1, 64, 716]             128\n",
      "             ReLU-14              [-1, 64, 716]               0\n",
      "          Dropout-15              [-1, 64, 716]               0\n",
      "           Conv1d-16              [-1, 64, 358]          65,600\n",
      "  MyConv1dPadSame-17              [-1, 64, 358]               0\n",
      "      BatchNorm1d-18              [-1, 64, 358]             128\n",
      "             ReLU-19              [-1, 64, 358]               0\n",
      "          Dropout-20              [-1, 64, 358]               0\n",
      "           Conv1d-21              [-1, 64, 358]          65,600\n",
      "  MyConv1dPadSame-22              [-1, 64, 358]               0\n",
      "        MaxPool1d-23              [-1, 64, 358]               0\n",
      "MyMaxPool1dPadSame-24              [-1, 64, 358]               0\n",
      "       BasicBlock-25              [-1, 64, 358]               0\n",
      "      BatchNorm1d-26              [-1, 64, 358]             128\n",
      "             ReLU-27              [-1, 64, 358]               0\n",
      "          Dropout-28              [-1, 64, 358]               0\n",
      "           Conv1d-29              [-1, 64, 358]          65,600\n",
      "  MyConv1dPadSame-30              [-1, 64, 358]               0\n",
      "      BatchNorm1d-31              [-1, 64, 358]             128\n",
      "             ReLU-32              [-1, 64, 358]               0\n",
      "          Dropout-33              [-1, 64, 358]               0\n",
      "           Conv1d-34              [-1, 64, 358]          65,600\n",
      "  MyConv1dPadSame-35              [-1, 64, 358]               0\n",
      "       BasicBlock-36              [-1, 64, 358]               0\n",
      "      BatchNorm1d-37              [-1, 64, 358]             128\n",
      "             ReLU-38              [-1, 64, 358]               0\n",
      "          Dropout-39              [-1, 64, 358]               0\n",
      "           Conv1d-40              [-1, 64, 358]          65,600\n",
      "  MyConv1dPadSame-41              [-1, 64, 358]               0\n",
      "      BatchNorm1d-42              [-1, 64, 358]             128\n",
      "             ReLU-43              [-1, 64, 358]               0\n",
      "          Dropout-44              [-1, 64, 358]               0\n",
      "           Conv1d-45              [-1, 64, 358]          65,600\n",
      "  MyConv1dPadSame-46              [-1, 64, 358]               0\n",
      "       BasicBlock-47              [-1, 64, 358]               0\n",
      "      BatchNorm1d-48              [-1, 64, 358]             128\n",
      "             ReLU-49              [-1, 64, 358]               0\n",
      "          Dropout-50              [-1, 64, 358]               0\n",
      "           Conv1d-51              [-1, 64, 358]          65,600\n",
      "  MyConv1dPadSame-52              [-1, 64, 358]               0\n",
      "      BatchNorm1d-53              [-1, 64, 358]             128\n",
      "             ReLU-54              [-1, 64, 358]               0\n",
      "          Dropout-55              [-1, 64, 358]               0\n",
      "           Conv1d-56              [-1, 64, 358]          65,600\n",
      "  MyConv1dPadSame-57              [-1, 64, 358]               0\n",
      "       BasicBlock-58              [-1, 64, 358]               0\n",
      "      BatchNorm1d-59              [-1, 64, 358]             128\n",
      "             ReLU-60              [-1, 64, 358]               0\n",
      "          Dropout-61              [-1, 64, 358]               0\n",
      "           Conv1d-62              [-1, 64, 358]          65,600\n",
      "  MyConv1dPadSame-63              [-1, 64, 358]               0\n",
      "      BatchNorm1d-64              [-1, 64, 358]             128\n",
      "             ReLU-65              [-1, 64, 358]               0\n",
      "          Dropout-66              [-1, 64, 358]               0\n",
      "           Conv1d-67              [-1, 64, 358]          65,600\n",
      "  MyConv1dPadSame-68              [-1, 64, 358]               0\n",
      "       BasicBlock-69              [-1, 64, 358]               0\n",
      "      BatchNorm1d-70              [-1, 64, 358]             128\n",
      "             ReLU-71              [-1, 64, 358]               0\n",
      "          Dropout-72              [-1, 64, 358]               0\n",
      "           Conv1d-73              [-1, 64, 358]          65,600\n",
      "  MyConv1dPadSame-74              [-1, 64, 358]               0\n",
      "      BatchNorm1d-75              [-1, 64, 358]             128\n",
      "             ReLU-76              [-1, 64, 358]               0\n",
      "          Dropout-77              [-1, 64, 358]               0\n",
      "           Conv1d-78              [-1, 64, 358]          65,600\n",
      "  MyConv1dPadSame-79              [-1, 64, 358]               0\n",
      "       BasicBlock-80              [-1, 64, 358]               0\n",
      "      BatchNorm1d-81              [-1, 64, 358]             128\n",
      "             ReLU-82              [-1, 64, 358]               0\n",
      "          Dropout-83              [-1, 64, 358]               0\n",
      "           Conv1d-84              [-1, 64, 179]          65,600\n",
      "  MyConv1dPadSame-85              [-1, 64, 179]               0\n",
      "      BatchNorm1d-86              [-1, 64, 179]             128\n",
      "             ReLU-87              [-1, 64, 179]               0\n",
      "          Dropout-88              [-1, 64, 179]               0\n",
      "           Conv1d-89              [-1, 64, 179]          65,600\n",
      "  MyConv1dPadSame-90              [-1, 64, 179]               0\n",
      "        MaxPool1d-91              [-1, 64, 179]               0\n",
      "MyMaxPool1dPadSame-92              [-1, 64, 179]               0\n",
      "       BasicBlock-93              [-1, 64, 179]               0\n",
      "      BatchNorm1d-94              [-1, 64, 179]             128\n",
      "             ReLU-95              [-1, 64, 179]               0\n",
      "          Dropout-96              [-1, 64, 179]               0\n",
      "           Conv1d-97              [-1, 64, 179]          65,600\n",
      "  MyConv1dPadSame-98              [-1, 64, 179]               0\n",
      "      BatchNorm1d-99              [-1, 64, 179]             128\n",
      "            ReLU-100              [-1, 64, 179]               0\n",
      "         Dropout-101              [-1, 64, 179]               0\n",
      "          Conv1d-102              [-1, 64, 179]          65,600\n",
      " MyConv1dPadSame-103              [-1, 64, 179]               0\n",
      "      BasicBlock-104              [-1, 64, 179]               0\n",
      "     BatchNorm1d-105              [-1, 64, 179]             128\n",
      "            ReLU-106              [-1, 64, 179]               0\n",
      "         Dropout-107              [-1, 64, 179]               0\n",
      "          Conv1d-108              [-1, 64, 179]          65,600\n",
      " MyConv1dPadSame-109              [-1, 64, 179]               0\n",
      "     BatchNorm1d-110              [-1, 64, 179]             128\n",
      "            ReLU-111              [-1, 64, 179]               0\n",
      "         Dropout-112              [-1, 64, 179]               0\n",
      "          Conv1d-113              [-1, 64, 179]          65,600\n",
      " MyConv1dPadSame-114              [-1, 64, 179]               0\n",
      "      BasicBlock-115              [-1, 64, 179]               0\n",
      "     BatchNorm1d-116              [-1, 64, 179]             128\n",
      "            ReLU-117              [-1, 64, 179]               0\n",
      "         Dropout-118              [-1, 64, 179]               0\n",
      "          Conv1d-119              [-1, 64, 179]          65,600\n",
      " MyConv1dPadSame-120              [-1, 64, 179]               0\n",
      "     BatchNorm1d-121              [-1, 64, 179]             128\n",
      "            ReLU-122              [-1, 64, 179]               0\n",
      "         Dropout-123              [-1, 64, 179]               0\n",
      "          Conv1d-124              [-1, 64, 179]          65,600\n",
      " MyConv1dPadSame-125              [-1, 64, 179]               0\n",
      "      BasicBlock-126              [-1, 64, 179]               0\n",
      "     BatchNorm1d-127              [-1, 64, 179]             128\n",
      "            ReLU-128              [-1, 64, 179]               0\n",
      "         Dropout-129              [-1, 64, 179]               0\n",
      "          Conv1d-130              [-1, 64, 179]          65,600\n",
      " MyConv1dPadSame-131              [-1, 64, 179]               0\n",
      "     BatchNorm1d-132              [-1, 64, 179]             128\n",
      "            ReLU-133              [-1, 64, 179]               0\n",
      "         Dropout-134              [-1, 64, 179]               0\n",
      "          Conv1d-135              [-1, 64, 179]          65,600\n",
      " MyConv1dPadSame-136              [-1, 64, 179]               0\n",
      "      BasicBlock-137              [-1, 64, 179]               0\n",
      "     BatchNorm1d-138              [-1, 64, 179]             128\n",
      "            ReLU-139              [-1, 64, 179]               0\n",
      "         Dropout-140              [-1, 64, 179]               0\n",
      "          Conv1d-141             [-1, 128, 179]         131,200\n",
      " MyConv1dPadSame-142             [-1, 128, 179]               0\n",
      "     BatchNorm1d-143             [-1, 128, 179]             256\n",
      "            ReLU-144             [-1, 128, 179]               0\n",
      "         Dropout-145             [-1, 128, 179]               0\n",
      "          Conv1d-146             [-1, 128, 179]         262,272\n",
      " MyConv1dPadSame-147             [-1, 128, 179]               0\n",
      "      BasicBlock-148             [-1, 128, 179]               0\n",
      "     BatchNorm1d-149             [-1, 128, 179]             256\n",
      "            ReLU-150             [-1, 128, 179]               0\n",
      "         Dropout-151             [-1, 128, 179]               0\n",
      "          Conv1d-152              [-1, 128, 90]         262,272\n",
      " MyConv1dPadSame-153              [-1, 128, 90]               0\n",
      "     BatchNorm1d-154              [-1, 128, 90]             256\n",
      "            ReLU-155              [-1, 128, 90]               0\n",
      "         Dropout-156              [-1, 128, 90]               0\n",
      "          Conv1d-157              [-1, 128, 90]         262,272\n",
      " MyConv1dPadSame-158              [-1, 128, 90]               0\n",
      "       MaxPool1d-159              [-1, 128, 90]               0\n",
      "MyMaxPool1dPadSame-160              [-1, 128, 90]               0\n",
      "      BasicBlock-161              [-1, 128, 90]               0\n",
      "     BatchNorm1d-162              [-1, 128, 90]             256\n",
      "            ReLU-163              [-1, 128, 90]               0\n",
      "         Dropout-164              [-1, 128, 90]               0\n",
      "          Conv1d-165              [-1, 128, 90]         262,272\n",
      " MyConv1dPadSame-166              [-1, 128, 90]               0\n",
      "     BatchNorm1d-167              [-1, 128, 90]             256\n",
      "            ReLU-168              [-1, 128, 90]               0\n",
      "         Dropout-169              [-1, 128, 90]               0\n",
      "          Conv1d-170              [-1, 128, 90]         262,272\n",
      " MyConv1dPadSame-171              [-1, 128, 90]               0\n",
      "      BasicBlock-172              [-1, 128, 90]               0\n",
      "     BatchNorm1d-173              [-1, 128, 90]             256\n",
      "            ReLU-174              [-1, 128, 90]               0\n",
      "         Dropout-175              [-1, 128, 90]               0\n",
      "          Conv1d-176              [-1, 128, 90]         262,272\n",
      " MyConv1dPadSame-177              [-1, 128, 90]               0\n",
      "     BatchNorm1d-178              [-1, 128, 90]             256\n",
      "            ReLU-179              [-1, 128, 90]               0\n",
      "         Dropout-180              [-1, 128, 90]               0\n",
      "          Conv1d-181              [-1, 128, 90]         262,272\n",
      " MyConv1dPadSame-182              [-1, 128, 90]               0\n",
      "      BasicBlock-183              [-1, 128, 90]               0\n",
      "     BatchNorm1d-184              [-1, 128, 90]             256\n",
      "            ReLU-185              [-1, 128, 90]               0\n",
      "         Dropout-186              [-1, 128, 90]               0\n",
      "          Conv1d-187              [-1, 128, 90]         262,272\n",
      " MyConv1dPadSame-188              [-1, 128, 90]               0\n",
      "     BatchNorm1d-189              [-1, 128, 90]             256\n",
      "            ReLU-190              [-1, 128, 90]               0\n",
      "         Dropout-191              [-1, 128, 90]               0\n",
      "          Conv1d-192              [-1, 128, 90]         262,272\n",
      " MyConv1dPadSame-193              [-1, 128, 90]               0\n",
      "      BasicBlock-194              [-1, 128, 90]               0\n",
      "     BatchNorm1d-195              [-1, 128, 90]             256\n",
      "            ReLU-196              [-1, 128, 90]               0\n",
      "         Dropout-197              [-1, 128, 90]               0\n",
      "          Conv1d-198              [-1, 128, 90]         262,272\n",
      " MyConv1dPadSame-199              [-1, 128, 90]               0\n",
      "     BatchNorm1d-200              [-1, 128, 90]             256\n",
      "            ReLU-201              [-1, 128, 90]               0\n",
      "         Dropout-202              [-1, 128, 90]               0\n",
      "          Conv1d-203              [-1, 128, 90]         262,272\n",
      " MyConv1dPadSame-204              [-1, 128, 90]               0\n",
      "      BasicBlock-205              [-1, 128, 90]               0\n",
      "     BatchNorm1d-206              [-1, 128, 90]             256\n",
      "            ReLU-207              [-1, 128, 90]               0\n",
      "         Dropout-208              [-1, 128, 90]               0\n",
      "          Conv1d-209              [-1, 128, 90]         262,272\n",
      " MyConv1dPadSame-210              [-1, 128, 90]               0\n",
      "     BatchNorm1d-211              [-1, 128, 90]             256\n",
      "            ReLU-212              [-1, 128, 90]               0\n",
      "         Dropout-213              [-1, 128, 90]               0\n",
      "          Conv1d-214              [-1, 128, 90]         262,272\n",
      " MyConv1dPadSame-215              [-1, 128, 90]               0\n",
      "      BasicBlock-216              [-1, 128, 90]               0\n",
      "     BatchNorm1d-217              [-1, 128, 90]             256\n",
      "            ReLU-218              [-1, 128, 90]               0\n",
      "         Dropout-219              [-1, 128, 90]               0\n",
      "          Conv1d-220              [-1, 128, 45]         262,272\n",
      " MyConv1dPadSame-221              [-1, 128, 45]               0\n",
      "     BatchNorm1d-222              [-1, 128, 45]             256\n",
      "            ReLU-223              [-1, 128, 45]               0\n",
      "         Dropout-224              [-1, 128, 45]               0\n",
      "          Conv1d-225              [-1, 128, 45]         262,272\n",
      " MyConv1dPadSame-226              [-1, 128, 45]               0\n",
      "       MaxPool1d-227              [-1, 128, 45]               0\n",
      "MyMaxPool1dPadSame-228              [-1, 128, 45]               0\n",
      "      BasicBlock-229              [-1, 128, 45]               0\n",
      "     BatchNorm1d-230              [-1, 128, 45]             256\n",
      "            ReLU-231              [-1, 128, 45]               0\n",
      "         Dropout-232              [-1, 128, 45]               0\n",
      "          Conv1d-233              [-1, 128, 45]         262,272\n",
      " MyConv1dPadSame-234              [-1, 128, 45]               0\n",
      "     BatchNorm1d-235              [-1, 128, 45]             256\n",
      "            ReLU-236              [-1, 128, 45]               0\n",
      "         Dropout-237              [-1, 128, 45]               0\n",
      "          Conv1d-238              [-1, 128, 45]         262,272\n",
      " MyConv1dPadSame-239              [-1, 128, 45]               0\n",
      "      BasicBlock-240              [-1, 128, 45]               0\n",
      "     BatchNorm1d-241              [-1, 128, 45]             256\n",
      "            ReLU-242              [-1, 128, 45]               0\n",
      "         Dropout-243              [-1, 128, 45]               0\n",
      "          Conv1d-244              [-1, 128, 45]         262,272\n",
      " MyConv1dPadSame-245              [-1, 128, 45]               0\n",
      "     BatchNorm1d-246              [-1, 128, 45]             256\n",
      "            ReLU-247              [-1, 128, 45]               0\n",
      "         Dropout-248              [-1, 128, 45]               0\n",
      "          Conv1d-249              [-1, 128, 45]         262,272\n",
      " MyConv1dPadSame-250              [-1, 128, 45]               0\n",
      "      BasicBlock-251              [-1, 128, 45]               0\n",
      "     BatchNorm1d-252              [-1, 128, 45]             256\n",
      "            ReLU-253              [-1, 128, 45]               0\n",
      "         Dropout-254              [-1, 128, 45]               0\n",
      "          Conv1d-255              [-1, 128, 45]         262,272\n",
      " MyConv1dPadSame-256              [-1, 128, 45]               0\n",
      "     BatchNorm1d-257              [-1, 128, 45]             256\n",
      "            ReLU-258              [-1, 128, 45]               0\n",
      "         Dropout-259              [-1, 128, 45]               0\n",
      "          Conv1d-260              [-1, 128, 45]         262,272\n",
      " MyConv1dPadSame-261              [-1, 128, 45]               0\n",
      "      BasicBlock-262              [-1, 128, 45]               0\n",
      "     BatchNorm1d-263              [-1, 128, 45]             256\n",
      "            ReLU-264              [-1, 128, 45]               0\n",
      "         Dropout-265              [-1, 128, 45]               0\n",
      "          Conv1d-266              [-1, 128, 45]         262,272\n",
      " MyConv1dPadSame-267              [-1, 128, 45]               0\n",
      "     BatchNorm1d-268              [-1, 128, 45]             256\n",
      "            ReLU-269              [-1, 128, 45]               0\n",
      "         Dropout-270              [-1, 128, 45]               0\n",
      "          Conv1d-271              [-1, 128, 45]         262,272\n",
      " MyConv1dPadSame-272              [-1, 128, 45]               0\n",
      "      BasicBlock-273              [-1, 128, 45]               0\n",
      "     BatchNorm1d-274              [-1, 128, 45]             256\n",
      "            ReLU-275              [-1, 128, 45]               0\n",
      "         Dropout-276              [-1, 128, 45]               0\n",
      "          Conv1d-277              [-1, 256, 45]         524,544\n",
      " MyConv1dPadSame-278              [-1, 256, 45]               0\n",
      "     BatchNorm1d-279              [-1, 256, 45]             512\n",
      "            ReLU-280              [-1, 256, 45]               0\n",
      "         Dropout-281              [-1, 256, 45]               0\n",
      "          Conv1d-282              [-1, 256, 45]       1,048,832\n",
      " MyConv1dPadSame-283              [-1, 256, 45]               0\n",
      "      BasicBlock-284              [-1, 256, 45]               0\n",
      "     BatchNorm1d-285              [-1, 256, 45]             512\n",
      "            ReLU-286              [-1, 256, 45]               0\n",
      "         Dropout-287              [-1, 256, 45]               0\n",
      "          Conv1d-288              [-1, 256, 23]       1,048,832\n",
      " MyConv1dPadSame-289              [-1, 256, 23]               0\n",
      "     BatchNorm1d-290              [-1, 256, 23]             512\n",
      "            ReLU-291              [-1, 256, 23]               0\n",
      "         Dropout-292              [-1, 256, 23]               0\n",
      "          Conv1d-293              [-1, 256, 23]       1,048,832\n",
      " MyConv1dPadSame-294              [-1, 256, 23]               0\n",
      "       MaxPool1d-295              [-1, 256, 23]               0\n",
      "MyMaxPool1dPadSame-296              [-1, 256, 23]               0\n",
      "      BasicBlock-297              [-1, 256, 23]               0\n",
      "     BatchNorm1d-298              [-1, 256, 23]             512\n",
      "            ReLU-299              [-1, 256, 23]               0\n",
      "         Dropout-300              [-1, 256, 23]               0\n",
      "          Conv1d-301              [-1, 256, 23]       1,048,832\n",
      " MyConv1dPadSame-302              [-1, 256, 23]               0\n",
      "     BatchNorm1d-303              [-1, 256, 23]             512\n",
      "            ReLU-304              [-1, 256, 23]               0\n",
      "         Dropout-305              [-1, 256, 23]               0\n",
      "          Conv1d-306              [-1, 256, 23]       1,048,832\n",
      " MyConv1dPadSame-307              [-1, 256, 23]               0\n",
      "      BasicBlock-308              [-1, 256, 23]               0\n",
      "     BatchNorm1d-309              [-1, 256, 23]             512\n",
      "            ReLU-310              [-1, 256, 23]               0\n",
      "         Dropout-311              [-1, 256, 23]               0\n",
      "          Conv1d-312              [-1, 256, 23]       1,048,832\n",
      " MyConv1dPadSame-313              [-1, 256, 23]               0\n",
      "     BatchNorm1d-314              [-1, 256, 23]             512\n",
      "            ReLU-315              [-1, 256, 23]               0\n",
      "         Dropout-316              [-1, 256, 23]               0\n",
      "          Conv1d-317              [-1, 256, 23]       1,048,832\n",
      " MyConv1dPadSame-318              [-1, 256, 23]               0\n",
      "      BasicBlock-319              [-1, 256, 23]               0\n",
      "     BatchNorm1d-320              [-1, 256, 23]             512\n",
      "            ReLU-321              [-1, 256, 23]               0\n",
      "         Dropout-322              [-1, 256, 23]               0\n",
      "          Conv1d-323              [-1, 256, 23]       1,048,832\n",
      " MyConv1dPadSame-324              [-1, 256, 23]               0\n",
      "     BatchNorm1d-325              [-1, 256, 23]             512\n",
      "            ReLU-326              [-1, 256, 23]               0\n",
      "         Dropout-327              [-1, 256, 23]               0\n",
      "          Conv1d-328              [-1, 256, 23]       1,048,832\n",
      " MyConv1dPadSame-329              [-1, 256, 23]               0\n",
      "      BasicBlock-330              [-1, 256, 23]               0\n",
      "     BatchNorm1d-331              [-1, 256, 23]             512\n",
      "            ReLU-332              [-1, 256, 23]               0\n",
      "         Dropout-333              [-1, 256, 23]               0\n",
      "          Conv1d-334              [-1, 256, 23]       1,048,832\n",
      " MyConv1dPadSame-335              [-1, 256, 23]               0\n",
      "     BatchNorm1d-336              [-1, 256, 23]             512\n",
      "            ReLU-337              [-1, 256, 23]               0\n",
      "         Dropout-338              [-1, 256, 23]               0\n",
      "          Conv1d-339              [-1, 256, 23]       1,048,832\n",
      " MyConv1dPadSame-340              [-1, 256, 23]               0\n",
      "      BasicBlock-341              [-1, 256, 23]               0\n",
      "     BatchNorm1d-342              [-1, 256, 23]             512\n",
      "            ReLU-343              [-1, 256, 23]               0\n",
      "         Dropout-344              [-1, 256, 23]               0\n",
      "          Conv1d-345              [-1, 256, 23]       1,048,832\n",
      " MyConv1dPadSame-346              [-1, 256, 23]               0\n",
      "     BatchNorm1d-347              [-1, 256, 23]             512\n",
      "            ReLU-348              [-1, 256, 23]               0\n",
      "         Dropout-349              [-1, 256, 23]               0\n",
      "          Conv1d-350              [-1, 256, 23]       1,048,832\n",
      " MyConv1dPadSame-351              [-1, 256, 23]               0\n",
      "      BasicBlock-352              [-1, 256, 23]               0\n",
      "     BatchNorm1d-353              [-1, 256, 23]             512\n",
      "            ReLU-354              [-1, 256, 23]               0\n",
      "         Dropout-355              [-1, 256, 23]               0\n",
      "          Conv1d-356              [-1, 256, 12]       1,048,832\n",
      " MyConv1dPadSame-357              [-1, 256, 12]               0\n",
      "     BatchNorm1d-358              [-1, 256, 12]             512\n",
      "            ReLU-359              [-1, 256, 12]               0\n",
      "         Dropout-360              [-1, 256, 12]               0\n",
      "          Conv1d-361              [-1, 256, 12]       1,048,832\n",
      " MyConv1dPadSame-362              [-1, 256, 12]               0\n",
      "       MaxPool1d-363              [-1, 256, 12]               0\n",
      "MyMaxPool1dPadSame-364              [-1, 256, 12]               0\n",
      "      BasicBlock-365              [-1, 256, 12]               0\n",
      "     BatchNorm1d-366              [-1, 256, 12]             512\n",
      "            ReLU-367              [-1, 256, 12]               0\n",
      "         Dropout-368              [-1, 256, 12]               0\n",
      "          Conv1d-369              [-1, 256, 12]       1,048,832\n",
      " MyConv1dPadSame-370              [-1, 256, 12]               0\n",
      "     BatchNorm1d-371              [-1, 256, 12]             512\n",
      "            ReLU-372              [-1, 256, 12]               0\n",
      "         Dropout-373              [-1, 256, 12]               0\n",
      "          Conv1d-374              [-1, 256, 12]       1,048,832\n",
      " MyConv1dPadSame-375              [-1, 256, 12]               0\n",
      "      BasicBlock-376              [-1, 256, 12]               0\n",
      "     BatchNorm1d-377              [-1, 256, 12]             512\n",
      "            ReLU-378              [-1, 256, 12]               0\n",
      "         Dropout-379              [-1, 256, 12]               0\n",
      "          Conv1d-380              [-1, 256, 12]       1,048,832\n",
      " MyConv1dPadSame-381              [-1, 256, 12]               0\n",
      "     BatchNorm1d-382              [-1, 256, 12]             512\n",
      "            ReLU-383              [-1, 256, 12]               0\n",
      "         Dropout-384              [-1, 256, 12]               0\n",
      "          Conv1d-385              [-1, 256, 12]       1,048,832\n",
      " MyConv1dPadSame-386              [-1, 256, 12]               0\n",
      "      BasicBlock-387              [-1, 256, 12]               0\n",
      "     BatchNorm1d-388              [-1, 256, 12]             512\n",
      "            ReLU-389              [-1, 256, 12]               0\n",
      "         Dropout-390              [-1, 256, 12]               0\n",
      "          Conv1d-391              [-1, 256, 12]       1,048,832\n",
      " MyConv1dPadSame-392              [-1, 256, 12]               0\n",
      "     BatchNorm1d-393              [-1, 256, 12]             512\n",
      "            ReLU-394              [-1, 256, 12]               0\n",
      "         Dropout-395              [-1, 256, 12]               0\n",
      "          Conv1d-396              [-1, 256, 12]       1,048,832\n",
      " MyConv1dPadSame-397              [-1, 256, 12]               0\n",
      "      BasicBlock-398              [-1, 256, 12]               0\n",
      "     BatchNorm1d-399              [-1, 256, 12]             512\n",
      "            ReLU-400              [-1, 256, 12]               0\n",
      "         Dropout-401              [-1, 256, 12]               0\n",
      "          Conv1d-402              [-1, 256, 12]       1,048,832\n",
      " MyConv1dPadSame-403              [-1, 256, 12]               0\n",
      "     BatchNorm1d-404              [-1, 256, 12]             512\n",
      "            ReLU-405              [-1, 256, 12]               0\n",
      "         Dropout-406              [-1, 256, 12]               0\n",
      "          Conv1d-407              [-1, 256, 12]       1,048,832\n",
      " MyConv1dPadSame-408              [-1, 256, 12]               0\n",
      "      BasicBlock-409              [-1, 256, 12]               0\n",
      "     BatchNorm1d-410              [-1, 256, 12]             512\n",
      "            ReLU-411              [-1, 256, 12]               0\n",
      "         Dropout-412              [-1, 256, 12]               0\n",
      "          Conv1d-413              [-1, 512, 12]       2,097,664\n",
      " MyConv1dPadSame-414              [-1, 512, 12]               0\n",
      "     BatchNorm1d-415              [-1, 512, 12]           1,024\n",
      "            ReLU-416              [-1, 512, 12]               0\n",
      "         Dropout-417              [-1, 512, 12]               0\n",
      "          Conv1d-418              [-1, 512, 12]       4,194,816\n",
      " MyConv1dPadSame-419              [-1, 512, 12]               0\n",
      "      BasicBlock-420              [-1, 512, 12]               0\n",
      "     BatchNorm1d-421              [-1, 512, 12]           1,024\n",
      "            ReLU-422              [-1, 512, 12]               0\n",
      "         Dropout-423              [-1, 512, 12]               0\n",
      "          Conv1d-424               [-1, 512, 6]       4,194,816\n",
      " MyConv1dPadSame-425               [-1, 512, 6]               0\n",
      "     BatchNorm1d-426               [-1, 512, 6]           1,024\n",
      "            ReLU-427               [-1, 512, 6]               0\n",
      "         Dropout-428               [-1, 512, 6]               0\n",
      "          Conv1d-429               [-1, 512, 6]       4,194,816\n",
      " MyConv1dPadSame-430               [-1, 512, 6]               0\n",
      "       MaxPool1d-431               [-1, 512, 6]               0\n",
      "MyMaxPool1dPadSame-432               [-1, 512, 6]               0\n",
      "      BasicBlock-433               [-1, 512, 6]               0\n",
      "     BatchNorm1d-434               [-1, 512, 6]           1,024\n",
      "            ReLU-435               [-1, 512, 6]               0\n",
      "         Dropout-436               [-1, 512, 6]               0\n",
      "          Conv1d-437               [-1, 512, 6]       4,194,816\n",
      " MyConv1dPadSame-438               [-1, 512, 6]               0\n",
      "     BatchNorm1d-439               [-1, 512, 6]           1,024\n",
      "            ReLU-440               [-1, 512, 6]               0\n",
      "         Dropout-441               [-1, 512, 6]               0\n",
      "          Conv1d-442               [-1, 512, 6]       4,194,816\n",
      " MyConv1dPadSame-443               [-1, 512, 6]               0\n",
      "      BasicBlock-444               [-1, 512, 6]               0\n",
      "     BatchNorm1d-445               [-1, 512, 6]           1,024\n",
      "            ReLU-446               [-1, 512, 6]               0\n",
      "         Dropout-447               [-1, 512, 6]               0\n",
      "          Conv1d-448               [-1, 512, 6]       4,194,816\n",
      " MyConv1dPadSame-449               [-1, 512, 6]               0\n",
      "     BatchNorm1d-450               [-1, 512, 6]           1,024\n",
      "            ReLU-451               [-1, 512, 6]               0\n",
      "         Dropout-452               [-1, 512, 6]               0\n",
      "          Conv1d-453               [-1, 512, 6]       4,194,816\n",
      " MyConv1dPadSame-454               [-1, 512, 6]               0\n",
      "      BasicBlock-455               [-1, 512, 6]               0\n",
      "     BatchNorm1d-456               [-1, 512, 6]           1,024\n",
      "            ReLU-457               [-1, 512, 6]               0\n",
      "         Dropout-458               [-1, 512, 6]               0\n",
      "          Conv1d-459               [-1, 512, 6]       4,194,816\n",
      " MyConv1dPadSame-460               [-1, 512, 6]               0\n",
      "     BatchNorm1d-461               [-1, 512, 6]           1,024\n",
      "            ReLU-462               [-1, 512, 6]               0\n",
      "         Dropout-463               [-1, 512, 6]               0\n",
      "          Conv1d-464               [-1, 512, 6]       4,194,816\n",
      " MyConv1dPadSame-465               [-1, 512, 6]               0\n",
      "      BasicBlock-466               [-1, 512, 6]               0\n",
      "     BatchNorm1d-467               [-1, 512, 6]           1,024\n",
      "            ReLU-468               [-1, 512, 6]               0\n",
      "         Dropout-469               [-1, 512, 6]               0\n",
      "          Conv1d-470               [-1, 512, 6]       4,194,816\n",
      " MyConv1dPadSame-471               [-1, 512, 6]               0\n",
      "     BatchNorm1d-472               [-1, 512, 6]           1,024\n",
      "            ReLU-473               [-1, 512, 6]               0\n",
      "         Dropout-474               [-1, 512, 6]               0\n",
      "          Conv1d-475               [-1, 512, 6]       4,194,816\n",
      " MyConv1dPadSame-476               [-1, 512, 6]               0\n",
      "      BasicBlock-477               [-1, 512, 6]               0\n",
      "     BatchNorm1d-478               [-1, 512, 6]           1,024\n",
      "            ReLU-479               [-1, 512, 6]               0\n",
      "         Dropout-480               [-1, 512, 6]               0\n",
      "          Conv1d-481               [-1, 512, 6]       4,194,816\n",
      " MyConv1dPadSame-482               [-1, 512, 6]               0\n",
      "     BatchNorm1d-483               [-1, 512, 6]           1,024\n",
      "            ReLU-484               [-1, 512, 6]               0\n",
      "         Dropout-485               [-1, 512, 6]               0\n",
      "          Conv1d-486               [-1, 512, 6]       4,194,816\n",
      " MyConv1dPadSame-487               [-1, 512, 6]               0\n",
      "      BasicBlock-488               [-1, 512, 6]               0\n",
      "     BatchNorm1d-489               [-1, 512, 6]           1,024\n",
      "            ReLU-490               [-1, 512, 6]               0\n",
      "         Dropout-491               [-1, 512, 6]               0\n",
      "          Conv1d-492               [-1, 512, 3]       4,194,816\n",
      " MyConv1dPadSame-493               [-1, 512, 3]               0\n",
      "     BatchNorm1d-494               [-1, 512, 3]           1,024\n",
      "            ReLU-495               [-1, 512, 3]               0\n",
      "         Dropout-496               [-1, 512, 3]               0\n",
      "          Conv1d-497               [-1, 512, 3]       4,194,816\n",
      " MyConv1dPadSame-498               [-1, 512, 3]               0\n",
      "       MaxPool1d-499               [-1, 512, 3]               0\n",
      "MyMaxPool1dPadSame-500               [-1, 512, 3]               0\n",
      "      BasicBlock-501               [-1, 512, 3]               0\n",
      "     BatchNorm1d-502               [-1, 512, 3]           1,024\n",
      "            ReLU-503               [-1, 512, 3]               0\n",
      "         Dropout-504               [-1, 512, 3]               0\n",
      "          Conv1d-505               [-1, 512, 3]       4,194,816\n",
      " MyConv1dPadSame-506               [-1, 512, 3]               0\n",
      "     BatchNorm1d-507               [-1, 512, 3]           1,024\n",
      "            ReLU-508               [-1, 512, 3]               0\n",
      "         Dropout-509               [-1, 512, 3]               0\n",
      "          Conv1d-510               [-1, 512, 3]       4,194,816\n",
      " MyConv1dPadSame-511               [-1, 512, 3]               0\n",
      "      BasicBlock-512               [-1, 512, 3]               0\n",
      "     BatchNorm1d-513               [-1, 512, 3]           1,024\n",
      "            ReLU-514               [-1, 512, 3]               0\n",
      "         Dropout-515               [-1, 512, 3]               0\n",
      "          Conv1d-516               [-1, 512, 3]       4,194,816\n",
      " MyConv1dPadSame-517               [-1, 512, 3]               0\n",
      "     BatchNorm1d-518               [-1, 512, 3]           1,024\n",
      "            ReLU-519               [-1, 512, 3]               0\n",
      "         Dropout-520               [-1, 512, 3]               0\n",
      "          Conv1d-521               [-1, 512, 3]       4,194,816\n",
      " MyConv1dPadSame-522               [-1, 512, 3]               0\n",
      "      BasicBlock-523               [-1, 512, 3]               0\n",
      "     BatchNorm1d-524               [-1, 512, 3]           1,024\n",
      "            ReLU-525               [-1, 512, 3]               0\n",
      "         Dropout-526               [-1, 512, 3]               0\n",
      "          Conv1d-527               [-1, 512, 3]       4,194,816\n",
      " MyConv1dPadSame-528               [-1, 512, 3]               0\n",
      "     BatchNorm1d-529               [-1, 512, 3]           1,024\n",
      "            ReLU-530               [-1, 512, 3]               0\n",
      "         Dropout-531               [-1, 512, 3]               0\n",
      "          Conv1d-532               [-1, 512, 3]       4,194,816\n",
      " MyConv1dPadSame-533               [-1, 512, 3]               0\n",
      "      BasicBlock-534               [-1, 512, 3]               0\n",
      "     BatchNorm1d-535               [-1, 512, 3]           1,024\n",
      "            ReLU-536               [-1, 512, 3]               0\n",
      "         Dropout-537               [-1, 512, 3]               0\n",
      "          Conv1d-538               [-1, 512, 3]       4,194,816\n",
      " MyConv1dPadSame-539               [-1, 512, 3]               0\n",
      "     BatchNorm1d-540               [-1, 512, 3]           1,024\n",
      "            ReLU-541               [-1, 512, 3]               0\n",
      "         Dropout-542               [-1, 512, 3]               0\n",
      "          Conv1d-543               [-1, 512, 3]       4,194,816\n",
      " MyConv1dPadSame-544               [-1, 512, 3]               0\n",
      "      BasicBlock-545               [-1, 512, 3]               0\n",
      "     BatchNorm1d-546               [-1, 512, 3]           1,024\n",
      "            ReLU-547               [-1, 512, 3]               0\n",
      "          Linear-548                    [-1, 4]           2,052\n",
      "================================================================\n",
      "Total params: 131,016,388\n",
      "Trainable params: 131,016,388\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 40.64\n",
      "Params size (MB): 499.79\n",
      "Estimated Total Size (MB): 540.44\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# init model\n",
    "model = ResNet1D(\n",
    "    in_channels=4,\n",
    "    base_filters=64,\n",
    "    kernel_size=16,\n",
    "    stride=2,\n",
    "    n_block=48,\n",
    "    groups=1,  # check this\n",
    "    n_classes=len(classes),\n",
    "    downsample_gap=6,\n",
    "    increasefilter_gap=12,\n",
    "    verbose=False,\n",
    ").to(device)\n",
    "\n",
    "model = model.float()\n",
    "\n",
    "# print a model summary\n",
    "print(\n",
    "    summary(model, (4, 716))\n",
    ")  # 4 channels, of length (max batch length, set at 716 here, this may be incorrect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer/criterion\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "all_loss = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "\n",
    "Upon completion of training, model weights are saved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    }
   ],
   "source": [
    "prog_bar = tqdm(trainloader, desc=\"Training\", leave=False)\n",
    "for i, batch in enumerate(prog_bar):\n",
    "\n",
    "    # at the end of every training session I tried, the last batch would cause an error, with an incorrect shaped tensor\n",
    "    # skip the last batch to solve this\n",
    "    if i == len(prog_bar) - 1:\n",
    "        break\n",
    "\n",
    "    x = batch[0].to(device)\n",
    "\n",
    "    # squeeze y to flatten predictions into 1d tensor\n",
    "    y = batch[1].squeeze().to(device)\n",
    "\n",
    "    if x.shape[1] != 4:\n",
    "        print(x.shape)\n",
    "\n",
    "    pred = model(x.float())\n",
    "\n",
    "    loss = criterion(pred, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    all_loss.append(loss.item())\n",
    "\n",
    "# save model\n",
    "torch.save(model, \"./results/models/turb/raw/may-fifth.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model\n",
    "\n",
    "Also displays graphics, and saves them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   0%|          | 0/40 [00:00<?, ?it/s]/var/folders/3w/lhkpgfc505n81_2vs8svxfpr0000gn/T/ipykernel_25728/1254555646.py:20: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /Users/runner/miniforge3/conda-bld/pytorch-recipe_1647804309932/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  label_list = torch.tensor(label_list, dtype=torch.int64)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/srrw/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         FPT       0.00      0.00      0.00         2\n",
      "         NAP       0.86      0.50      0.63       915\n",
      "          PP       0.14      0.04      0.07       260\n",
      "         SKP       0.10      0.84      0.18        76\n",
      "\n",
      "    accuracy                           0.42      1253\n",
      "   macro avg       0.28      0.34      0.22      1253\n",
      "weighted avg       0.66      0.42      0.48      1253\n",
      "\n",
      "Balanced accuracy: 0.3448737306696754\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test model\n",
    "model = torch.load(\"./results/models/turb/raw/may-sixth.pt\")\n",
    "model.eval()\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "prog_bar = tqdm(testloader, desc=\"Testing\", leave=False)\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(prog_bar):\n",
    "        x = batch[0].to(device)\n",
    "\n",
    "        y = batch[1].squeeze().to(device)\n",
    "\n",
    "        outs = model(x.float())\n",
    "\n",
    "        _, preds = torch.max(outs, 1)\n",
    "\n",
    "        for label, prediction in zip(y, preds):\n",
    "            # convert label and prediction to current vals\n",
    "            label = le.inverse_transform([label])[0]\n",
    "            prediction = le.inverse_transform([prediction])[0]\n",
    "\n",
    "            y_pred.append(prediction)\n",
    "            y_true.append(label)\n",
    "\n",
    "\n",
    "# build conf matrix\n",
    "conf = confusion_matrix(y_true, y_pred, labels=classes)\n",
    "\n",
    "# review the classnames here\n",
    "df_cm = pd.DataFrame(\n",
    "    conf / conf.sum(axis=1)[:, np.newaxis],\n",
    "    index=[i for i in classes],\n",
    "    columns=[i for i in classes],\n",
    ")\n",
    "\n",
    "# classification report\n",
    "acc_report = classification_report(y_true, y_pred)\n",
    "print(acc_report)\n",
    "\n",
    "bal_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "print(f\"Balanced accuracy: {bal_acc}\")\n",
    "\n",
    "# display conf matrix\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "plt.xlabel(\"Ground Truths\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.title(label=\"Turbidity Peak Detection Ratio Confusion Matrix\")\n",
    "\n",
    "plot = sn.heatmap(df_cm, annot=True)\n",
    "\n",
    "plt.xlabel(\"Ground Truths\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.title(label=\"Turbidity Peak Detection Ratio Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "plot.get_figure().savefig(\"./results/graphics/turb/raw/may-2.png\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ed753961bdc37ee89b4275051722ceb8ec0b57b8793db9d189305c313070a7d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('srrw')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
